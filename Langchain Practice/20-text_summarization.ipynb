{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Data Transformation: Simplified Explanation\\n\\nWhat is Data Transformation?\\nData transformation is like changing the way we measure things to make them easier to understand and compare. It's like converting inches to centimeters or changing dollars to euros to help with calculations and comparisons.\\n\\nWhy and Where?\\nData transformation is important because it helps us work with data more effectively. We transform data to make it more useful for analysis and building models.\\n\\nPractical Uses:\\n- Scaling: Changing the range or size of numbers.\\n- Normalization: Making data follow a certain pattern or shape.\\n\\nReal-Life Example:\\nThink about temperatures. In some places, they use Celsius, and in others, Fahrenheit. If you want to compare temperatures accurately, you might convert everything to one scale, like Celsius.\\n\\nMin-Max Scaling: Simplified Explanation\\n\\nStandard Scaling is like making all your numbers play nicely with each other by giving them a common center (average) and making sure they're all about the same distance (standard deviation) from that center.\\n\\nWhy and Where?\\nWe use Standard Scaling when we want to compare data that might have different averages and spreads.\\n\\nPractical Uses:\\n- Stock Prices: Comparing stock prices with different averages and volatility.\\n- Test Scores: Comparing student scores on different tests with varying difficulty levels.\\n\\nReal-Life Example:\\nSuppose you're analyzing test scores from different subjects. Some subjects might have higher averages and more spread-out scores. To compare them fairly, you'd use Standard Scaling to bring them all to the same baseline.\\n\\nIn summary, data transformation methods like Min-Max Scaling and Standard Scaling are like adjusting data to make it easier to work with and compare. They're useful for various situations where you want to ensure fair comparisons and prevent some data from overshadowing others. Choosing the right method depends on what you're trying to achieve and the nature of your data.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "with open(\"Data Transformation Simplified Expl.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_messages = [\n",
    "    SystemMessage(content=\"You are an expert in summarizing text content.\"),\n",
    "    HumanMessage(content=f\"Please provide a short and concise summary of the text below:\\n\\n{text}\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Data transformation changes the way data is measured for easier analysis and comparison. It's like converting units to make calculations simpler. Methods like Min-Max Scaling and Standard Scaling help normalize data by adjusting its range and spread, ensuring fair comparisons, especially when data has different averages or variations. Choosing the right method depends on the specific goal and data characteristics. \\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gengerating summary of the text\n",
    "llm(chat_messages).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['language', 'text'], template='\\nWrite the summary of the following text:\\nText: {text}\\n\\nTranslate the precise summary into {language}\\n')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Write the summary of the following text:\n",
    "Text: {text}\n",
    "\n",
    "Translate the precise summary into {language}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"language\"],\n",
    "    template=prompt_template\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWrite the summary of the following text:\\nText: Data Transformation: Simplified Explanation\\n\\nWhat is Data Transformation?\\nData transformation is like changing the way we measure things to make them easier to understand and compare. It's like converting inches to centimeters or changing dollars to euros to help with calculations and comparisons.\\n\\nWhy and Where?\\nData transformation is important because it helps us work with data more effectively. We transform data to make it more useful for analysis and building models.\\n\\nPractical Uses:\\n- Scaling: Changing the range or size of numbers.\\n- Normalization: Making data follow a certain pattern or shape.\\n\\nReal-Life Example:\\nThink about temperatures. In some places, they use Celsius, and in others, Fahrenheit. If you want to compare temperatures accurately, you might convert everything to one scale, like Celsius.\\n\\nMin-Max Scaling: Simplified Explanation\\n\\nStandard Scaling is like making all your numbers play nicely with each other by giving them a common center (average) and making sure they're all about the same distance (standard deviation) from that center.\\n\\nWhy and Where?\\nWe use Standard Scaling when we want to compare data that might have different averages and spreads.\\n\\nPractical Uses:\\n- Stock Prices: Comparing stock prices with different averages and volatility.\\n- Test Scores: Comparing student scores on different tests with varying difficulty levels.\\n\\nReal-Life Example:\\nSuppose you're analyzing test scores from different subjects. Some subjects might have higher averages and more spread-out scores. To compare them fairly, you'd use Standard Scaling to bring them all to the same baseline.\\n\\nIn summary, data transformation methods like Min-Max Scaling and Standard Scaling are like adjusting data to make it easier to work with and compare. They're useful for various situations where you want to ensure fair comparisons and prevent some data from overshadowing others. Choosing the right method depends on what you're trying to achieve and the nature of your data.\\n\\nTranslate the precise summary into Urdu\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_prompt = prompt.format(text=text, language=\"Urdu\")\n",
    "complete_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "410"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(complete_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## Summary:\\n\\nData transformation is like changing the way we measure things to make them easier to understand and compare. It helps us analyze data effectively and build better models. Examples include scaling, which changes the range of numbers, and normalization, which makes data follow a specific pattern.\\n\\nMin-Max Scaling is a specific type of data transformation where we adjust data to have the same average and spread. This allows for fairer comparisons, especially when dealing with data that has different averages and spreads, like stock prices or test scores.\\n\\n## Urdu Translation:\\n\\nڈیٹا ٹرانسفرمیشن چیزوں کو ناپنے کے طریقے کو تبدیل کرنے جیسا ہے تاکہ انہیں سمجھنا اور موازنہ کرنا آسان ہو جائے۔ یہ ہمیں ڈیٹا کا تجزیہ کرنے اور بہتر ماڈل بنانے میں مدد کرتا ہے۔ اس کے مثالیں ہیں سکیلنگ، جو نمبروں کی حد کو تبدیل کرتا ہے، اور نارملائزیشن، جو ڈیٹا کو ایک مخصوص پیٹرن پر چلاتا ہے۔\\n\\nمن-میکس سکیلنگ ڈیٹا ٹرانسفرمیشن کا ایک خاص طریقہ ہے جہاں ہم ڈیٹا کو ایڈجسٹ کرتے ہیں تاکہ اس کا اوسط اور پھیلاؤ ایک جیسا ہو۔ یہ خاص طور پر اس وقت اہمیت کا حامل ہے جب ہم اس طرح کے ڈیٹا کا موازنہ کرتے ہیں جس کے مختلف اوسط اور پھیلاؤ ہوں، جیسے اسٹاک کی قیمتیں یا امتحان کے نمبر۔ \\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "summary = llm_chain.run({\"text\": text, \"language\": \"Urdu\"})\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"## Summary:\\n\\nData transformation is like changing the units of measurement to make data easier to understand and compare. It's crucial for effective analysis and building models. \\n\\nTwo common techniques are:\\n\\n* **Min-Max Scaling:**  Rescales data to a specific range, like 0 to 1. This helps compare data with different scales.\\n* **Standard Scaling:**  Adjusts data by centering it around the average and standardizing its spread. This is useful for comparing data with different averages and variations.\\n\\nThink of it like converting temperatures from Fahrenheit to Celsius for accurate comparisons.\\n\\n## Urdu Translation:\\n\\nڈیٹا ٹرانسفرمیشن ڈیٹا کو سمجھنے اور موازنہ کرنے کے لیے اس کے پیمانے کو تبدیل کرنے جیسا ہے۔ یہ تجزیہ اور ماڈل سازی کے لیے بہت ضروری ہے۔\\n\\nدو عام تکنیکیں ہیں:\\n\\n* **من-میکس اسکیلنگ:**  ڈیٹا کو کسی مخصوص رینج، جیسے 0 سے 1 تک، میں تبدیل کرنا۔ یہ مختلف پیمانے پر ڈیٹا کے موازنہ میں مدد کرتا ہے۔\\n* **سٹینڈرڈ اسکیلنگ:**  ڈیٹا کو اوسط کے ارد گرد مرتکز کر کے اور اس کی پھیلاؤ کو معیاری بنانے کے ذریعے ایڈجسٹ کرنا۔ یہ مختلف اوسطوں اور تغیرات والے ڈیٹا کے موازنہ کے لیے مفید ہے۔\\n\\nیہ فہرنہائٹ کو سیلسیئس میں تبدیل کرنے کی طرح سوچیں تاکہ درست موازنہ کیا جا سکے۔ \\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also use this method\n",
    "llm_chain = prompt | llm \n",
    "\n",
    "summary = llm_chain.invoke({\"text\": text, \"language\": \"Urdu\"})\n",
    "summary.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Stuff Document Chain Text Summarization\n",
    "If the size of documents fits in the context window of the LLM, we use this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 0, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"Certified Cloud Native Applied\\nGenerative AI Engineer\\nMaster the Future\\nBuild Custom GPTs, AI Agents, Humanoids, and Fine-Tune LLMs\\nVersion: 12.5 (Implementation and adoption starting from August 1, 2024)\\nToday's pivotal technological trends are Cloud Native (CN), Generative AI (GenAI),\\nand Physical AI. Cloud Native technology offers a scalable and dependable platform\\nfor application operation, while AI equips these applications with intelligent,\\nhuman-like capabilities. Physical AI aims to bridge the gap between digital\\nintelligence and physical capability, creating systems that can understand and\\ninteract with the world in a human-like manner. Our aim is to train you to excel as a\\nCloud Native Applied Generative and Physical AI developer globally.\\nThe Cloud Native Applied Generative AI Certification program equips you to create\\nleading-edge Cloud Native AI and Physical AI solutions using a comprehensive\\ncloud-native, AI, and Physical AI platform.\\nEverything will soon be represented by a conversational interface, or to put it another\\nway, a personal AI, we will cover it extensively in this program. () Currently, OpenAI\\nCustom GPT Platform is the best platform to develop personal AI.\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 1, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"We will also be covering AI agents, which are autonomous programs or entities that\\nperceive their environment through sensors, process this information, and take\\nactions to achieve specific goals or tasks. They can operate independently, adapt to\\nchanging conditions, and make decisions based on their observations and\\nobjectives.\\nMaterial to Understand the Coming AI Age:\\n●\\nWatch the Overview Video of Our Program\\n●\\nWatch AGI could Double GDP\\n●\\nWatch Personal AI Short Video\\n●\\nThe Future Is Agentic\\n●\\nThe INSANE Race for AI Humanoid Robots\\n●\\nWhat Is an AI Anyway? Mustafa Suleyman\\n●\\nThe Coming Wave: Technology, Power, and the 21st Century’s Greatest\\nDilemma\\n●\\nThe Worlds I See: Curiosity, Exploration, and Discovery at the Dawn of AI\\n●\\nEthan Mollick’s Substack\\n●\\nDavid Autor Lecture\\n●\\nConversation between Suleyman, Yuval Noah Harari, and Zanny Minton\\nBeddoes\\nThis twenty one month program equips you with the skills to thrive in the age of\\nGenerative AI (GenAI), Physical AI, and cloud native computing (CN). You will\\nbecome an expert Custom GPT, AI Agent, and Humanoid Robotics Developer. The\\nprogram is divided into two levels: foundation level and professional level. Students\\nwill be able to start working after completing the foundation level. They will\\ncontinue their professional level studies while working.\\nWhy This Program?\\n●\\nCutting-Edge Skills: Develop in-demand skills to build intelligent, scalable\\ncloud applications using Generative AI and Cloud Native technologies.\\n●\\nIndustry-Ready: Prepare for global certifications, startup and freelance\\nopportunities after just six months.\\n●\\nFuture-Proof Your Career: Stay ahead of the curve in a rapidly evolving tech\\nlandscape.\\nWhat You'll Learn:\\n●\\nCustom GPTs and Multi AI Agent Systems: Learn to fine-tuning\\nfoundational AI models, and market them in GPT stores. Learn key principles\\nof designing effective AI agents, and organising a team of AI agents to\\n2\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 2, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='perform complex, multi-step tasks. Apply these concepts to automate\\ncommon business processes.\\n●\\nDevelop AI Powered Microservices: Master Python, build APIs using\\nFastAPI, SQLModel, Postgres, Kafka, Kong, and leverage cutting-edge GenAI\\nAPIs like OpenAI, and Open Source AI LLMs.\\n●\\nCloud Native Expertise: Design and deploy cloud-native applications using\\nDocker, DevContainers, TestContainers, Kubernetes, Terraform, and GitHub\\nActions.\\n●\\nDistributed System Design: Designing systems that run on multiple\\ncomputers (or nodes) simultaneously, interacting and coordinating their\\nactions by passing messages over a network.\\n●\\nDesigning AI Solutions using Design Thinking and Behaviour Driven\\nDevelopment (BDD): We will learn to leverage these methodologies to create\\nAI solutions that are not only technically sound but also highly user-centric\\nand aligned with real-world needs.\\n●\\nFine-Tuning Open-Source Large Language Models using PyTorch, and\\nFast AI: We will learn to fine-tuning of open-source Large Language Models\\n(LLMs) like Meta LLaMA 3 using PyTorch and Fast AI, with a focus on\\ncloud-native training and deployment. We will set up development\\nenvironments, preprocess data, fine-tune models, and deploy them using\\ncloud native platforms.\\n●\\nPhysical AI and Humanoid Robotics: We will learn to design, simulate, and\\ndeploy advanced humanoid robots capable of natural interactions.\\nFlexible Learning:\\n●\\nEarn While You Learn: Start freelancing or contributing to projects after the\\nthird quarter.\\nProgram Structure (Foundation: 3 + Professional: 4 = Total: 7 Quarters):\\nFoundation Level (3 Quarters)\\n●\\nQuarter 1: Fundamentals of Prompt Engineering, Docker, GitHub, and\\nModern Python Programming\\nWe begin the course by understanding the basics of GenAI and Prompt\\nEngineering. Then we will understand the basics of Linux, Docker, VSCode,\\nDevcontainer, and GitHub. The main focus will be on mastering the\\nfundamentals of Modern Python with Typing, the go-to language for AI.\\n○\\nCertification:\\n■\\nCertified Professional Python Programmer (CPPP1)\\n3'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 3, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='Learning Repo:\\nhttps://github.com/panaversity/learn-cloud-native-modern-python\\n●\\nQuarter 2: Applied Generative AI Fundamentals: Prompt Engineering,\\nDeveloping Custom GPTs and Multi AI Agent Systems\\nWith this course, you’ll start by building a strong understanding of generative\\nAI and learn how to apply Large language models (LLMs) and diffusion\\nmodels practically. We will introduce a set of principles known as prompt\\nengineering, which will help developers to work efficiently with AI. Learn to\\ncreate custom AI models and GPTs using OpenAI, Azure, and Google\\ntechnologies. Use open source libraries, like Langchain, CrewAI, and\\nLangGraph to automate repeatable, multi-step tasks and automate business\\nprocesses that are typically done by a group of people.\\nCertifications:\\n■\\nMicrosoft Certified: Azure AI Engineer Associate\\n■\\nCertified crewAI Engineer\\nLearning Repo:\\nhttps://github.com/panaversity/learn-applied-generative-ai-fundamentals/\\n●\\nQuarter 3: Cloud Native AI Powered Microservices Design, Development,\\nand Deployment:\\nBuild scalable AI Powered APIs using FastAPI, Postgres, Kafka, Kong, GenAI\\nAPIs like OpenAI Chat Completion APIs, Assistant APIs, LangChain and\\nOpen Source AI LLMs, develop them using Containers and Dev Containers,\\nand deploy them using Docker Compose locally and Kubernetes Powered\\nServerless Container Services on the cloud.\\nWe will also learn to integrate design thinking and Behavior-Driven\\nDevelopment (BDD) in developing AI systems. We will learn to create AI\\nsolutions that are deeply aligned with user needs and expectations. Design\\nthinking ensures a thorough understanding of the user and problem space,\\nwhile BDD provides a structured approach to defining and validating the\\ndesired behaviours of the AI system. Together, these methodologies lead to\\nthe development of AI solutions that are not only technically robust but also\\nhighly user-centric and effective in solving real-world problems.\\n○\\nCertifications:\\n■\\nPostgreSQL 13 Associate Certification\\n■\\nConfluent Certified Developer for Apache Kafka (CCDAK)\\n4'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 4, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"■\\nDesign Thinking Professional Certificate (DTPC)\\n■\\nTest and Behavior Driven Development (TDD/BDD)\\nLearning Repo:\\nhttps://github.com/panaversity/learn-cloud-native-ai-powered-microservices/\\nWe Will Be Using Microsoft Azure as our Default Cloud Platform\\nAmazon is still the cloud king based on market share. But many analysts\\nagree: In the battle for the cloud, AI is now a game-changer — and Amazon's\\nmain competitors, particularly Microsoft, have the momentum.\\nIn our program we will be using Azure as our default provider for teaching and\\ndeployment. We will be using using these services:\\nGet a free Azure Account now:\\nhttps://azure.microsoft.com/en-us/free\\nNote: Use GitHub Account to start an Azure free trial\\nAzure Container Apps (We will Start from this service using Dapr and Keda)\\nhttps://azure.microsoft.com/en-us/products/container-apps\\nGet started with the free tier: The first 180,000 vCPU per second, 360,000\\nGiB/s, and 2 million requests each month are free.\\nWatch: https://www.youtube.com/watch?v=0HwQfsa03K8\\nDeploy:\\nhttps://learn.microsoft.com/en-us/azure/container-apps/code-to-cloud-options\\nAzure Container Registry\\nhttps://azure.microsoft.com/en-us/products/container-registry/\\nDeploy to Azure Container Apps with GitHub Actions\\nhttps://learn.microsoft.com/en-us/azure/container-apps/github-actions\\nAzure Kubernetes Service (AKS)\\nhttps://azure.microsoft.com/en-us/products/kubernetes-service\\nGitHub\\nhttps://azure.microsoft.com/en-us/products/github/\\nGitHub Actions for AKS\\nhttps://learn.microsoft.com/en-us/azure/aks/kubernetes-action\\n5\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 5, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='Azure OpenAI Service\\nhttps://azure.microsoft.com/en-us/products/ai-services/openai-service\\nAzure Database for PostgreSQL\\nhttps://azure.microsoft.com/en-us/products/postgresql/\\nKafka\\nhttps://cloudatlas.me/5-different-ways-you-can-run-apache-kafka-on-azure-97\\n3a18925ac7\\nProfessional Level (4 Quarters)\\n●\\nQuarter 4: Generative AI with PyTorch:\\nGenerative AI tools like ChatGPT, Gemini, and DALL-E have revolutionised\\nour professional landscape. This hands-on course, “Master Generative AI with\\nPyTorch,” guides you through the exciting process of building and training AI\\nmodels using Python and the versatile, open-source PyTorch framework, all\\nwith the hardware you already have. You’ll delve into the core concepts of\\nGenerative Adversarial Networks (GANs), Transformers, Large Language\\nModels (LLMs), variational autoencoders, diffusion models, LangChain, and\\nmore. Along the way, you’ll gain practical experience and a deep\\nunderstanding of these cutting-edge technologies.\\nLearning Repo: https://github.com/panaversity/genai-with-pytorch\\n●\\nQuarter 5: Fine-Tuning Open-Source Large Language Models:\\nThis comprehensive course is designed to guide learners through the process\\nof fine-tuning open-source Large Language Models (LLMs) such as Meta\\nLLaMA 3 using PyTorch, with a particular emphasis on cloud-native training\\nand deployment. The course covers everything from the fundamentals to\\nadvanced concepts, ensuring students acquire both theoretical knowledge\\nand practical skills.\\nThe journey begins with an introduction to LLMs, focusing on their\\narchitecture, capabilities, and the specific features of Meta LLaMA 3. Next, the\\ncourse dives into PyTorch fundamentals, teaching students how to perform\\nbasic operations with tensors and build simple neural networks. This\\n6'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 6, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='foundation is crucial for understanding the mechanics behind LLMs. Data\\npreparation is a crucial aspect of training models. The course covers\\ncomprehensive data collection and preprocessing techniques, such as\\ntokenization and text normalisation. These steps are essential for preparing\\ndatasets suitable for fine-tuning LLMs like Meta LLaMA 3. Through practical\\nexercises, students learn how to handle and preprocess various types of text\\ndata, ensuring they can prepare their datasets for optimal model performance.\\nFine-tuning Meta LLaMA 3 with PyTorch forms a significant part of the course.\\nStudents will delve into the architecture of Meta LLaMA 3, learn how to load\\npre-trained models, and apply fine-tuning techniques. The course covers\\nadvanced topics such as regularisation and optimization strategies to\\nenhance model performance. Practical sessions guide students through the\\nentire fine-tuning process on custom datasets, emphasising best practices\\nand troubleshooting techniques.\\nA critical aspect of this course is its focus on cloud-native training and\\ndeployment using Nvidia NIM. Furthermore, students learn how to deploy\\nmodels using Docker and Kubernetes, set up monitoring and maintenance\\ntools, and ensure their models are scalable and efficient.\\nTo round off the learning experience, the course includes an in-depth segment\\non exporting models for inference and building robust inference pipelines.\\nStudents will deploy models on cloud platforms, focusing on practical aspects\\nof setting up monitoring tools to maintain model performance and reliability.\\nThe course culminates in a capstone project, where students apply all the\\nskills they have learned to fine-tune and deploy Meta LLaMA 3 on a chosen\\nplatform. This project allows students to demonstrate their understanding and\\nproficiency in the entire process, from data preparation to cloud-native\\ndeployment.\\nLearning Repo:\\nhttps://github.com/panaversity/learn-fine-tuning-llms\\n●\\nQuarter 6: Physical AI and Humanoid Robotics Development:\\nArtificial intelligence (AI) has experienced remarkable advancements in recent\\nyears. However, the future of AI extends beyond the digital space into the\\nphysical world, driven by robotics. This new frontier, known as “Physical AI,”\\ninvolves AI systems that can function in the real world and comprehend\\nphysical laws. This marks a notable transition from AI models confined to\\ndigital environments. Humanoid robots are poised to excel in our\\n7'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 7, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='human-centred world because they share our physical form and can be\\ntrained with abundant data from interacting in human environments.\\nThis course provides an in-depth exploration of humanoid robotics, focusing\\non the integration of ROS 2 (Robot Operating System), Open Source Meta\\nLlama 3, and OpenAI technologies. Students will learn to design, simulate,\\nand deploy advanced humanoid robots capable of natural interactions. The\\ncurriculum covers essential topics such as ROS 2 for robotic control,\\nsimulations with Gazebo and Unity, and using OpenAI’s GPT models for\\nconversational AI. Through practical projects and real-world applications,\\nstudents will develop the skills needed to drive innovation in humanoid\\nrobotics.\\nLearning Repo:\\nhttps://github.com/panaversity/learn-physical-ai-humanoid-robotics\\n●\\nQuarter 7: Kubernetes and Distributed System Design:\\nMaster Kubernetes, Terraform, and GitHub Actions to deploy your AI APIs and\\nmicroservices in the cloud. We will cover distributed system design involving\\ncreating systems that are distributed across multiple nodes, focusing on\\nscalability, fault tolerance, consistency, availability, and partition tolerance.\\nCertifications:\\n■\\nCertified Kubernetes Application Developer (CKAD)\\n■\\nHashiCorp Certified: Terraform Associate\\nLearning Repo: https://github.com/panaversity/learn-kubernetes\\nFrontend Specialisation\\n●\\nQuarter 8: Front-end Web GUI Development using Next.js and\\nTypeScript (Optional):\\nNext.js is designed to handle complex front-end applications well, making it a\\ngood fit for AI applications that might grow in features and data usage over\\ntime. Next.js offers features like API routes and file-based routing, which can\\nstreamline development for AI applications that need to interact with backend\\nAPIs and manage different application views. While Next.js and TypeScript\\n8'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 8, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"aren't the only options for building AI application frontends, their focus on\\nperformance, scalability, and developer experience makes them a compelling\\nchoice for many developers.\\nLearning Repo:\\nhttps://github.com/panaverse/learn-nextjs\\n9\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 9, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='In 2015, Klaus Schwab, founder of the World Economic Forum, asserted that we\\nwere on the brink of a “Fourth Industrial Revolution,” one powered by a fusion of\\ntechnologies, such as advanced robotics, artificial intelligence, and the Internet of\\nThings.\\n“[This revolution] will fundamentally alter the way we live, work, and relate to one\\nanother,” wrote Schwab in an essay published in Foreign Affairs. “In its scale, scope,\\nand complexity, the transformation will be unlike anything humankind has\\nexperienced before.”\\nGenerative AI is set to revolutionise our daily lives and work environments.\\nAccording to McKinsey & Company, generative AI could contribute an annual\\neconomic value of $2.6 trillion to $4.4 trillion across various sectors by enhancing\\nautomation, bolstering decision-making, and providing personalised experiences.\\nInvestor Cathie Wood predicts that the market for humanoid robots could grow to $1\\ntrillion by 2030.\\nCloud native is an approach in software development that enables application\\ncreation, deployment, and management in cloud environments. It involves\\nconstructing applications as a collection of small, interconnected services known as\\nmicroservices, a shift from traditional monolithic structures. This modular approach\\nenhances the agility of cloud-native applications, allowing them to operate more\\nefficiently with fewer resources.\\nCloud Native has already been adopted by the majority of the companies, by 2024,\\nmore than 90% of global organisations will be running containerized applications in\\nproduction. The adoption of Docker and Kubernetes has seen significant growth over\\nrecent years. As of 2022, about 61% of organisations reported using Kubernetes for\\ncontainer orchestration. This number has been steadily increasing as more\\ncompanies realise the benefits of these technologies for managing containerized\\napplications ￼￼.\\nTechnologies such as Kubernetes, Docker, serverless containers, APIs, SQL\\nDatabases, and Kafka support developers in swiftly constructing cloud-native\\napplications. These tools offer a standardised platform for application development\\nand management across various cloud services like Azure, Google Cloud, and AWS.\\nThis revolution is pivotal for technology and job landscapes, making it essential\\nknowledge in fast-evolving tech cycles. The rapid emergence of Gen AI-powered\\nand Physical AI technologies, and the evolving demand for skills necessitate\\nextensive and timely professional training.\\n10'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 10, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='Vertical Specialization Level\\nStudents will have the option of selecting one of the following specialisations after\\nthe completion of sixth quarter i.e. in the seventh quarter:\\n1. Healthcare and Medical GenAI Specialization\\n2. Web3, Blockchain, and GenAI Integration Specialization\\n3. Metaverse, 3D, and GenAI Integration Specialization\\n4. GenAI for Accounting, Finance, and Banking Specialization\\n5. GenAI for Engineers Specialization\\n6. GenAI for Sales and Marketing Specialization\\n7. GenAI for Automation and Internet of Things (IoT) Specialisation\\n8. GenAI for Cyber Security\\nCommon Questions (FAQs) with Detailed Answers\\n1. What is Cloud Native Applied Generative AI Engineering?\\nCloud Applied Generative AI Engineering (GenEng) is the application of\\ngenerative AI technologies to solve real-world problems in the cloud.\\n●\\nGenerative AI is a type of artificial intelligence that can create new data\\nor content from existing data.\\n●\\nCloud Native computing is the delivery of computing\\nservices—including servers, storage, databases, networking, software,\\nanalytics, and intelligence—over the Internet (“the cloud”).\\nBy combining generative AI with cloud native computing, businesses can\\nsolve a variety of problems, such as:\\n●\\nCreating personalised experiences for customers\\n●\\nAutomating tasks\\n●\\nImproving decision-making\\n●\\nDetecting fraud\\n●\\nDeveloping new products and services\\nThe potential applications of cloud native-applied generative AI are endless.\\nAs generative AI and cloud native computing continue to develop, we can\\nexpect to see even more innovative and groundbreaking uses for this\\ntechnology.\\n2. How valuable are the Cloud Native Applied Generative AI developers?\\nDevelopers with expertise in Cloud Native Applied Generative AI were in\\nextremely high demand due to the increasing adoption of GenAI technologies\\nacross various industries. However, the supply of developers skilled\\n11'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 11, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='specifically in this niche area might not have been as abundant compared to\\nmore generalised AI or cloud computing roles.\\nThe demand for AI developers, especially those proficient in applying\\ngenerative AI techniques within cloud native environments, has been rising\\ndue to the growing interest in using AI for creative applications, content\\ngeneration, image synthesis, natural language processing, and other\\ninnovative purposes.\\nAccording to some sources, the average salary for a Cloud Native Applied\\nGenerative AI developer in the global market is around $150,000 per year.\\nHowever, this may vary depending on the experience level, industry, location,\\nand skills of the developer. For example, a senior Cloud Applied Generative\\nAI developer with more than five years of experience can earn up to $200,000\\nper year. A Cloud Applied Generative AI developer working in the financial\\nservices industry can earn more than a developer working in the\\nentertainment industry. A Cloud Applied Generative AI developer working in\\nNew York City can earn more than a developer working in Dubai. In general,\\nhighly skilled AI developers, especially those specialising in applied\\ngenerative AI within cloud environments, tend to earn competitive salaries that\\nare often above the average for software developers or AI engineers due to\\nthe specialised nature of their skills. Moreover, as generative AI technology\\nbecomes more widely adopted and integrated into various products and\\nservices, the demand for Cloud Applied Generative AI developers is likely to\\nincrease.\\nTherefore, Cloud Applied Generative AI developers are valuable professionals\\nwho have a bright future ahead of them. They can leverage their creativity and\\ntechnical skills to create innovative solutions that can benefit various\\nindustries and domains. They can also enjoy very competitive salary and\\ncareer growth opportunities.\\n3. What is the potential for Cloud Applied Generative AI Developers to start\\ntheir own companies?\\nCloud Applied Generative AI Developers have a significant potential to start\\ntheir own companies due to several factors:\\n1. Emerging Field: Generative AI, particularly when applied within cloud\\nenvironments, is still an evolving field with immense potential for innovation.\\nDevelopers who understand the intricacies of both generative AI techniques\\nand cloud technologies can identify unique opportunities to create novel\\nproducts, services, or solutions.\\n2. Market Demand: There is a growing demand for AI-driven applications,\\nespecially those that involve generative capabilities such as image\\n12'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 12, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"generation, content creation, style transfer, etc. Developers with expertise in\\nthis area can leverage this demand to create specialized products that cater\\nto specific industries or consumer needs.\\n3. Innovation and Differentiation: The ability to develop unique and innovative\\nsolutions using generative AI in the cloud can set apart these developers'\\nstartups from more conventional companies. They can explore new ways of\\ngenerating content, enhancing user experiences, or solving complex problems\\nwith AI-generated solutions.\\n4. Access to Cloud Resources: Cloud platforms provide scalable and\\ncost-effective resources that are crucial for AI development. Developers\\nstarting their own companies can leverage cloud services to access powerful\\ncomputing resources, storage, and AI-related services without significant\\nupfront investment.\\n5. Entrepreneurial Opportunities: Developers with entrepreneurial spirit and a\\ndeep understanding of AI technologies can identify gaps in the market and\\nbuild startups to fill those gaps. They can create platforms, tools, or services\\nthat simplify the adoption of generative AI for businesses or developers.\\n6. Collaboration and Partnerships: These developers can collaborate with\\nother experts in AI, domain specialists, or businesses to create innovative\\nsolutions or explore new application areas for generative AI in the cloud.\\nHowever, starting a company, especially in a specialised field like Cloud\\nApplied Generative AI, requires more than technical expertise. It also\\ndemands business acumen, understanding market needs, networking,\\nsecuring funding, managing resources effectively, and navigating legal and\\nregulatory landscapes.\\nSuccessful entrepreneurship in this domain involves a combination of\\ntechnical skills, innovation, a deep understanding of market dynamics, and the\\nability to transform technical expertise into viable products or services that\\naddress real-world challenges or opportunities.\\nDevelopers aspiring to start their own companies in the Cloud Applied\\nGenerative AI space can do so by conducting thorough market research,\\nnetworking with industry experts, building a strong team, and developing a\\nclear business plan that highlights the unique value proposition of their\\nofferings.\\nTo sum up, the potential for Cloud Applied Generative AI Developers to start\\ntheir own companies is high.\\n●\\nGenerative AI is a rapidly growing field with a high demand for skilled\\nprofessionals.\\n13\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 13, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"●\\nThe Certified Generative AI (GenEng) Developer and Engineering\\nProgram provides students with the skills and knowledge they need to\\ndevelop and apply cutting-edge generative AI technologies.\\n●\\nThe program also teaches students how to start and run a successful\\nbusiness.\\n●\\nGraduates of the program will be well-positioned to start their own\\ncompanies and capitalise on the growing demand for generative AI\\nsolutions.\\n4. Is the program not too long, twenty one months is a long time?\\nThe length of the program is twenty one months which is broken down into\\nseven quarters of three months each. The program covers a wide range of\\ntopics including Python, GenAI, Microservices, Database, Cloud\\nDevelopment, Fine-tuning, DevOps, GPTs, AI Agents, and Humanoids. The\\nprogram is designed to give students a comprehensive understanding of\\ngenerative AI and prepare them for careers in this field. Nothing valuable can\\nbe achieved overnight, there are no shortcuts in life.\\n5. Why don't we use TypeScript (Node.js) to develop APIs instead of using\\nPython?\\nWe will not use Typescript in GenAI API development because Python is a\\npriority with the AI community when working with AI and if any updates come\\nin libraries they will first come for Python. Python is always a better choice\\nwhen dealing with AI and API.\\n●\\nPython is the de facto standard for AI Development.\\n●\\nTypeScript is a more modern language that is gaining popularity for\\nWeb Development, but Python is more widely used and has a larger\\necosystem of libraries and frameworks available, especially for AI.\\n●\\nTypeScript is used for web user interfaces, while Python is used for\\nAPIs.\\n●\\nIn the second quarter, students will learn to develop APIs using Python\\ninstead of TypeScript.\\n●\\nPython is a more commonly used language for AI and API\\ndevelopment, and it has a larger ecosystem of libraries and\\nframeworks available for these purposes.\\n●\\nTypeScript is a more modern language that is becoming increasingly\\npopular for API development also, but it is still not as widely used as\\nPython, especially for AI applications and development.\\n6. What is the difference between OpenAI Completion API, OpenAI\\nAssistant API, Google Gemini Multi-Modal API, and LangChain?\\n14\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 14, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"The difference between OpenAI Completion API, OpenAI Assistant API,\\nGoogle Gemini Multi-Modal API, and LangChain is that they are different\\nways of using artificial intelligence to generate text, images, audio, and video\\nbased on some input, but they have different features and applications. Here\\nis a summary of each one:\\nOpenAI Completion API is the most fundamental OpenAI model that\\nprovides a simple interface that’s extremely flexible and powerful. You give it a\\nprompt and it returns a text completion, generated according to your\\ninstructions. You can think of it as a very advanced autocomplete where the\\nlanguage model processes your text prompt and tries to predict what’s most\\nlikely to come next. The Completion API can be used for various tasks such\\nas writing stories, poems, essays, code, lyrics, etc. It also supports different\\nmodels with different levels of power suitable for different tasks.\\nOpenAI Assistant API is an interface to OpenAI's most capable model\\n(gpt-4) and their most cost-effective model (gpt-3.5-turbo). It provides a simple\\nway to take text as input and use a model like gpt-4 or gpt-3.5-turbo to\\ngenerate an output. The Assistant API allows you to build AI assistants within\\nyour applications. An Assistant has instructions and can leverage models,\\ntools, and knowledge to respond to user queries. The Assistant API currently\\nsupports three types of tools: Code Interpreter, Retrieval, and Function calling.\\nGoogle Gemini Multi-Modal API is a new series of foundational models built\\nand introduced by Google. It is built with a focus on multimodality from the\\nground up. This makes the Gemini models powerful against different\\ncombinations of information types including text, images, audio, and video.\\nCurrently, the API supports images and text. Gemini has proven by reaching\\nstate-of-the-art performance on the benchmarks and even beating the\\nChatGPT and the GPT4-Vision models in many of the tests.\\nThere are three different Gemini models based on their size, the Gemini Ultra,\\nGemini Pro, and Gemini Nano in decreasing order of their size.\\nLangChain is a platform that allows you to interact with various language\\nmodels from different providers such as OpenAI, Google Gemini, Hugging\\nFace Transformers, etc. You can use LangChain to create applications that\\nleverage the power of natural language processing without having to deal with\\nthe complexity of APIs or SDKs. LangChain provides a user-friendly interface\\nthat lets you choose the model you want to use, customize the parameters\\nyou want to apply, and see the results in real-time.\\n15\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 15, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"7. Why don't we use Flask or Django for API development instead of\\nFastAPI?\\n●\\nFastAPI is a newer and more modern framework than Flask or\\nDjango. It is designed to be fast, efficient, and easy to use. FastAPI is\\nalso more scalable than Flask or Django, making it a better choice for\\nlarge-scale projects.\\n●\\nFastAPI is also more feature-rich than Flask or Django. It includes\\nseveral built-in features that make it easy to develop APIs, such as\\nrouting, validation, and documentation.\\n●\\nOverall, FastAPI is a better choice for API development than Flask\\nor Django. It is faster, more scalable, and more feature-rich.\\n8. Why do we need to learn Cloud technologies in a Generative AI\\nprogram?\\nCloud technologies are essential for developing and deploying generative AI\\napplications because they provide a scalable and reliable platform for hosting\\nand managing complex workloads.\\n●\\nCloud computing offers a vast pool of resources that can be\\nprovisioned on demand, which is ideal for generative AI applications\\nthat can be computationally intensive.\\n●\\nCloud providers offer a wide range of services that can be used to\\nsupport generative AI applications, including storage, computing,\\nnetworking, and machine learning.\\n●\\nCloud services are typically more cost-effective than on-premises\\ninfrastructure, which can be a significant advantage for generative AI\\napplications that are often used for large-scale projects.\\nThe Certified Generative AI (GenEng) Developer and Engineering Program\\nteaches you how to use cloud native services, including containers and\\nKubernetes, to deploy your applications to the cloud. You will also learn how\\nto use Docker containers to package and deploy your applications, and how\\nto use Terraform to manage your cloud infrastructure.\\nBy the end of the program, you will be able to:\\n●\\nUse Docker containers to package and deploy your applications\\n●\\nDevelop and deploy generative AI applications to the cloud\\n●\\nManage your cloud infrastructure using Terraform\\n9. What is the purpose of Docker Containers and what are the benefits of\\ndeploying them with Docker Compose, and Kubernetes?\\n●\\nDocker Containers are a way to package software into a single unit\\nthat can be run on any machine, regardless of its operating system. It\\n16\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 16, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"is used to create a Dockerfile, which is a text file that describes how to\\nbuild a Docker image. The image is then used to create a container,\\nwhich is a running instance of the image. This makes them ideal for\\ndeploying applications on a variety of platforms, including cloud-based\\nservices.\\n●\\nDocker Compose is a tool provided by Docker that allows you to\\ndefine and manage multi-container Docker applications locally. It\\nenables you to use a YAML file to configure the services, networks,\\nand volumes needed for your application's setup. With Docker\\nCompose, you can describe the services your application requires,\\ntheir configurations, dependencies, and how they should interact with\\neach other, all in a single file. This makes it easier to orchestrate\\ncomplex applications locally composed of multiple interconnected\\ncontainers.\\n●\\nKubernetes is a container orchestration system that automates the\\ndeployment, scaling, and management of containerized applications. It\\nallows you to run multiple containers on a single machine or across\\nmultiple machines. It is an open source and can be deployed in your\\ndata centre or the cloud.\\n10.What is the purpose of learning to develop APIs in a Generative AI\\nprogram?\\nAPIs (Application Programming Interfaces) are used to connect different\\nsoftware applications and services together. They are the building blocks of\\nthe internet and are essential for the exchange of data between different\\nsystems.\\nIn the third quarter of the Certified Generative AI (GenEng) Developer and\\nEngineering Program, students will learn to develop APIs not just as a\\nbackend for their front end but also as a product itself. In this model, the API\\nis at the core of the business's value.\\n●\\nAPIs are used to make it possible for different software applications to\\ncommunicate with each other.\\n●\\nAPIs are used to access data from a remote server.\\n●\\nAPIs are used to create new services or applications that are\\nintegrated with existing systems.\\n●\\nAPIs are used to improve the security of applications by providing a\\nway to control access to data.\\n●\\nBy learning to develop APIs, students will gain the skills necessary to\\ncreate powerful and efficient software applications that can be used to\\nsolve a variety of business problems.\\n17\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 17, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"11. What is the purpose of using Python-based FastAPI and related\\ntechnologies in Quarter 3?\\nIn the third quarter of the Engineering Program, students will learn how to use\\nPython-based FastAPI as a core library for API development.\\n●\\nFastAPI is a high-performance, lightweight, and easy-to-use framework\\nfor building APIs.\\n●\\nIt is designed to be fast, scalable, and secure.\\n●\\nFastAPI is compatible with a wide range of programming languages\\nand frameworks, making it a good choice for developers with different\\nskill sets.\\n●\\nStudents will also learn about the following related technologies:\\n●\\nPydantic: Pydantic is a Python library that helps to improve the quality\\nof your code by checking for errors and potential problems.\\n●\\nSQLModel: SQLModel is a Python library that provides an\\nobject-relational mapping (ORM) layer for working with databases.\\n●\\nPostgreSQL: PostgreSQL is a free and open-source relational\\ndatabase management system (RDBMS) that can be used for\\ndevelopment. Highly scalable database systems compatible with it\\nhave also been deployed by all the major cloud platforms.\\nBy the end of the quarter, students will be able to use Python-based FastAPI\\nto develop APIs that are fast, scalable, and secure.\\n12.What does the API-as-a-Product model entail?\\nAPI-as-a-Product is a type of Software-as-a-Service that monetizes niche\\nfunctionality, typically served over HTTP. In this model, the API is at the core\\nof the business's value. The API-as-a-Product model is different from the\\ntraditional API model, where APIs are used as a means to access data or\\nfunctionality from another application. In the API-as-a-Product model, the API\\nitself is the product that is being sold.\\nThe benefits of the API-as-a-Product model include:\\n●\\nIncreased flexibility: APIs can be used to access data or functionality\\nfrom any application, regardless of the underlying platform or\\ntechnology. This gives businesses greater flexibility in how they\\nintegrate APIs into their applications.\\n●\\nReduced development costs: APIs can be reused by multiple\\napplications, which can save businesses the time and expense of\\ndeveloping their custom APIs.\\n18\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 18, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='●\\nImproved scalability: APIs can be scaled up or down as needed,\\nwhich makes them well-suited for businesses with fluctuating or\\nunpredictable traffic demands.\\n●\\nEnhanced security: APIs can be more secure than traditional\\nmethods of data exchange, as they can be protected by a variety of\\nsecurity measures, such as encryption and access control.\\n13.What are the benefits of using Docker Containers for development,\\ntesting, and deployment?\\nDocker Containers are a fundamental building block for development, testing,\\nand deployment because they provide a consistent environment that can be\\nused across different systems. This eliminates the need to worry about\\ndependencies or compatibility issues, and it can help to improve the efficiency\\nof the development process. Additionally, Docker Containers can be used to\\nisolate applications, which can help to improve security and make it easier to\\nmanage deployments.\\n14.What is the advantage of using open Docker, Kubernetes, and Terraform\\ntechnologies instead of using AWS, Azure, or Google Cloud\\ntechnologies?\\nUsing open-source technologies like Docker, Kubernetes, and Terraform\\noffers several advantages over relying solely on proprietary cloud services\\nfrom AWS, Azure, or Google Cloud. Here’s a detailed comparison:\\nAdvantages of Using Docker, Kubernetes, and Terraform (Open Technologies)\\n1. Portability and Flexibility:\\n- Vendor Agnostic: These tools are cloud-agnostic, meaning you can run\\nyour applications on any cloud provider or on-premises infrastructure without\\nbeing locked into a specific vendor.\\n- Ease of Migration: Applications packaged in Docker containers can easily\\nbe moved across different environments, and Kubernetes provides a\\nconsistent orchestration layer, ensuring seamless transitions.\\n2. Cost Efficiency:\\n- Avoid Vendor Lock-In: Being locked into a single cloud provider can lead to\\nhigher costs over time. Using open technologies allows you to leverage\\ncompetitive pricing from multiple providers or even use on-premises\\nresources.\\n- Optimised Resource Utilisation: Kubernetes helps in efficiently managing\\nresources through automated scaling and load balancing, potentially reducing\\ncosts.\\n19'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 19, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='3. Community and Ecosystem:\\n- Open Source: These tools are backed by strong, active open-source\\ncommunities that continuously improve the software, provide support, and\\nshare best practices.\\n- Ecosystem: A rich ecosystem of tools and integrations is available,\\nproviding flexibility to choose the best components that fit your specific needs.\\n4. Standardisation and Consistency:\\n- Unified Platform: Using Docker for containerization, Kubernetes for\\norchestration, and Terraform for infrastructure as code (IaC) provides a\\nstandardised way to deploy, manage, and scale applications across different\\nenvironments.\\n- Consistency Across Environments: These tools ensure that your\\ndevelopment, staging, and production environments are consistent, reducing\\nbugs and deployment issues.\\n5. Customization and Control:\\n- Full Control: Open-source tools give you complete control over your\\ninfrastructure and deployment pipelines. You can customise and extend the\\nfunctionality to suit specific requirements.\\n- Transparency: Access to the source code means you can audit and modify\\nthe software to meet your security and compliance needs.\\nAdvantages of Using AWS, Azure, or Google Cloud Technologies\\n1. Managed Services:\\n- **Ease of Use:** Cloud providers offer a wide range of managed services\\nthat abstract away the complexity of setting up and managing infrastructure.\\nThis can save time and reduce operational overhead.\\n- Integrated Solutions: These platforms provide integrated services and\\ntools, such as databases, machine learning, analytics, and monitoring, which\\ncan be easily combined to build complex applications.\\n2. Scalability and Reliability:\\n- Global Infrastructure: Cloud providers have extensive global infrastructure,\\nensuring high availability, redundancy, and low latency.\\n- Auto-Scaling: Advanced auto-scaling capabilities can dynamically adjust\\nresources to meet changing demands, ensuring optimal performance.\\n3. Security and Compliance:\\n- Built-In Security: Cloud providers offer robust security features, including\\nidentity and access management, encryption, and compliance certifications,\\nhelping to protect your data and meet regulatory requirements.\\n20'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 20, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"- Automatic Updates: Managed services often include automatic updates\\nand patches, reducing the risk of security vulnerabilities.\\n4. Innovation and Support:\\n- Cutting-Edge Technology: Major cloud providers continuously innovate and\\nintroduce new services and features, allowing you to leverage the latest\\ntechnologies without significant investment.\\n- Support and SLA: Comprehensive support services and Service Level\\nAgreements (SLAs) ensure that you have access to expert help and\\nguaranteed uptime.\\nConclusion\\nChoosing between open-source technologies like Docker, Kubernetes, and\\nTerraform versus proprietary cloud services from AWS, Azure, or Google\\nCloud depends on your specific needs and priorities.\\n- Open Technologies: Offer portability, cost efficiency, customization, and\\ncontrol, making them ideal for multi-cloud strategies, avoiding vendor lock-in,\\nand having more control over your infrastructure.\\n- Cloud Providers: Provide ease of use, managed services, scalability,\\nsecurity, and access to cutting-edge technology, which can be advantageous\\nfor rapid development, scaling, and leveraging advanced services.\\nIn many cases, a hybrid approach that combines the strengths of both\\nopen-source tools and cloud provider services can provide the best of both\\nworlds, allowing you to optimise for cost, flexibility, and innovation.\\n15.Why in this program are we not learning to build LLMs ourselves? How\\ndifficult is it to develop an LLM like ChatGPT 4 or Google’s Gemini?\\nDeveloping an LLM like ChatGPT 4 or Google Gemini is extremely difficult\\nand requires a complex combination of resources, expertise, and\\ninfrastructure. Here's a breakdown of the key challenges:\\nTechnical hurdles:\\nMassive data requirements: Training these models requires an immense\\namount of high-quality data, often exceeding petabytes. Compiling, cleaning,\\nand structuring this data is a monumental task.\\nComputational power: Training LLMs demands incredible computational\\nresources, like high-performance GPUs and specialised AI hardware. Access\\nto these resources and the ability to optimise training processes are crucial.\\n21\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 21, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"Model architecture: Designing the LLM's architecture involves complex\\ndecisions about parameters, layers, and attention mechanisms. Optimising\\nthis architecture for performance and efficiency is critical.\\nEvaluation and bias: Evaluating the performance of LLMs involves diverse\\nbenchmarks and careful monitoring for biases and harmful outputs. Mitigating\\nthese biases is an ongoing research challenge.\\nResource and expertise:\\nTeam effort: Developing an LLM like ChatGPT 4 or Google Gemini requires a\\nlarge team of experts across various disciplines, including AI researchers,\\nmachine learning engineers, data scientists, and software developers.\\nFinancial investment: The financial resources needed are substantial,\\ncovering costs for data acquisition, hardware, software, and talent. Access to\\nsustained funding is critical.\\nAdditionally:\\nEthical considerations: LLMs raise ethical concerns like potential misuse,\\nmisinformation, and societal impacts. Responsible development and\\ndeployment are crucial.\\nRapidly evolving field: The LLM landscape is constantly evolving, with new\\nresearch, models, and benchmarks emerging. Staying abreast of these\\nadvancements is essential.\\nTherefore, while ChatGPT 4 and Google Gemini have made impressive\\nstrides, developing similar LLMs remains a daunting task accessible only to a\\nhandful of organisations with the necessary resources and expertise.\\nIn simpler terms, it's like building a skyscraper of knowledge and intelligence.\\nYou need the right materials (data), the right tools (hardware and software),\\nthe right architects (experts), and a lot of hard work and attention to detail to\\nmake it stand tall and function flawlessly.\\nDeveloping similar models would be a daunting task for individual developers\\nor smaller teams due to the enormous scale of resources and expertise\\nneeded. However, as technology progresses and research findings become\\nmore accessible, it might become incrementally more feasible for a broader\\nrange of organisations or researchers to work on similar models, albeit at a\\nsmaller scale or with fewer resources. At that time we might also start to focus\\non developing LLMs ourselves.\\n22\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 22, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"To sum up, the focus of the program is not on LLM model development but on\\napplied Cloud GenAI Engineering (GenEng), application development, and\\nfine-tuning of foundational models. The program covers a wide range of topics\\nincluding Python, GenAI, Microserices, API, Database, Cloud Development,\\nand DevOps, which will give students a comprehensive understanding of\\ngenerative AI and prepare them for careers in this field.\\n16.Business wise does it make more sense to develop LLMs ourselves\\nfrom scratch or use LLMs developed by others and build applications\\nusing these tools by using APIs and/or fine-tuning them?\\nWhether it makes more business sense to develop LLMs from scratch or\\nleverage existing ones through APIs and fine-tuning depends on several\\nfactors specific to your situation. Here's a breakdown of the pros and cons to\\nhelp you decide:\\nDeveloping LLMs from scratch:\\nPros:\\nCustomization: You can tailor the LLM to your specific needs and data,\\npotentially achieving higher performance on relevant tasks.\\nIntellectual property: Owning the LLM allows you to claim intellectual property\\nrights and potentially monetize it through licensing or other means.\\nControl: You have full control over the training data, algorithms, and biases,\\nensuring alignment with your ethical and business values.\\nCons:\\nHigh cost: Building and training LLMs require significant technical expertise,\\ncomputational resources, and data, translating to high financial investment.\\nTime commitment: Developing an LLM is a time-consuming process,\\npotentially delaying your go-to-market with your application.\\nTechnical expertise: You need a team of highly skilled AI specialists to\\ndesign, train, and maintain the LLM.\\nUsing existing LLMs:\\nPros:\\nLower cost: Leveraging existing LLMs through APIs or fine-tuning is\\nsignificantly cheaper than building them from scratch.\\nFaster time to market: You can quickly integrate existing LLMs into your\\napplications, accelerating your launch timeline.\\n23\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 23, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='Reduced technical burden: You don\\'t need a large team of AI specialists to\\nmaintain the LLM itself\\nCons:\\nLess customization: Existing LLMs are not specifically designed for your\\nneeds, potentially leading to lower performance on some tasks.\\nLimited control: You rely on the data and biases of the existing LLM, which\\nmight not align with your specific requirements.\\nDependency on external parties: You are dependent on the availability and\\nmaintenance of the LLM by its developers.\\nHere are some additional factors to consider:\\nThe complexity of your application: Simpler applications might benefit\\nmore from existing LLMs, while highly complex ones might require the\\ncustomization of a dedicated LLM.\\nYour available resources: If you have the financial and technical resources,\\ndeveloping your own LLM might be feasible. Otherwise, existing options might\\nbe more practical.\\nYour competitive landscape: If your competitors are using LLMs, you might\\nneed to follow suit to remain competitive.\\nUltimately, the best decision depends on your specific needs, resources, and\\nbusiness goals. Carefully evaluating the pros and cons of each approach will\\nhelp you choose the strategy that best aligns with your success.\\n17.What are Custom GPTs?\\n\"Custom GPTs\" refers to specialised versions of the Generative Pre-trained\\nTransformer (GPT) models that are tailored for specific tasks, industries, or\\ndata types. These custom models are adapted from the base GPT\\narchitecture, which is a type of language model developed by OpenAI.\\nCustom GPT models are trained or fine-tuned on specific datasets or for\\nparticular applications, allowing them to perform better in those contexts\\ncompared to the general-purpose models.\\nHere are some examples of what custom GPT models might be used for:\\n1. Industry-Specific Needs: A custom GPT for legal, medical, or financial\\nindustries could be trained on domain-specific texts to understand and\\ngenerate industry-specific language more accurately.\\n24'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 24, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"2. Language and Localization: Models can be customised for different\\nlanguages or dialects that might not be well-represented in the training data of\\nthe base model.\\n3. Company-Specific Applications: Organisations might develop a custom\\nGPT model trained on their own documents and communications to assist\\nwith internal tasks like drafting emails, generating reports, or providing\\ncustomer support.\\n4. Educational Purposes: Educational institutions might develop custom\\nGPTs trained on educational material to assist in creating teaching materials\\nor providing tutoring in specific subjects.\\n5. Creative Writing and Entertainment: Custom models could be trained on\\nspecific genres of literature or scripts to assist in creative writing or content\\ncreation.\\n6. Technical and Scientific Research: A custom GPT model could be\\ntrained on scientific literature to assist researchers in summarising papers,\\ngenerating hypotheses, or even drafting new research.\\nThese custom models are created through a process of fine-tuning, where the\\nbase GPT model is further trained (or 'fine-tuned') on a specific dataset. This\\nprocess allows the model to become more adept at understanding and\\ngenerating text that is relevant to the specific use case. Fine-tuning requires\\nexpertise in machine learning and natural language processing, as well as\\naccess to relevant training data.\\n18.What are Actions in GPTs?\\nActions are a way to connect custom GPTs to external APIs, allowing them to\\naccess data or interact with the real-world. For example, you can use actions\\nto create a GPT that can book flights, send emails, or order pizza. Actions\\nare defined using the OpenAPI specification, which is a standard for\\ndescribing APIs. You can import an existing OpenAPI specification or create a\\nnew one using the GPT editor.\\n19.What are AI Agents and how do they differ from Custom GPTs?\\nAI Agents and Custom GPTs are both tools that utilise artificial intelligence to\\nperform tasks, but they have distinct functionalities and use cases. Here’s a\\nbreakdown of their differences:\\nAI Agents\\nAI Agents are autonomous programs that can perceive their environment,\\nmake decisions, and act upon them to achieve specific goals. They often\\n25\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 25, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='interact with other systems or users, continuously learning and adapting\\nbased on their experiences.\\nKey Characteristics:\\n1. Autonomy: AI Agents operate independently without continuous human\\nintervention.\\n2. Learning: They often employ machine learning algorithms to improve\\nperformance over time.\\n3. Interactivity: AI Agents can interact with their environment, other systems,\\nand users.\\n4. Goal-Oriented: They are designed to achieve specific objectives and can\\nadapt their actions to optimise towards these goals.\\n5. Multi-Modal Capabilities: AI Agents can incorporate various forms of AI,\\nsuch as computer vision, natural language processing, and decision-making\\nalgorithms.\\nExamples:\\n- Robotics: Autonomous robots that navigate and perform tasks.\\n- Virtual Assistants: Programs like Siri or Alexa that interact with users and\\nperform tasks based on voice commands.\\n- Game AI: Non-player characters (NPCs) that adapt and react to player\\nactions.\\nCustom GPTs\\nCustom GPTs are tailored instances of OpenAI’s ChatGPT, launched in late\\n2022. They are designed for specific purposes and enhanced with context.\\nEach custom GPT can have a unique “personality,” including tone of voice,\\nlanguage complexity, and responsiveness to specific topics. For example, a\\nfinancial institution’s custom GPT could be trained on financial reports and\\nindustry-specific terminology, while a healthcare provider’s version might\\nfocus on medical literature and health policy documents\\nKey Differences\\n1. Autonomy:\\n- AI Agents: Operate autonomously and continuously interact with their\\nenvironment.\\n- Custom GPTs: Typically respond to specific inputs and generate outputs\\naccordingly, but don’t operate autonomously beyond text generation tasks.\\n2. Learning and Adaptation:\\n- AI Agents: Often incorporate continuous learning and adaptation\\nmechanisms.\\n26'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 26, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='- Custom GPTs: Rely on pre-training and fine-tuning phases, with limited\\ncontinuous learning capabilities.\\n4. Interactivity:\\n- AI Agents: Can interact with both digital and physical environments.\\n- Custom GPTs: Primarily interact through text-based inputs and outputs.\\nIn summary, while both AI Agents and Custom GPTs utilise AI, AI Agents are\\ndesigned for autonomous, goal-oriented actions in diverse environments, and\\nCustom GPTs are specialised in generating and understanding human-like\\ntext for specific applications.\\n20.Do we need to use Design Thinking and BDD for designing custom GPTs\\nand AI Agents?\\nDesign Thinking and Behavior-Driven Development (BDD) are methodologies\\nthat can greatly enhance the process of designing custom GPTs and AI\\nAgents, though they are not strictly necessary. Here’s how each can be\\nbeneficial:\\nDesign Thinking\\nDesign Thinking is a user-centred approach to innovation and problem-solving\\nthat involves understanding the user, challenging assumptions, redefining\\nproblems, and creating innovative solutions through iterative prototyping and\\ntesting.\\nBenefits for Custom GPTs and AI Agents:\\n1. User-Centric Focus: Ensures that the AI solutions are tailored to the actual\\nneeds and pain points of users.\\n2. Empathy: Helps in understanding the context and environment in which the\\nAI will be used, leading to more relevant and effective solutions.\\n3. Iterative Development: Encourages continuous testing and refinement of\\nideas, leading to more robust and user-friendly AI models.\\n4. Collaboration: Promotes cross-disciplinary collaboration, which can bring\\ndiverse perspectives and expertise to the design process.\\nBehaviour-Driven Development (BDD)\\nBDD is a software development methodology that encourages collaboration\\nbetween developers, QA, and non-technical stakeholders through the use of\\nnatural language descriptions of the desired behaviour of the software.\\nBenefits for Custom GPTs and AI Agents:\\n1. Clear Requirements: Ensures that the requirements are clearly understood\\nand agreed upon by all stakeholders.\\n27'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 27, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='2. Testable Scenarios: Facilitates the creation of testable scenarios that can\\nvalidate the AI’s behaviour against the expected outcomes.\\n3. Documentation: Provides clear and comprehensive documentation of the\\nAI’s intended behaviour, which is useful for future maintenance and\\nenhancements.\\n4. Alignment: Ensures that the development stays aligned with business goals\\nand user expectations.\\nApplication in Designing Custom GPTs and AI Agents\\nFor Custom GPTs:\\n- Design Thinking:\\n- Understand the specific use cases and user interactions where the GPT\\nwill be applied.\\n- Iterate on the model’s performance by gathering user feedback and refining\\nthe fine-tuning process.\\n- Prototype different conversation flows and evaluate their effectiveness with\\nreal users.\\n- BDD:\\n- Define the expected behaviours of the GPT in natural language scenarios.\\n- Create automated tests that validate the GPT’s responses against these\\nscenarios.\\n- Ensure that the GPT’s behaviour aligns with user stories and business\\nrequirements.\\nFor AI Agents:\\n- Design Thinking:\\n- Map out the user journey and identify critical interaction points where the AI\\nAgent will provide value.\\n- Prototype and test the agent’s interactions in various environments to\\nensure robustness and usability.\\n- Use empathy maps and personas to better understand and anticipate user\\nneeds and behaviours.\\n- BDD:\\n- Write behaviour scenarios that describe how the AI Agent should react in\\ndifferent situations.\\n- Develop tests that simulate these scenarios to verify the agent’s\\ndecision-making and learning processes.\\n- Continuously refine the agent’s behaviour based on test results and user\\nfeedback.\\n28'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 28, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"While not strictly necessary, Design Thinking and BDD can significantly\\nenhance the design and development process of custom GPTs and AI Agents\\nby ensuring a user-centred approach, clear requirements, and continuous\\nimprovement through iterative testing and feedback. These methodologies\\nhelp in creating more effective, reliable, and user-friendly AI solutions.\\n21.When Fine-Tuning Open-Source Large Language Models, how is FastAI\\nand PyTorch important and what role do these libraries play?\\nFine-tuning open-source Large Language Models (LLMs) like Meta LLaMA 3\\ninvolves adapting pre-trained models to specific tasks or domains by\\ncontinuing the training process on a smaller, task-specific dataset. FastAI and\\nPyTorch play crucial roles in this process due to their powerful features and\\nease of use. Here's how they contribute:\\nPyTorch\\nPyTorch is an open-source deep learning framework developed by\\nFacebook’s AI Research lab. It provides a flexible and efficient platform for\\nbuilding and training neural networks.\\nImportance in Fine-Tuning LLMs:\\n1. Dynamic Computation Graphs: PyTorch’s dynamic computation graph (also\\nknown as define-by-run) allows for flexibility and ease of debugging. This is\\nparticularly useful when experimenting with different model architectures and\\ntraining strategies.\\n2. Extensive Libraries and Tools: PyTorch has a wide range of libraries and\\ntools that facilitate various deep learning tasks, including natural language\\nprocessing (NLP). Libraries like Hugging Face’s Transformers are built on top\\nof PyTorch, providing pre-trained models and utilities for fine-tuning.\\n3. GPU Acceleration: PyTorch supports GPU acceleration, which is essential\\nfor handling the large computational requirements of fine-tuning LLMs.\\n4. Community and Ecosystem: PyTorch has a strong community and\\nextensive documentation, making it easier to find resources, tutorials, and\\nsupport for fine-tuning tasks.\\nRole in Fine-Tuning:\\n- Model Customization: Allows users to modify the architecture of LLMs to\\nbetter fit specific tasks.\\n- Efficient Training: Provides efficient backpropagation and optimization\\nroutines to train large models on specialised datasets.\\n- Experimentation: Facilitates rapid experimentation with different\\nhyperparameters and training setups due to its flexible framework.\\n29\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 29, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='FastAI\\nFastAI is a deep learning library built on top of PyTorch that aims to simplify\\ntraining neural networks by providing high-level abstractions and best\\npractices.\\nImportance in Fine-Tuning LLMs:\\n1. Ease of Use: FastAI provides high-level APIs that simplify many complex\\ntasks involved in training and fine-tuning models, making it accessible to both\\nbeginners and experts.\\n2. State-of-the-Art Techniques: FastAI incorporates many state-of-the-art\\ntechniques and best practices in deep learning, such as learning rate\\nschedules, data augmentation, and transfer learning, which can improve the\\nperformance of fine-tuned models.\\n3. Rapid Prototyping: FastAI’s concise and readable code allows for rapid\\nprototyping and iteration, which is crucial for experimenting with different\\nfine-tuning approaches.\\n4. Integrated Data Handling: FastAI offers powerful data handling and\\npreprocessing utilities, which streamline the process of preparing datasets for\\ntraining.\\nRole in Fine-Tuning:\\n- High-Level API: Simplifies the process of loading pre-trained models,\\ndefining custom datasets, and setting up training loops.\\n- Training Utilities: Provides utilities for monitoring training progress, adjusting\\nlearning rates, and saving model checkpoints.\\n- Best Practices: Encourages the use of best practices in model training, such\\nas using discriminative learning rates and employing effective data\\naugmentation techniques.\\nCombined Workflow for Fine-Tuning LLMs\\n1. Model Loading: Use PyTorch (and libraries like Hugging Face\\nTransformers) to load a pre-trained LLM.\\n2. Data Preparation: Leverage FastAI’s data handling capabilities to\\npreprocess and load the fine-tuning dataset.\\n3. Training Setup: Define the model architecture and training parameters\\nusing PyTorch, and use FastAI’s high-level APIs to simplify this process.\\n4. Fine-Tuning: Utilise FastAI’s training utilities to fine-tune the model on the\\nspecific dataset, adjusting hyperparameters as needed.\\n5. Evaluation and Iteration: Evaluate the fine-tuned model using PyTorch’s\\nevaluation utilities, and iterate on the fine-tuning process by leveraging\\nFastAI’s rapid prototyping capabilities.\\n30'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 30, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"Both PyTorch and FastAI play crucial roles in the fine-tuning of open-source\\nLLMs. PyTorch provides the foundational tools and flexibility needed for deep\\nlearning, while FastAI builds on top of PyTorch to offer high-level abstractions\\nand best practices that streamline the fine-tuning process. Together, they\\nenable efficient, effective, and user-friendly fine-tuning of large language\\nmodels for specific tasks and domains.\\n22.In this course both PyTorch and FastAI play crucial roles in the\\nfine-tuning of open-source LLMs, why don't we use TensorFlow instead?\\nWhile TensorFlow is a powerful and widely-used deep learning framework,\\nPyTorch and FastAI offer several advantages that make them particularly\\nwell-suited for fine-tuning open-source Large Language Models (LLMs).\\nHere’s a detailed comparison highlighting why PyTorch and FastAI might be\\npreferred over TensorFlow for this specific task:\\nPyTorch vs. TensorFlow\\n1. Dynamic Computation Graphs:\\n- PyTorch: Uses dynamic computation graphs (define-by-run), which allow\\nfor greater flexibility and ease of debugging. This is especially useful when\\nexperimenting with new models and training strategies.\\n- TensorFlow: Initially used static computation graphs (define-and-run).\\nAlthough TensorFlow 2.0 introduced eager execution to support dynamic\\ngraphs, PyTorch's implementation is often considered more intuitive and\\neasier to work with for dynamic tasks.\\n2. Ease of Use:\\n- PyTorch: Known for its simplicity and clear, Pythonic code, which makes it\\neasier to learn and use, especially for research and prototyping.\\n- TensorFlow: While TensorFlow 2.0 improved usability, it is still considered\\nmore complex compared to PyTorch, particularly for newcomers.\\n3. Community and Ecosystem:\\n- PyTorch: Has seen rapid adoption in the research community, leading to a\\nrich ecosystem of tools, libraries, and community support. Libraries like\\nHugging Face’s Transformers are built primarily for PyTorch, offering\\nextensive support for LLMs.\\n- TensorFlow: Has a strong industrial presence and is widely used in\\nproduction environments. However, the research community has increasingly\\nfavoured PyTorch.\\n4. Integration with Hugging Face:\\n31\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 31, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='- PyTorch: Hugging Face’s Transformers library, which is a go-to for working\\nwith LLMs, is deeply integrated with PyTorch. This library provides pre-trained\\nmodels, tokenizers, and utilities that simplify the process of fine-tuning LLMs.\\n- TensorFlow: Although Hugging Face provides TensorFlow support, the\\nintegration is not as seamless or feature-rich as it is with PyTorch.\\nFastAI vs. TensorFlow\\n1. High-Level Abstractions:\\n- FastAI: Provides high-level abstractions that simplify complex tasks in\\nmodel training and fine-tuning, making it accessible and efficient for users.\\nThese abstractions are built on top of PyTorch, leveraging its flexibility.\\n- TensorFlow: While Keras (part of TensorFlow) offers high-level APIs,\\nFastAI’s APIs are often considered more intuitive and tailored towards rapid\\nexperimentation and prototyping.\\n2. Best Practices:\\n- FastAI: Incorporates state-of-the-art techniques and best practices in deep\\nlearning, such as learning rate schedules, transfer learning, and data\\naugmentation, making it easier to achieve high performance with minimal\\neffort.\\n- TensorFlow: Requires more manual effort to implement many of these best\\npractices, which can be a barrier for quick iteration and experimentation.\\n3. Community and Learning Resources:\\n- FastAI: Has an active community and a wealth of educational resources,\\nincluding courses and documentation that focus on practical, hands-on\\nlearning.\\n- TensorFlow: Also has extensive documentation and resources, but the\\nlearning curve can be steeper, especially for those new to deep learning.\\nSummary of Why PyTorch and FastAI Might Be Preferred\\n- Flexibility and Debugging: PyTorch’s dynamic computation graph is more\\nflexible and easier to debug.\\n- User-Friendly: PyTorch and FastAI offer more intuitive and user-friendly\\ninterfaces, making them suitable for rapid prototyping and experimentation.\\n- Research and Development: PyTorch is preferred in the research\\ncommunity, leading to faster adoption of new techniques and tools like\\nHugging Face’s Transformers.\\n- Seamless Integration: Hugging Face’s deep integration with PyTorch\\nprovides a robust ecosystem for working with LLMs.\\n32'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 32, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='- Educational Resources: FastAI’s focus on best practices and practical\\neducation makes it easier for users to get started and achieve good results\\nquickly.\\nWhile TensorFlow remains a powerful framework, particularly in production\\nenvironments, PyTorch and FastAI provide a combination of flexibility, ease of\\nuse, and community support that make them particularly well-suited for the\\nfine-tuning of open-source LLMs.\\n23.What is Physical AI?\\nPhysical AI refers to the integration of artificial intelligence with physical\\nentities, such as robots, that can operate and interact in the real world. This\\nconcept involves AI systems that not only process data and make decisions\\nbut also perform physical actions and understand the laws of physics.\\nKey Characteristics:\\n1. Real-World Interaction:\\n- Physical AI systems can perceive their environment through sensors,\\nprocess this information, and take appropriate actions using actuators.\\n2. Embodiment:\\n- Unlike purely digital AI, Physical AI involves AI embedded in physical\\nbodies, like humanoid robots, which can navigate and manipulate the physical\\nworld.\\n3. Understanding Physics:\\n- These AI systems are designed to comprehend and adhere to the physical\\nlaws that govern real-world interactions, such as gravity, friction, and object\\ndynamics.\\n4. Human-like Functionality:\\n- Humanoid robots are a prime example of Physical AI, as they are built to\\nperform tasks in environments designed for humans, utilising a form factor\\nthat mirrors human anatomy.\\n5. Data-Driven Training:\\n- Physical AI leverages vast amounts of real-world data to train AI models,\\nenabling robots to improve their performance through machine learning and\\ninteraction experiences.\\nApplications:\\n- Healthcare:\\n- Assistive robots that help with patient care, rehabilitation, and surgery.\\n33'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 33, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='- Service Industry:\\n- Robots that perform tasks such as cleaning, delivery, and customer\\nservice.\\n- Manufacturing:\\n- Industrial robots that assemble products, manage inventory, and ensure\\nquality control.\\n- Exploration:\\n- Robots designed for exploration in environments like space, underwater, or\\ndisaster zones.\\nPhysical AI represents a significant shift from traditional AI applications\\nconfined to virtual environments. It aims to bridge the gap between digital\\nintelligence and physical capability, creating systems that can understand and\\ninteract with the world in a human-like manner. This evolution has the\\npotential to revolutionise various industries by enhancing automation,\\nimproving efficiency, and enabling new forms of human-machine\\ncollaboration.\\n24.What are the different specialisations offered at the end of the program\\nand what are their benefits?\\nAt the end of the GenEng certification program we offer six specialisations in\\ndifferent fields:\\nHealthcare and Medical GenAI: This specialisation will teach students how\\nto use generative AI to improve healthcare and medical research. This is\\nrelevant to fields such as drug discovery, personalised medicine, and surgery\\nplanning.\\nBenefits:\\n●\\nLearn how to use generative AI to identify diseases, develop new\\ndrugs, and personalise treatment plans.\\n●\\nGain a deeper understanding of the ethical implications of using\\ngenerative AI in healthcare.\\n●\\nPrepare for a career in a growing field with high demand for skilled\\nprofessionals.\\nWeb3, Blockchain, and GenAI Integration: This specialisation will teach\\nstudents how to integrate generative AI with Web3 and blockchain\\ntechnologies. This is relevant to fields such as finance, healthcare, and supply\\nchain management.\\nBenefits:\\n●\\nLearn how to create smart contracts and decentralised applications\\n(dApps).\\n34'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 34, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='●\\nGain a deeper understanding of the potential of blockchain technology\\nand how it can be used to improve business processes.\\n●\\nDevelop the skills necessary to work in a rapidly growing field with high\\ndemand for skilled professionals.\\nMetaverse, 3D, and GenAI Integration: This specialisation will teach\\nstudents how to create and use 3D models and other immersive content\\nmanually and with generative AI. This is relevant to fields such as gaming,\\nmarketing, and architecture.\\nBenefits:\\n●\\nLearn how to use generative AI to create realistic and immersive 3D\\nmodels.\\n●\\nDevelop the skills necessary to work in the growing field of virtual\\nreality (VR) and augmented reality (AR).\\n●\\nApply generative AI to solve real-world problems in areas such as\\nproduct design, marketing, and education.\\nGenAI for Accounting, Finance, and Banking: This specialisation will teach\\nstudents how to use generative AI to improve accounting, finance, and\\nbanking processes. This is relevant to fields such as fraud detection, risk\\nmanagement, and investment analysis.\\nBenefits:\\n●\\nLearn how to use generative AI to automate tasks, identify patterns,\\nand make predictions.\\n●\\nGain a deeper understanding of the financial industry and how\\ngenerative AI can be used to improve its processes.\\n●\\nPrepare for a career in a growing field with high demand for skilled\\nprofessionals.\\nGenAI for Engineers: This specialisation will teach students how to use\\ngenerative AI to improve engineering design and problem-solving. This is\\nrelevant to fields such as manufacturing, construction, and product\\ndevelopment.\\nBenefits:\\n●\\nLearn how to use generative AI to create simulations, optimize designs,\\nand predict failures.\\n●\\nGain a deeper understanding of the engineering design process and\\nhow generative AI can be used to improve it.\\n●\\nPrepare for a career in a growing field with high demand for skilled\\nprofessionals.\\n35'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 35, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='GenAI for Sales and Marketing: This specialisation will teach students how\\nto use generative AI to improve sales and marketing campaigns. This is\\nrelevant to fields such as advertising, public relations, and customer service.\\nBenefits:\\n●\\nLearn how to use generative AI to create personalised marketing\\nmessages, generate leads, and track campaign performance.\\n●\\nGain a deeper understanding of the latest marketing trends and how\\ngenerative AI can be used to improve them.\\n●\\nPrepare for a career in a growing field with high demand for skilled\\nprofessionals.\\nGenAI for Automation and Internet of Things (IoT):\\n●\\nProvide Multi-Modal User Interface for the IoT systems: Multimodal\\ninteraction exploits the synergic use of different modalities to optimise\\nthe interactive tasks accomplished by the users. This allows a user to\\nuse several input modes such as speech, touch, and visual to interact\\nwith IoT systems.\\n●\\nImprove efficiency and accuracy of industrial processes: By\\nimplementing GenAI in automation and IoT systems, industries can\\noptimise their processes, reduce manual labour, and increase\\nproductivity while ensuring higher accuracy and consistency.\\n●\\nEnhance decision-making: GenAI can analyse vast amounts of data\\ncollected by IoT sensors to derive valuable insights, enabling\\nbusinesses to make informed decisions regarding operations,\\nmaintenance, and resource allocation.\\n●\\nPersonalise user experiences: GenAI can leverage IoT data to\\nunderstand user preferences and behaviours, enabling the creation of\\npersonalised experiences across smart devices and IoT-enabled\\nsystems.\\nGenAI for Cyber Security:\\n●\\nStrengthen threat detection and response: GenAI can be used to\\nrapidly detect and respond to cyber threats by analysing large volumes\\nof security data in real time, identifying anomalies, and suggesting\\nappropriate countermeasures.\\n●\\nEnhance security monitoring and analysis: GenAI can assist\\nsecurity analysts in monitoring and analysing security logs, automating\\nthreat detection, and providing insights into security risks and\\nvulnerabilities.\\n●\\nImprove threat intelligence: GenAI can be used to gather and\\nanalyse threat intelligence from various sources, enabling\\norganisations to stay informed about the latest threats and trends and\\nproactively strengthen their security posture.\\n36')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "\n",
    "loader = PyMuPDFLoader(\"Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf\")\n",
    "doc_pages = loader.load_and_split()\n",
    "doc_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['text'], template='\\nWrite a concise and short summary of the following text capturing all important information:\\nText: {text}\\n')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Write a concise and short summary of the following text capturing all important information:\n",
    "Text: {text}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"text\"], template=template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Write a concise and short summary of the following text capturing all important information:\n",
      "Text: Certified Cloud Native Applied\n",
      "Generative AI Engineer\n",
      "Master the Future\n",
      "Build Custom GPTs, AI Agents, Humanoids, and Fine-Tune LLMs\n",
      "Version: 12.5 (Implementation and adoption starting from August 1, 2024)\n",
      "Today's pivotal technological trends are Cloud Native (CN), Generative AI (GenAI),\n",
      "and Physical AI. Cloud Native technology offers a scalable and dependable platform\n",
      "for application operation, while AI equips these applications with intelligent,\n",
      "human-like capabilities. Physical AI aims to bridge the gap between digital\n",
      "intelligence and physical capability, creating systems that can understand and\n",
      "interact with the world in a human-like manner. Our aim is to train you to excel as a\n",
      "Cloud Native Applied Generative and Physical AI developer globally.\n",
      "The Cloud Native Applied Generative AI Certification program equips you to create\n",
      "leading-edge Cloud Native AI and Physical AI solutions using a comprehensive\n",
      "cloud-native, AI, and Physical AI platform.\n",
      "Everything will soon be represented by a conversational interface, or to put it another\n",
      "way, a personal AI, we will cover it extensively in this program. () Currently, OpenAI\n",
      "Custom GPT Platform is the best platform to develop personal AI.\n",
      "\n",
      "We will also be covering AI agents, which are autonomous programs or entities that\n",
      "perceive their environment through sensors, process this information, and take\n",
      "actions to achieve specific goals or tasks. They can operate independently, adapt to\n",
      "changing conditions, and make decisions based on their observations and\n",
      "objectives.\n",
      "Material to Understand the Coming AI Age:\n",
      "●\n",
      "Watch the Overview Video of Our Program\n",
      "●\n",
      "Watch AGI could Double GDP\n",
      "●\n",
      "Watch Personal AI Short Video\n",
      "●\n",
      "The Future Is Agentic\n",
      "●\n",
      "The INSANE Race for AI Humanoid Robots\n",
      "●\n",
      "What Is an AI Anyway? Mustafa Suleyman\n",
      "●\n",
      "The Coming Wave: Technology, Power, and the 21st Century’s Greatest\n",
      "Dilemma\n",
      "●\n",
      "The Worlds I See: Curiosity, Exploration, and Discovery at the Dawn of AI\n",
      "●\n",
      "Ethan Mollick’s Substack\n",
      "●\n",
      "David Autor Lecture\n",
      "●\n",
      "Conversation between Suleyman, Yuval Noah Harari, and Zanny Minton\n",
      "Beddoes\n",
      "This twenty one month program equips you with the skills to thrive in the age of\n",
      "Generative AI (GenAI), Physical AI, and cloud native computing (CN). You will\n",
      "become an expert Custom GPT, AI Agent, and Humanoid Robotics Developer. The\n",
      "program is divided into two levels: foundation level and professional level. Students\n",
      "will be able to start working after completing the foundation level. They will\n",
      "continue their professional level studies while working.\n",
      "Why This Program?\n",
      "●\n",
      "Cutting-Edge Skills: Develop in-demand skills to build intelligent, scalable\n",
      "cloud applications using Generative AI and Cloud Native technologies.\n",
      "●\n",
      "Industry-Ready: Prepare for global certifications, startup and freelance\n",
      "opportunities after just six months.\n",
      "●\n",
      "Future-Proof Your Career: Stay ahead of the curve in a rapidly evolving tech\n",
      "landscape.\n",
      "What You'll Learn:\n",
      "●\n",
      "Custom GPTs and Multi AI Agent Systems: Learn to fine-tuning\n",
      "foundational AI models, and market them in GPT stores. Learn key principles\n",
      "of designing effective AI agents, and organising a team of AI agents to\n",
      "2\n",
      "\n",
      "perform complex, multi-step tasks. Apply these concepts to automate\n",
      "common business processes.\n",
      "●\n",
      "Develop AI Powered Microservices: Master Python, build APIs using\n",
      "FastAPI, SQLModel, Postgres, Kafka, Kong, and leverage cutting-edge GenAI\n",
      "APIs like OpenAI, and Open Source AI LLMs.\n",
      "●\n",
      "Cloud Native Expertise: Design and deploy cloud-native applications using\n",
      "Docker, DevContainers, TestContainers, Kubernetes, Terraform, and GitHub\n",
      "Actions.\n",
      "●\n",
      "Distributed System Design: Designing systems that run on multiple\n",
      "computers (or nodes) simultaneously, interacting and coordinating their\n",
      "actions by passing messages over a network.\n",
      "●\n",
      "Designing AI Solutions using Design Thinking and Behaviour Driven\n",
      "Development (BDD): We will learn to leverage these methodologies to create\n",
      "AI solutions that are not only technically sound but also highly user-centric\n",
      "and aligned with real-world needs.\n",
      "●\n",
      "Fine-Tuning Open-Source Large Language Models using PyTorch, and\n",
      "Fast AI: We will learn to fine-tuning of open-source Large Language Models\n",
      "(LLMs) like Meta LLaMA 3 using PyTorch and Fast AI, with a focus on\n",
      "cloud-native training and deployment. We will set up development\n",
      "environments, preprocess data, fine-tune models, and deploy them using\n",
      "cloud native platforms.\n",
      "●\n",
      "Physical AI and Humanoid Robotics: We will learn to design, simulate, and\n",
      "deploy advanced humanoid robots capable of natural interactions.\n",
      "Flexible Learning:\n",
      "●\n",
      "Earn While You Learn: Start freelancing or contributing to projects after the\n",
      "third quarter.\n",
      "Program Structure (Foundation: 3 + Professional: 4 = Total: 7 Quarters):\n",
      "Foundation Level (3 Quarters)\n",
      "●\n",
      "Quarter 1: Fundamentals of Prompt Engineering, Docker, GitHub, and\n",
      "Modern Python Programming\n",
      "We begin the course by understanding the basics of GenAI and Prompt\n",
      "Engineering. Then we will understand the basics of Linux, Docker, VSCode,\n",
      "Devcontainer, and GitHub. The main focus will be on mastering the\n",
      "fundamentals of Modern Python with Typing, the go-to language for AI.\n",
      "○\n",
      "Certification:\n",
      "■\n",
      "Certified Professional Python Programmer (CPPP1)\n",
      "3\n",
      "\n",
      "Learning Repo:\n",
      "https://github.com/panaversity/learn-cloud-native-modern-python\n",
      "●\n",
      "Quarter 2: Applied Generative AI Fundamentals: Prompt Engineering,\n",
      "Developing Custom GPTs and Multi AI Agent Systems\n",
      "With this course, you’ll start by building a strong understanding of generative\n",
      "AI and learn how to apply Large language models (LLMs) and diffusion\n",
      "models practically. We will introduce a set of principles known as prompt\n",
      "engineering, which will help developers to work efficiently with AI. Learn to\n",
      "create custom AI models and GPTs using OpenAI, Azure, and Google\n",
      "technologies. Use open source libraries, like Langchain, CrewAI, and\n",
      "LangGraph to automate repeatable, multi-step tasks and automate business\n",
      "processes that are typically done by a group of people.\n",
      "Certifications:\n",
      "■\n",
      "Microsoft Certified: Azure AI Engineer Associate\n",
      "■\n",
      "Certified crewAI Engineer\n",
      "Learning Repo:\n",
      "https://github.com/panaversity/learn-applied-generative-ai-fundamentals/\n",
      "●\n",
      "Quarter 3: Cloud Native AI Powered Microservices Design, Development,\n",
      "and Deployment:\n",
      "Build scalable AI Powered APIs using FastAPI, Postgres, Kafka, Kong, GenAI\n",
      "APIs like OpenAI Chat Completion APIs, Assistant APIs, LangChain and\n",
      "Open Source AI LLMs, develop them using Containers and Dev Containers,\n",
      "and deploy them using Docker Compose locally and Kubernetes Powered\n",
      "Serverless Container Services on the cloud.\n",
      "We will also learn to integrate design thinking and Behavior-Driven\n",
      "Development (BDD) in developing AI systems. We will learn to create AI\n",
      "solutions that are deeply aligned with user needs and expectations. Design\n",
      "thinking ensures a thorough understanding of the user and problem space,\n",
      "while BDD provides a structured approach to defining and validating the\n",
      "desired behaviours of the AI system. Together, these methodologies lead to\n",
      "the development of AI solutions that are not only technically robust but also\n",
      "highly user-centric and effective in solving real-world problems.\n",
      "○\n",
      "Certifications:\n",
      "■\n",
      "PostgreSQL 13 Associate Certification\n",
      "■\n",
      "Confluent Certified Developer for Apache Kafka (CCDAK)\n",
      "4\n",
      "\n",
      "■\n",
      "Design Thinking Professional Certificate (DTPC)\n",
      "■\n",
      "Test and Behavior Driven Development (TDD/BDD)\n",
      "Learning Repo:\n",
      "https://github.com/panaversity/learn-cloud-native-ai-powered-microservices/\n",
      "We Will Be Using Microsoft Azure as our Default Cloud Platform\n",
      "Amazon is still the cloud king based on market share. But many analysts\n",
      "agree: In the battle for the cloud, AI is now a game-changer — and Amazon's\n",
      "main competitors, particularly Microsoft, have the momentum.\n",
      "In our program we will be using Azure as our default provider for teaching and\n",
      "deployment. We will be using using these services:\n",
      "Get a free Azure Account now:\n",
      "https://azure.microsoft.com/en-us/free\n",
      "Note: Use GitHub Account to start an Azure free trial\n",
      "Azure Container Apps (We will Start from this service using Dapr and Keda)\n",
      "https://azure.microsoft.com/en-us/products/container-apps\n",
      "Get started with the free tier: The first 180,000 vCPU per second, 360,000\n",
      "GiB/s, and 2 million requests each month are free.\n",
      "Watch: https://www.youtube.com/watch?v=0HwQfsa03K8\n",
      "Deploy:\n",
      "https://learn.microsoft.com/en-us/azure/container-apps/code-to-cloud-options\n",
      "Azure Container Registry\n",
      "https://azure.microsoft.com/en-us/products/container-registry/\n",
      "Deploy to Azure Container Apps with GitHub Actions\n",
      "https://learn.microsoft.com/en-us/azure/container-apps/github-actions\n",
      "Azure Kubernetes Service (AKS)\n",
      "https://azure.microsoft.com/en-us/products/kubernetes-service\n",
      "GitHub\n",
      "https://azure.microsoft.com/en-us/products/github/\n",
      "GitHub Actions for AKS\n",
      "https://learn.microsoft.com/en-us/azure/aks/kubernetes-action\n",
      "5\n",
      "\n",
      "Azure OpenAI Service\n",
      "https://azure.microsoft.com/en-us/products/ai-services/openai-service\n",
      "Azure Database for PostgreSQL\n",
      "https://azure.microsoft.com/en-us/products/postgresql/\n",
      "Kafka\n",
      "https://cloudatlas.me/5-different-ways-you-can-run-apache-kafka-on-azure-97\n",
      "3a18925ac7\n",
      "Professional Level (4 Quarters)\n",
      "●\n",
      "Quarter 4: Generative AI with PyTorch:\n",
      "Generative AI tools like ChatGPT, Gemini, and DALL-E have revolutionised\n",
      "our professional landscape. This hands-on course, “Master Generative AI with\n",
      "PyTorch,” guides you through the exciting process of building and training AI\n",
      "models using Python and the versatile, open-source PyTorch framework, all\n",
      "with the hardware you already have. You’ll delve into the core concepts of\n",
      "Generative Adversarial Networks (GANs), Transformers, Large Language\n",
      "Models (LLMs), variational autoencoders, diffusion models, LangChain, and\n",
      "more. Along the way, you’ll gain practical experience and a deep\n",
      "understanding of these cutting-edge technologies.\n",
      "Learning Repo: https://github.com/panaversity/genai-with-pytorch\n",
      "●\n",
      "Quarter 5: Fine-Tuning Open-Source Large Language Models:\n",
      "This comprehensive course is designed to guide learners through the process\n",
      "of fine-tuning open-source Large Language Models (LLMs) such as Meta\n",
      "LLaMA 3 using PyTorch, with a particular emphasis on cloud-native training\n",
      "and deployment. The course covers everything from the fundamentals to\n",
      "advanced concepts, ensuring students acquire both theoretical knowledge\n",
      "and practical skills.\n",
      "The journey begins with an introduction to LLMs, focusing on their\n",
      "architecture, capabilities, and the specific features of Meta LLaMA 3. Next, the\n",
      "course dives into PyTorch fundamentals, teaching students how to perform\n",
      "basic operations with tensors and build simple neural networks. This\n",
      "6\n",
      "\n",
      "foundation is crucial for understanding the mechanics behind LLMs. Data\n",
      "preparation is a crucial aspect of training models. The course covers\n",
      "comprehensive data collection and preprocessing techniques, such as\n",
      "tokenization and text normalisation. These steps are essential for preparing\n",
      "datasets suitable for fine-tuning LLMs like Meta LLaMA 3. Through practical\n",
      "exercises, students learn how to handle and preprocess various types of text\n",
      "data, ensuring they can prepare their datasets for optimal model performance.\n",
      "Fine-tuning Meta LLaMA 3 with PyTorch forms a significant part of the course.\n",
      "Students will delve into the architecture of Meta LLaMA 3, learn how to load\n",
      "pre-trained models, and apply fine-tuning techniques. The course covers\n",
      "advanced topics such as regularisation and optimization strategies to\n",
      "enhance model performance. Practical sessions guide students through the\n",
      "entire fine-tuning process on custom datasets, emphasising best practices\n",
      "and troubleshooting techniques.\n",
      "A critical aspect of this course is its focus on cloud-native training and\n",
      "deployment using Nvidia NIM. Furthermore, students learn how to deploy\n",
      "models using Docker and Kubernetes, set up monitoring and maintenance\n",
      "tools, and ensure their models are scalable and efficient.\n",
      "To round off the learning experience, the course includes an in-depth segment\n",
      "on exporting models for inference and building robust inference pipelines.\n",
      "Students will deploy models on cloud platforms, focusing on practical aspects\n",
      "of setting up monitoring tools to maintain model performance and reliability.\n",
      "The course culminates in a capstone project, where students apply all the\n",
      "skills they have learned to fine-tune and deploy Meta LLaMA 3 on a chosen\n",
      "platform. This project allows students to demonstrate their understanding and\n",
      "proficiency in the entire process, from data preparation to cloud-native\n",
      "deployment.\n",
      "Learning Repo:\n",
      "https://github.com/panaversity/learn-fine-tuning-llms\n",
      "●\n",
      "Quarter 6: Physical AI and Humanoid Robotics Development:\n",
      "Artificial intelligence (AI) has experienced remarkable advancements in recent\n",
      "years. However, the future of AI extends beyond the digital space into the\n",
      "physical world, driven by robotics. This new frontier, known as “Physical AI,”\n",
      "involves AI systems that can function in the real world and comprehend\n",
      "physical laws. This marks a notable transition from AI models confined to\n",
      "digital environments. Humanoid robots are poised to excel in our\n",
      "7\n",
      "\n",
      "human-centred world because they share our physical form and can be\n",
      "trained with abundant data from interacting in human environments.\n",
      "This course provides an in-depth exploration of humanoid robotics, focusing\n",
      "on the integration of ROS 2 (Robot Operating System), Open Source Meta\n",
      "Llama 3, and OpenAI technologies. Students will learn to design, simulate,\n",
      "and deploy advanced humanoid robots capable of natural interactions. The\n",
      "curriculum covers essential topics such as ROS 2 for robotic control,\n",
      "simulations with Gazebo and Unity, and using OpenAI’s GPT models for\n",
      "conversational AI. Through practical projects and real-world applications,\n",
      "students will develop the skills needed to drive innovation in humanoid\n",
      "robotics.\n",
      "Learning Repo:\n",
      "https://github.com/panaversity/learn-physical-ai-humanoid-robotics\n",
      "●\n",
      "Quarter 7: Kubernetes and Distributed System Design:\n",
      "Master Kubernetes, Terraform, and GitHub Actions to deploy your AI APIs and\n",
      "microservices in the cloud. We will cover distributed system design involving\n",
      "creating systems that are distributed across multiple nodes, focusing on\n",
      "scalability, fault tolerance, consistency, availability, and partition tolerance.\n",
      "Certifications:\n",
      "■\n",
      "Certified Kubernetes Application Developer (CKAD)\n",
      "■\n",
      "HashiCorp Certified: Terraform Associate\n",
      "Learning Repo: https://github.com/panaversity/learn-kubernetes\n",
      "Frontend Specialisation\n",
      "●\n",
      "Quarter 8: Front-end Web GUI Development using Next.js and\n",
      "TypeScript (Optional):\n",
      "Next.js is designed to handle complex front-end applications well, making it a\n",
      "good fit for AI applications that might grow in features and data usage over\n",
      "time. Next.js offers features like API routes and file-based routing, which can\n",
      "streamline development for AI applications that need to interact with backend\n",
      "APIs and manage different application views. While Next.js and TypeScript\n",
      "8\n",
      "\n",
      "aren't the only options for building AI application frontends, their focus on\n",
      "performance, scalability, and developer experience makes them a compelling\n",
      "choice for many developers.\n",
      "Learning Repo:\n",
      "https://github.com/panaverse/learn-nextjs\n",
      "9\n",
      "\n",
      "In 2015, Klaus Schwab, founder of the World Economic Forum, asserted that we\n",
      "were on the brink of a “Fourth Industrial Revolution,” one powered by a fusion of\n",
      "technologies, such as advanced robotics, artificial intelligence, and the Internet of\n",
      "Things.\n",
      "“[This revolution] will fundamentally alter the way we live, work, and relate to one\n",
      "another,” wrote Schwab in an essay published in Foreign Affairs. “In its scale, scope,\n",
      "and complexity, the transformation will be unlike anything humankind has\n",
      "experienced before.”\n",
      "Generative AI is set to revolutionise our daily lives and work environments.\n",
      "According to McKinsey & Company, generative AI could contribute an annual\n",
      "economic value of $2.6 trillion to $4.4 trillion across various sectors by enhancing\n",
      "automation, bolstering decision-making, and providing personalised experiences.\n",
      "Investor Cathie Wood predicts that the market for humanoid robots could grow to $1\n",
      "trillion by 2030.\n",
      "Cloud native is an approach in software development that enables application\n",
      "creation, deployment, and management in cloud environments. It involves\n",
      "constructing applications as a collection of small, interconnected services known as\n",
      "microservices, a shift from traditional monolithic structures. This modular approach\n",
      "enhances the agility of cloud-native applications, allowing them to operate more\n",
      "efficiently with fewer resources.\n",
      "Cloud Native has already been adopted by the majority of the companies, by 2024,\n",
      "more than 90% of global organisations will be running containerized applications in\n",
      "production. The adoption of Docker and Kubernetes has seen significant growth over\n",
      "recent years. As of 2022, about 61% of organisations reported using Kubernetes for\n",
      "container orchestration. This number has been steadily increasing as more\n",
      "companies realise the benefits of these technologies for managing containerized\n",
      "applications ￼￼.\n",
      "Technologies such as Kubernetes, Docker, serverless containers, APIs, SQL\n",
      "Databases, and Kafka support developers in swiftly constructing cloud-native\n",
      "applications. These tools offer a standardised platform for application development\n",
      "and management across various cloud services like Azure, Google Cloud, and AWS.\n",
      "This revolution is pivotal for technology and job landscapes, making it essential\n",
      "knowledge in fast-evolving tech cycles. The rapid emergence of Gen AI-powered\n",
      "and Physical AI technologies, and the evolving demand for skills necessitate\n",
      "extensive and timely professional training.\n",
      "10\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"## Certified Cloud Native Applied Generative AI Engineer: Master the Future\\n\\nThis 21-month program trains you to become a leading-edge Cloud Native Generative and Physical AI developer. It equips you with skills to thrive in the future of AI and cloud computing, covering topics like custom GPTs, AI agents, and humanoid robotics.\\n\\n**Key Features:**\\n\\n* **Cutting-edge skills:** Develop in-demand skills using GenAI and cloud-native technologies.\\n* **Industry-ready:** Prepare for global certifications and freelance opportunities in just six months.\\n* **Future-proof your career:** Stay ahead of the curve in the rapidly evolving tech landscape.\\n\\n**Program Structure:**\\n\\n* **Foundation Level (3 Quarters):** Covers fundamentals of prompt engineering, Docker, GitHub, modern Python programming, applied Generative AI, building custom GPTs and multi AI agent systems, and cloud-native AI-powered microservices design, development, and deployment.\\n* **Professional Level (4 Quarters):** Focuses on Generative AI with PyTorch, fine-tuning open-source LLMs, Physical AI and Humanoid Robotics, Kubernetes and distributed system design, and optional front-end development using Next.js and TypeScript.\\n\\n**Why This Program?**\\n\\n* **Generative AI is transforming the world:**  It's expected to contribute trillions of dollars to the economy.\\n* **Cloud-native is the future of software development:**  Over 90% of global organizations will be running containerized applications in production by 2024.\\n* **This program provides the skills needed to succeed in this rapidly evolving landscape.**\\n\\n**This program is designed to prepare you for a successful career in the exciting world of AI and cloud computing.** \\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "chain = load_summarize_chain(llm=llm, chain_type=\"stuff\", prompt=prompt, verbose=True)\n",
    "summary = chain.run(doc_pages[:10])  # first 10 document chunks\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Map Reduce Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 0, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"Certified Cloud Native Applied\\nGenerative AI Engineer\\nMaster the Future\\nBuild Custom GPTs, AI Agents, Humanoids, and Fine-Tune LLMs\\nVersion: 12.5 (Implementation and adoption starting from August 1, 2024)\\nToday's pivotal technological trends are Cloud Native (CN), Generative AI (GenAI),\\nand Physical AI. Cloud Native technology offers a scalable and dependable platform\\nfor application operation, while AI equips these applications with intelligent,\\nhuman-like capabilities. Physical AI aims to bridge the gap between digital\\nintelligence and physical capability, creating systems that can understand and\\ninteract with the world in a human-like manner. Our aim is to train you to excel as a\\nCloud Native Applied Generative and Physical AI developer globally.\\nThe Cloud Native Applied Generative AI Certification program equips you to create\\nleading-edge Cloud Native AI and Physical AI solutions using a comprehensive\\ncloud-native, AI, and Physical AI platform.\\nEverything will soon be represented by a conversational interface, or to put it another\\nway, a personal AI, we will cover it extensively in this program. () Currently, OpenAI\\nCustom GPT Platform is the best platform to develop personal AI.\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 1, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"We will also be covering AI agents, which are autonomous programs or entities that\\nperceive their environment through sensors, process this information, and take\\nactions to achieve specific goals or tasks. They can operate independently, adapt to\\nchanging conditions, and make decisions based on their observations and\\nobjectives.\\nMaterial to Understand the Coming AI Age:\\n●\\nWatch the Overview Video of Our Program\\n●\\nWatch AGI could Double GDP\\n●\\nWatch Personal AI Short Video\\n●\\nThe Future Is Agentic\\n●\\nThe INSANE Race for AI Humanoid Robots\\n●\\nWhat Is an AI Anyway? Mustafa Suleyman\\n●\\nThe Coming Wave: Technology, Power, and the 21st Century’s Greatest\\nDilemma\\n●\\nThe Worlds I See: Curiosity, Exploration, and Discovery at the Dawn of AI\\n●\\nEthan Mollick’s Substack\\n●\\nDavid Autor Lecture\\n●\\nConversation between Suleyman, Yuval Noah Harari, and Zanny Minton\\nBeddoes\\nThis twenty one month program equips you with the skills to thrive in the age of\\nGenerative AI (GenAI), Physical AI, and cloud native computing (CN). You will\\nbecome an expert Custom GPT, AI Agent, and Humanoid Robotics Developer. The\\nprogram is divided into two levels: foundation level and professional level. Students\\nwill be able to start working after completing the foundation level. They will\\ncontinue their professional level studies while working.\\nWhy This Program?\\n●\\nCutting-Edge Skills: Develop in-demand skills to build intelligent, scalable\\ncloud applications using Generative AI and Cloud Native technologies.\\n●\\nIndustry-Ready: Prepare for global certifications, startup and freelance\\nopportunities after just six months.\\n●\\nFuture-Proof Your Career: Stay ahead of the curve in a rapidly evolving tech\\nlandscape.\\nWhat You'll Learn:\\n●\\nCustom GPTs and Multi AI Agent Systems: Learn to fine-tuning\\nfoundational AI models, and market them in GPT stores. Learn key principles\\nof designing effective AI agents, and organising a team of AI agents to\\n2\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 2, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='perform complex, multi-step tasks. Apply these concepts to automate\\ncommon business processes.\\n●\\nDevelop AI Powered Microservices: Master Python, build APIs using\\nFastAPI, SQLModel, Postgres, Kafka, Kong, and leverage cutting-edge GenAI\\nAPIs like OpenAI, and Open Source AI LLMs.\\n●\\nCloud Native Expertise: Design and deploy cloud-native applications using\\nDocker, DevContainers, TestContainers, Kubernetes, Terraform, and GitHub\\nActions.\\n●\\nDistributed System Design: Designing systems that run on multiple\\ncomputers (or nodes) simultaneously, interacting and coordinating their\\nactions by passing messages over a network.\\n●\\nDesigning AI Solutions using Design Thinking and Behaviour Driven\\nDevelopment (BDD): We will learn to leverage these methodologies to create\\nAI solutions that are not only technically sound but also highly user-centric\\nand aligned with real-world needs.\\n●\\nFine-Tuning Open-Source Large Language Models using PyTorch, and\\nFast AI: We will learn to fine-tuning of open-source Large Language Models\\n(LLMs) like Meta LLaMA 3 using PyTorch and Fast AI, with a focus on\\ncloud-native training and deployment. We will set up development\\nenvironments, preprocess data, fine-tune models, and deploy them using\\ncloud native platforms.\\n●\\nPhysical AI and Humanoid Robotics: We will learn to design, simulate, and\\ndeploy advanced humanoid robots capable of natural interactions.\\nFlexible Learning:\\n●\\nEarn While You Learn: Start freelancing or contributing to projects after the\\nthird quarter.\\nProgram Structure (Foundation: 3 + Professional: 4 = Total: 7 Quarters):\\nFoundation Level (3 Quarters)\\n●\\nQuarter 1: Fundamentals of Prompt Engineering, Docker, GitHub, and\\nModern Python Programming\\nWe begin the course by understanding the basics of GenAI and Prompt\\nEngineering. Then we will understand the basics of Linux, Docker, VSCode,\\nDevcontainer, and GitHub. The main focus will be on mastering the\\nfundamentals of Modern Python with Typing, the go-to language for AI.\\n○\\nCertification:\\n■'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 2, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='We begin the course by understanding the basics of GenAI and Prompt\\nEngineering. Then we will understand the basics of Linux, Docker, VSCode,\\nDevcontainer, and GitHub. The main focus will be on mastering the\\nfundamentals of Modern Python with Typing, the go-to language for AI.\\n○\\nCertification:\\n■\\nCertified Professional Python Programmer (CPPP1)\\n3'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 3, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='Learning Repo:\\nhttps://github.com/panaversity/learn-cloud-native-modern-python\\n●\\nQuarter 2: Applied Generative AI Fundamentals: Prompt Engineering,\\nDeveloping Custom GPTs and Multi AI Agent Systems\\nWith this course, you’ll start by building a strong understanding of generative\\nAI and learn how to apply Large language models (LLMs) and diffusion\\nmodels practically. We will introduce a set of principles known as prompt\\nengineering, which will help developers to work efficiently with AI. Learn to\\ncreate custom AI models and GPTs using OpenAI, Azure, and Google\\ntechnologies. Use open source libraries, like Langchain, CrewAI, and\\nLangGraph to automate repeatable, multi-step tasks and automate business\\nprocesses that are typically done by a group of people.\\nCertifications:\\n■\\nMicrosoft Certified: Azure AI Engineer Associate\\n■\\nCertified crewAI Engineer\\nLearning Repo:\\nhttps://github.com/panaversity/learn-applied-generative-ai-fundamentals/\\n●\\nQuarter 3: Cloud Native AI Powered Microservices Design, Development,\\nand Deployment:\\nBuild scalable AI Powered APIs using FastAPI, Postgres, Kafka, Kong, GenAI\\nAPIs like OpenAI Chat Completion APIs, Assistant APIs, LangChain and\\nOpen Source AI LLMs, develop them using Containers and Dev Containers,\\nand deploy them using Docker Compose locally and Kubernetes Powered\\nServerless Container Services on the cloud.\\nWe will also learn to integrate design thinking and Behavior-Driven\\nDevelopment (BDD) in developing AI systems. We will learn to create AI\\nsolutions that are deeply aligned with user needs and expectations. Design\\nthinking ensures a thorough understanding of the user and problem space,\\nwhile BDD provides a structured approach to defining and validating the\\ndesired behaviours of the AI system. Together, these methodologies lead to\\nthe development of AI solutions that are not only technically robust but also\\nhighly user-centric and effective in solving real-world problems.\\n○\\nCertifications:\\n■\\nPostgreSQL 13 Associate Certification\\n■'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 3, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='desired behaviours of the AI system. Together, these methodologies lead to\\nthe development of AI solutions that are not only technically robust but also\\nhighly user-centric and effective in solving real-world problems.\\n○\\nCertifications:\\n■\\nPostgreSQL 13 Associate Certification\\n■\\nConfluent Certified Developer for Apache Kafka (CCDAK)\\n4'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 4, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"■\\nDesign Thinking Professional Certificate (DTPC)\\n■\\nTest and Behavior Driven Development (TDD/BDD)\\nLearning Repo:\\nhttps://github.com/panaversity/learn-cloud-native-ai-powered-microservices/\\nWe Will Be Using Microsoft Azure as our Default Cloud Platform\\nAmazon is still the cloud king based on market share. But many analysts\\nagree: In the battle for the cloud, AI is now a game-changer — and Amazon's\\nmain competitors, particularly Microsoft, have the momentum.\\nIn our program we will be using Azure as our default provider for teaching and\\ndeployment. We will be using using these services:\\nGet a free Azure Account now:\\nhttps://azure.microsoft.com/en-us/free\\nNote: Use GitHub Account to start an Azure free trial\\nAzure Container Apps (We will Start from this service using Dapr and Keda)\\nhttps://azure.microsoft.com/en-us/products/container-apps\\nGet started with the free tier: The first 180,000 vCPU per second, 360,000\\nGiB/s, and 2 million requests each month are free.\\nWatch: https://www.youtube.com/watch?v=0HwQfsa03K8\\nDeploy:\\nhttps://learn.microsoft.com/en-us/azure/container-apps/code-to-cloud-options\\nAzure Container Registry\\nhttps://azure.microsoft.com/en-us/products/container-registry/\\nDeploy to Azure Container Apps with GitHub Actions\\nhttps://learn.microsoft.com/en-us/azure/container-apps/github-actions\\nAzure Kubernetes Service (AKS)\\nhttps://azure.microsoft.com/en-us/products/kubernetes-service\\nGitHub\\nhttps://azure.microsoft.com/en-us/products/github/\\nGitHub Actions for AKS\\nhttps://learn.microsoft.com/en-us/azure/aks/kubernetes-action\\n5\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 5, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='Azure OpenAI Service\\nhttps://azure.microsoft.com/en-us/products/ai-services/openai-service\\nAzure Database for PostgreSQL\\nhttps://azure.microsoft.com/en-us/products/postgresql/\\nKafka\\nhttps://cloudatlas.me/5-different-ways-you-can-run-apache-kafka-on-azure-97\\n3a18925ac7\\nProfessional Level (4 Quarters)\\n●\\nQuarter 4: Generative AI with PyTorch:\\nGenerative AI tools like ChatGPT, Gemini, and DALL-E have revolutionised\\nour professional landscape. This hands-on course, “Master Generative AI with\\nPyTorch,” guides you through the exciting process of building and training AI\\nmodels using Python and the versatile, open-source PyTorch framework, all\\nwith the hardware you already have. You’ll delve into the core concepts of\\nGenerative Adversarial Networks (GANs), Transformers, Large Language\\nModels (LLMs), variational autoencoders, diffusion models, LangChain, and\\nmore. Along the way, you’ll gain practical experience and a deep\\nunderstanding of these cutting-edge technologies.\\nLearning Repo: https://github.com/panaversity/genai-with-pytorch\\n●\\nQuarter 5: Fine-Tuning Open-Source Large Language Models:\\nThis comprehensive course is designed to guide learners through the process\\nof fine-tuning open-source Large Language Models (LLMs) such as Meta\\nLLaMA 3 using PyTorch, with a particular emphasis on cloud-native training\\nand deployment. The course covers everything from the fundamentals to\\nadvanced concepts, ensuring students acquire both theoretical knowledge\\nand practical skills.\\nThe journey begins with an introduction to LLMs, focusing on their\\narchitecture, capabilities, and the specific features of Meta LLaMA 3. Next, the\\ncourse dives into PyTorch fundamentals, teaching students how to perform\\nbasic operations with tensors and build simple neural networks. This\\n6'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 6, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='foundation is crucial for understanding the mechanics behind LLMs. Data\\npreparation is a crucial aspect of training models. The course covers\\ncomprehensive data collection and preprocessing techniques, such as\\ntokenization and text normalisation. These steps are essential for preparing\\ndatasets suitable for fine-tuning LLMs like Meta LLaMA 3. Through practical\\nexercises, students learn how to handle and preprocess various types of text\\ndata, ensuring they can prepare their datasets for optimal model performance.\\nFine-tuning Meta LLaMA 3 with PyTorch forms a significant part of the course.\\nStudents will delve into the architecture of Meta LLaMA 3, learn how to load\\npre-trained models, and apply fine-tuning techniques. The course covers\\nadvanced topics such as regularisation and optimization strategies to\\nenhance model performance. Practical sessions guide students through the\\nentire fine-tuning process on custom datasets, emphasising best practices\\nand troubleshooting techniques.\\nA critical aspect of this course is its focus on cloud-native training and\\ndeployment using Nvidia NIM. Furthermore, students learn how to deploy\\nmodels using Docker and Kubernetes, set up monitoring and maintenance\\ntools, and ensure their models are scalable and efficient.\\nTo round off the learning experience, the course includes an in-depth segment\\non exporting models for inference and building robust inference pipelines.\\nStudents will deploy models on cloud platforms, focusing on practical aspects\\nof setting up monitoring tools to maintain model performance and reliability.\\nThe course culminates in a capstone project, where students apply all the\\nskills they have learned to fine-tune and deploy Meta LLaMA 3 on a chosen\\nplatform. This project allows students to demonstrate their understanding and\\nproficiency in the entire process, from data preparation to cloud-native\\ndeployment.\\nLearning Repo:\\nhttps://github.com/panaversity/learn-fine-tuning-llms\\n●'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 6, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='platform. This project allows students to demonstrate their understanding and\\nproficiency in the entire process, from data preparation to cloud-native\\ndeployment.\\nLearning Repo:\\nhttps://github.com/panaversity/learn-fine-tuning-llms\\n●\\nQuarter 6: Physical AI and Humanoid Robotics Development:\\nArtificial intelligence (AI) has experienced remarkable advancements in recent\\nyears. However, the future of AI extends beyond the digital space into the\\nphysical world, driven by robotics. This new frontier, known as “Physical AI,”\\ninvolves AI systems that can function in the real world and comprehend\\nphysical laws. This marks a notable transition from AI models confined to\\ndigital environments. Humanoid robots are poised to excel in our\\n7'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 7, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='human-centred world because they share our physical form and can be\\ntrained with abundant data from interacting in human environments.\\nThis course provides an in-depth exploration of humanoid robotics, focusing\\non the integration of ROS 2 (Robot Operating System), Open Source Meta\\nLlama 3, and OpenAI technologies. Students will learn to design, simulate,\\nand deploy advanced humanoid robots capable of natural interactions. The\\ncurriculum covers essential topics such as ROS 2 for robotic control,\\nsimulations with Gazebo and Unity, and using OpenAI’s GPT models for\\nconversational AI. Through practical projects and real-world applications,\\nstudents will develop the skills needed to drive innovation in humanoid\\nrobotics.\\nLearning Repo:\\nhttps://github.com/panaversity/learn-physical-ai-humanoid-robotics\\n●\\nQuarter 7: Kubernetes and Distributed System Design:\\nMaster Kubernetes, Terraform, and GitHub Actions to deploy your AI APIs and\\nmicroservices in the cloud. We will cover distributed system design involving\\ncreating systems that are distributed across multiple nodes, focusing on\\nscalability, fault tolerance, consistency, availability, and partition tolerance.\\nCertifications:\\n■\\nCertified Kubernetes Application Developer (CKAD)\\n■\\nHashiCorp Certified: Terraform Associate\\nLearning Repo: https://github.com/panaversity/learn-kubernetes\\nFrontend Specialisation\\n●\\nQuarter 8: Front-end Web GUI Development using Next.js and\\nTypeScript (Optional):\\nNext.js is designed to handle complex front-end applications well, making it a\\ngood fit for AI applications that might grow in features and data usage over\\ntime. Next.js offers features like API routes and file-based routing, which can\\nstreamline development for AI applications that need to interact with backend\\nAPIs and manage different application views. While Next.js and TypeScript\\n8'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 8, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"aren't the only options for building AI application frontends, their focus on\\nperformance, scalability, and developer experience makes them a compelling\\nchoice for many developers.\\nLearning Repo:\\nhttps://github.com/panaverse/learn-nextjs\\n9\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 9, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='In 2015, Klaus Schwab, founder of the World Economic Forum, asserted that we\\nwere on the brink of a “Fourth Industrial Revolution,” one powered by a fusion of\\ntechnologies, such as advanced robotics, artificial intelligence, and the Internet of\\nThings.\\n“[This revolution] will fundamentally alter the way we live, work, and relate to one\\nanother,” wrote Schwab in an essay published in Foreign Affairs. “In its scale, scope,\\nand complexity, the transformation will be unlike anything humankind has\\nexperienced before.”\\nGenerative AI is set to revolutionise our daily lives and work environments.\\nAccording to McKinsey & Company, generative AI could contribute an annual\\neconomic value of $2.6 trillion to $4.4 trillion across various sectors by enhancing\\nautomation, bolstering decision-making, and providing personalised experiences.\\nInvestor Cathie Wood predicts that the market for humanoid robots could grow to $1\\ntrillion by 2030.\\nCloud native is an approach in software development that enables application\\ncreation, deployment, and management in cloud environments. It involves\\nconstructing applications as a collection of small, interconnected services known as\\nmicroservices, a shift from traditional monolithic structures. This modular approach\\nenhances the agility of cloud-native applications, allowing them to operate more\\nefficiently with fewer resources.\\nCloud Native has already been adopted by the majority of the companies, by 2024,\\nmore than 90% of global organisations will be running containerized applications in\\nproduction. The adoption of Docker and Kubernetes has seen significant growth over\\nrecent years. As of 2022, about 61% of organisations reported using Kubernetes for\\ncontainer orchestration. This number has been steadily increasing as more\\ncompanies realise the benefits of these technologies for managing containerized\\napplications ￼￼.\\nTechnologies such as Kubernetes, Docker, serverless containers, APIs, SQL'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 9, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='container orchestration. This number has been steadily increasing as more\\ncompanies realise the benefits of these technologies for managing containerized\\napplications ￼￼.\\nTechnologies such as Kubernetes, Docker, serverless containers, APIs, SQL\\nDatabases, and Kafka support developers in swiftly constructing cloud-native\\napplications. These tools offer a standardised platform for application development\\nand management across various cloud services like Azure, Google Cloud, and AWS.\\nThis revolution is pivotal for technology and job landscapes, making it essential\\nknowledge in fast-evolving tech cycles. The rapid emergence of Gen AI-powered\\nand Physical AI technologies, and the evolving demand for skills necessitate\\nextensive and timely professional training.\\n10'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 10, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='Vertical Specialization Level\\nStudents will have the option of selecting one of the following specialisations after\\nthe completion of sixth quarter i.e. in the seventh quarter:\\n1. Healthcare and Medical GenAI Specialization\\n2. Web3, Blockchain, and GenAI Integration Specialization\\n3. Metaverse, 3D, and GenAI Integration Specialization\\n4. GenAI for Accounting, Finance, and Banking Specialization\\n5. GenAI for Engineers Specialization\\n6. GenAI for Sales and Marketing Specialization\\n7. GenAI for Automation and Internet of Things (IoT) Specialisation\\n8. GenAI for Cyber Security\\nCommon Questions (FAQs) with Detailed Answers\\n1. What is Cloud Native Applied Generative AI Engineering?\\nCloud Applied Generative AI Engineering (GenEng) is the application of\\ngenerative AI technologies to solve real-world problems in the cloud.\\n●\\nGenerative AI is a type of artificial intelligence that can create new data\\nor content from existing data.\\n●\\nCloud Native computing is the delivery of computing\\nservices—including servers, storage, databases, networking, software,\\nanalytics, and intelligence—over the Internet (“the cloud”).\\nBy combining generative AI with cloud native computing, businesses can\\nsolve a variety of problems, such as:\\n●\\nCreating personalised experiences for customers\\n●\\nAutomating tasks\\n●\\nImproving decision-making\\n●\\nDetecting fraud\\n●\\nDeveloping new products and services\\nThe potential applications of cloud native-applied generative AI are endless.\\nAs generative AI and cloud native computing continue to develop, we can\\nexpect to see even more innovative and groundbreaking uses for this\\ntechnology.\\n2. How valuable are the Cloud Native Applied Generative AI developers?\\nDevelopers with expertise in Cloud Native Applied Generative AI were in\\nextremely high demand due to the increasing adoption of GenAI technologies\\nacross various industries. However, the supply of developers skilled\\n11'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 11, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='specifically in this niche area might not have been as abundant compared to\\nmore generalised AI or cloud computing roles.\\nThe demand for AI developers, especially those proficient in applying\\ngenerative AI techniques within cloud native environments, has been rising\\ndue to the growing interest in using AI for creative applications, content\\ngeneration, image synthesis, natural language processing, and other\\ninnovative purposes.\\nAccording to some sources, the average salary for a Cloud Native Applied\\nGenerative AI developer in the global market is around $150,000 per year.\\nHowever, this may vary depending on the experience level, industry, location,\\nand skills of the developer. For example, a senior Cloud Applied Generative\\nAI developer with more than five years of experience can earn up to $200,000\\nper year. A Cloud Applied Generative AI developer working in the financial\\nservices industry can earn more than a developer working in the\\nentertainment industry. A Cloud Applied Generative AI developer working in\\nNew York City can earn more than a developer working in Dubai. In general,\\nhighly skilled AI developers, especially those specialising in applied\\ngenerative AI within cloud environments, tend to earn competitive salaries that\\nare often above the average for software developers or AI engineers due to\\nthe specialised nature of their skills. Moreover, as generative AI technology\\nbecomes more widely adopted and integrated into various products and\\nservices, the demand for Cloud Applied Generative AI developers is likely to\\nincrease.\\nTherefore, Cloud Applied Generative AI developers are valuable professionals\\nwho have a bright future ahead of them. They can leverage their creativity and\\ntechnical skills to create innovative solutions that can benefit various\\nindustries and domains. They can also enjoy very competitive salary and\\ncareer growth opportunities.\\n3. What is the potential for Cloud Applied Generative AI Developers to start\\ntheir own companies?'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 11, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='technical skills to create innovative solutions that can benefit various\\nindustries and domains. They can also enjoy very competitive salary and\\ncareer growth opportunities.\\n3. What is the potential for Cloud Applied Generative AI Developers to start\\ntheir own companies?\\nCloud Applied Generative AI Developers have a significant potential to start\\ntheir own companies due to several factors:\\n1. Emerging Field: Generative AI, particularly when applied within cloud\\nenvironments, is still an evolving field with immense potential for innovation.\\nDevelopers who understand the intricacies of both generative AI techniques\\nand cloud technologies can identify unique opportunities to create novel\\nproducts, services, or solutions.\\n2. Market Demand: There is a growing demand for AI-driven applications,\\nespecially those that involve generative capabilities such as image\\n12'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 12, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"generation, content creation, style transfer, etc. Developers with expertise in\\nthis area can leverage this demand to create specialized products that cater\\nto specific industries or consumer needs.\\n3. Innovation and Differentiation: The ability to develop unique and innovative\\nsolutions using generative AI in the cloud can set apart these developers'\\nstartups from more conventional companies. They can explore new ways of\\ngenerating content, enhancing user experiences, or solving complex problems\\nwith AI-generated solutions.\\n4. Access to Cloud Resources: Cloud platforms provide scalable and\\ncost-effective resources that are crucial for AI development. Developers\\nstarting their own companies can leverage cloud services to access powerful\\ncomputing resources, storage, and AI-related services without significant\\nupfront investment.\\n5. Entrepreneurial Opportunities: Developers with entrepreneurial spirit and a\\ndeep understanding of AI technologies can identify gaps in the market and\\nbuild startups to fill those gaps. They can create platforms, tools, or services\\nthat simplify the adoption of generative AI for businesses or developers.\\n6. Collaboration and Partnerships: These developers can collaborate with\\nother experts in AI, domain specialists, or businesses to create innovative\\nsolutions or explore new application areas for generative AI in the cloud.\\nHowever, starting a company, especially in a specialised field like Cloud\\nApplied Generative AI, requires more than technical expertise. It also\\ndemands business acumen, understanding market needs, networking,\\nsecuring funding, managing resources effectively, and navigating legal and\\nregulatory landscapes.\\nSuccessful entrepreneurship in this domain involves a combination of\\ntechnical skills, innovation, a deep understanding of market dynamics, and the\\nability to transform technical expertise into viable products or services that\\naddress real-world challenges or opportunities.\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 12, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='regulatory landscapes.\\nSuccessful entrepreneurship in this domain involves a combination of\\ntechnical skills, innovation, a deep understanding of market dynamics, and the\\nability to transform technical expertise into viable products or services that\\naddress real-world challenges or opportunities.\\nDevelopers aspiring to start their own companies in the Cloud Applied\\nGenerative AI space can do so by conducting thorough market research,\\nnetworking with industry experts, building a strong team, and developing a\\nclear business plan that highlights the unique value proposition of their\\nofferings.\\nTo sum up, the potential for Cloud Applied Generative AI Developers to start\\ntheir own companies is high.\\n●\\nGenerative AI is a rapidly growing field with a high demand for skilled\\nprofessionals.\\n13'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 13, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"●\\nThe Certified Generative AI (GenEng) Developer and Engineering\\nProgram provides students with the skills and knowledge they need to\\ndevelop and apply cutting-edge generative AI technologies.\\n●\\nThe program also teaches students how to start and run a successful\\nbusiness.\\n●\\nGraduates of the program will be well-positioned to start their own\\ncompanies and capitalise on the growing demand for generative AI\\nsolutions.\\n4. Is the program not too long, twenty one months is a long time?\\nThe length of the program is twenty one months which is broken down into\\nseven quarters of three months each. The program covers a wide range of\\ntopics including Python, GenAI, Microservices, Database, Cloud\\nDevelopment, Fine-tuning, DevOps, GPTs, AI Agents, and Humanoids. The\\nprogram is designed to give students a comprehensive understanding of\\ngenerative AI and prepare them for careers in this field. Nothing valuable can\\nbe achieved overnight, there are no shortcuts in life.\\n5. Why don't we use TypeScript (Node.js) to develop APIs instead of using\\nPython?\\nWe will not use Typescript in GenAI API development because Python is a\\npriority with the AI community when working with AI and if any updates come\\nin libraries they will first come for Python. Python is always a better choice\\nwhen dealing with AI and API.\\n●\\nPython is the de facto standard for AI Development.\\n●\\nTypeScript is a more modern language that is gaining popularity for\\nWeb Development, but Python is more widely used and has a larger\\necosystem of libraries and frameworks available, especially for AI.\\n●\\nTypeScript is used for web user interfaces, while Python is used for\\nAPIs.\\n●\\nIn the second quarter, students will learn to develop APIs using Python\\ninstead of TypeScript.\\n●\\nPython is a more commonly used language for AI and API\\ndevelopment, and it has a larger ecosystem of libraries and\\nframeworks available for these purposes.\\n●\\nTypeScript is a more modern language that is becoming increasingly\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 13, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='instead of TypeScript.\\n●\\nPython is a more commonly used language for AI and API\\ndevelopment, and it has a larger ecosystem of libraries and\\nframeworks available for these purposes.\\n●\\nTypeScript is a more modern language that is becoming increasingly\\npopular for API development also, but it is still not as widely used as\\nPython, especially for AI applications and development.\\n6. What is the difference between OpenAI Completion API, OpenAI\\nAssistant API, Google Gemini Multi-Modal API, and LangChain?\\n14'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 14, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"The difference between OpenAI Completion API, OpenAI Assistant API,\\nGoogle Gemini Multi-Modal API, and LangChain is that they are different\\nways of using artificial intelligence to generate text, images, audio, and video\\nbased on some input, but they have different features and applications. Here\\nis a summary of each one:\\nOpenAI Completion API is the most fundamental OpenAI model that\\nprovides a simple interface that’s extremely flexible and powerful. You give it a\\nprompt and it returns a text completion, generated according to your\\ninstructions. You can think of it as a very advanced autocomplete where the\\nlanguage model processes your text prompt and tries to predict what’s most\\nlikely to come next. The Completion API can be used for various tasks such\\nas writing stories, poems, essays, code, lyrics, etc. It also supports different\\nmodels with different levels of power suitable for different tasks.\\nOpenAI Assistant API is an interface to OpenAI's most capable model\\n(gpt-4) and their most cost-effective model (gpt-3.5-turbo). It provides a simple\\nway to take text as input and use a model like gpt-4 or gpt-3.5-turbo to\\ngenerate an output. The Assistant API allows you to build AI assistants within\\nyour applications. An Assistant has instructions and can leverage models,\\ntools, and knowledge to respond to user queries. The Assistant API currently\\nsupports three types of tools: Code Interpreter, Retrieval, and Function calling.\\nGoogle Gemini Multi-Modal API is a new series of foundational models built\\nand introduced by Google. It is built with a focus on multimodality from the\\nground up. This makes the Gemini models powerful against different\\ncombinations of information types including text, images, audio, and video.\\nCurrently, the API supports images and text. Gemini has proven by reaching\\nstate-of-the-art performance on the benchmarks and even beating the\\nChatGPT and the GPT4-Vision models in many of the tests.\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 14, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='combinations of information types including text, images, audio, and video.\\nCurrently, the API supports images and text. Gemini has proven by reaching\\nstate-of-the-art performance on the benchmarks and even beating the\\nChatGPT and the GPT4-Vision models in many of the tests.\\nThere are three different Gemini models based on their size, the Gemini Ultra,\\nGemini Pro, and Gemini Nano in decreasing order of their size.\\nLangChain is a platform that allows you to interact with various language\\nmodels from different providers such as OpenAI, Google Gemini, Hugging\\nFace Transformers, etc. You can use LangChain to create applications that\\nleverage the power of natural language processing without having to deal with\\nthe complexity of APIs or SDKs. LangChain provides a user-friendly interface\\nthat lets you choose the model you want to use, customize the parameters\\nyou want to apply, and see the results in real-time.\\n15'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 15, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"7. Why don't we use Flask or Django for API development instead of\\nFastAPI?\\n●\\nFastAPI is a newer and more modern framework than Flask or\\nDjango. It is designed to be fast, efficient, and easy to use. FastAPI is\\nalso more scalable than Flask or Django, making it a better choice for\\nlarge-scale projects.\\n●\\nFastAPI is also more feature-rich than Flask or Django. It includes\\nseveral built-in features that make it easy to develop APIs, such as\\nrouting, validation, and documentation.\\n●\\nOverall, FastAPI is a better choice for API development than Flask\\nor Django. It is faster, more scalable, and more feature-rich.\\n8. Why do we need to learn Cloud technologies in a Generative AI\\nprogram?\\nCloud technologies are essential for developing and deploying generative AI\\napplications because they provide a scalable and reliable platform for hosting\\nand managing complex workloads.\\n●\\nCloud computing offers a vast pool of resources that can be\\nprovisioned on demand, which is ideal for generative AI applications\\nthat can be computationally intensive.\\n●\\nCloud providers offer a wide range of services that can be used to\\nsupport generative AI applications, including storage, computing,\\nnetworking, and machine learning.\\n●\\nCloud services are typically more cost-effective than on-premises\\ninfrastructure, which can be a significant advantage for generative AI\\napplications that are often used for large-scale projects.\\nThe Certified Generative AI (GenEng) Developer and Engineering Program\\nteaches you how to use cloud native services, including containers and\\nKubernetes, to deploy your applications to the cloud. You will also learn how\\nto use Docker containers to package and deploy your applications, and how\\nto use Terraform to manage your cloud infrastructure.\\nBy the end of the program, you will be able to:\\n●\\nUse Docker containers to package and deploy your applications\\n●\\nDevelop and deploy generative AI applications to the cloud\\n●\\nManage your cloud infrastructure using Terraform\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 15, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='to use Terraform to manage your cloud infrastructure.\\nBy the end of the program, you will be able to:\\n●\\nUse Docker containers to package and deploy your applications\\n●\\nDevelop and deploy generative AI applications to the cloud\\n●\\nManage your cloud infrastructure using Terraform\\n9. What is the purpose of Docker Containers and what are the benefits of\\ndeploying them with Docker Compose, and Kubernetes?\\n●\\nDocker Containers are a way to package software into a single unit\\nthat can be run on any machine, regardless of its operating system. It\\n16'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 16, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"is used to create a Dockerfile, which is a text file that describes how to\\nbuild a Docker image. The image is then used to create a container,\\nwhich is a running instance of the image. This makes them ideal for\\ndeploying applications on a variety of platforms, including cloud-based\\nservices.\\n●\\nDocker Compose is a tool provided by Docker that allows you to\\ndefine and manage multi-container Docker applications locally. It\\nenables you to use a YAML file to configure the services, networks,\\nand volumes needed for your application's setup. With Docker\\nCompose, you can describe the services your application requires,\\ntheir configurations, dependencies, and how they should interact with\\neach other, all in a single file. This makes it easier to orchestrate\\ncomplex applications locally composed of multiple interconnected\\ncontainers.\\n●\\nKubernetes is a container orchestration system that automates the\\ndeployment, scaling, and management of containerized applications. It\\nallows you to run multiple containers on a single machine or across\\nmultiple machines. It is an open source and can be deployed in your\\ndata centre or the cloud.\\n10.What is the purpose of learning to develop APIs in a Generative AI\\nprogram?\\nAPIs (Application Programming Interfaces) are used to connect different\\nsoftware applications and services together. They are the building blocks of\\nthe internet and are essential for the exchange of data between different\\nsystems.\\nIn the third quarter of the Certified Generative AI (GenEng) Developer and\\nEngineering Program, students will learn to develop APIs not just as a\\nbackend for their front end but also as a product itself. In this model, the API\\nis at the core of the business's value.\\n●\\nAPIs are used to make it possible for different software applications to\\ncommunicate with each other.\\n●\\nAPIs are used to access data from a remote server.\\n●\\nAPIs are used to create new services or applications that are\\nintegrated with existing systems.\\n●\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 16, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"is at the core of the business's value.\\n●\\nAPIs are used to make it possible for different software applications to\\ncommunicate with each other.\\n●\\nAPIs are used to access data from a remote server.\\n●\\nAPIs are used to create new services or applications that are\\nintegrated with existing systems.\\n●\\nAPIs are used to improve the security of applications by providing a\\nway to control access to data.\\n●\\nBy learning to develop APIs, students will gain the skills necessary to\\ncreate powerful and efficient software applications that can be used to\\nsolve a variety of business problems.\\n17\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 17, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"11. What is the purpose of using Python-based FastAPI and related\\ntechnologies in Quarter 3?\\nIn the third quarter of the Engineering Program, students will learn how to use\\nPython-based FastAPI as a core library for API development.\\n●\\nFastAPI is a high-performance, lightweight, and easy-to-use framework\\nfor building APIs.\\n●\\nIt is designed to be fast, scalable, and secure.\\n●\\nFastAPI is compatible with a wide range of programming languages\\nand frameworks, making it a good choice for developers with different\\nskill sets.\\n●\\nStudents will also learn about the following related technologies:\\n●\\nPydantic: Pydantic is a Python library that helps to improve the quality\\nof your code by checking for errors and potential problems.\\n●\\nSQLModel: SQLModel is a Python library that provides an\\nobject-relational mapping (ORM) layer for working with databases.\\n●\\nPostgreSQL: PostgreSQL is a free and open-source relational\\ndatabase management system (RDBMS) that can be used for\\ndevelopment. Highly scalable database systems compatible with it\\nhave also been deployed by all the major cloud platforms.\\nBy the end of the quarter, students will be able to use Python-based FastAPI\\nto develop APIs that are fast, scalable, and secure.\\n12.What does the API-as-a-Product model entail?\\nAPI-as-a-Product is a type of Software-as-a-Service that monetizes niche\\nfunctionality, typically served over HTTP. In this model, the API is at the core\\nof the business's value. The API-as-a-Product model is different from the\\ntraditional API model, where APIs are used as a means to access data or\\nfunctionality from another application. In the API-as-a-Product model, the API\\nitself is the product that is being sold.\\nThe benefits of the API-as-a-Product model include:\\n●\\nIncreased flexibility: APIs can be used to access data or functionality\\nfrom any application, regardless of the underlying platform or\\ntechnology. This gives businesses greater flexibility in how they\\nintegrate APIs into their applications.\\n●\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 17, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='The benefits of the API-as-a-Product model include:\\n●\\nIncreased flexibility: APIs can be used to access data or functionality\\nfrom any application, regardless of the underlying platform or\\ntechnology. This gives businesses greater flexibility in how they\\nintegrate APIs into their applications.\\n●\\nReduced development costs: APIs can be reused by multiple\\napplications, which can save businesses the time and expense of\\ndeveloping their custom APIs.\\n18'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 18, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='●\\nImproved scalability: APIs can be scaled up or down as needed,\\nwhich makes them well-suited for businesses with fluctuating or\\nunpredictable traffic demands.\\n●\\nEnhanced security: APIs can be more secure than traditional\\nmethods of data exchange, as they can be protected by a variety of\\nsecurity measures, such as encryption and access control.\\n13.What are the benefits of using Docker Containers for development,\\ntesting, and deployment?\\nDocker Containers are a fundamental building block for development, testing,\\nand deployment because they provide a consistent environment that can be\\nused across different systems. This eliminates the need to worry about\\ndependencies or compatibility issues, and it can help to improve the efficiency\\nof the development process. Additionally, Docker Containers can be used to\\nisolate applications, which can help to improve security and make it easier to\\nmanage deployments.\\n14.What is the advantage of using open Docker, Kubernetes, and Terraform\\ntechnologies instead of using AWS, Azure, or Google Cloud\\ntechnologies?\\nUsing open-source technologies like Docker, Kubernetes, and Terraform\\noffers several advantages over relying solely on proprietary cloud services\\nfrom AWS, Azure, or Google Cloud. Here’s a detailed comparison:\\nAdvantages of Using Docker, Kubernetes, and Terraform (Open Technologies)\\n1. Portability and Flexibility:\\n- Vendor Agnostic: These tools are cloud-agnostic, meaning you can run\\nyour applications on any cloud provider or on-premises infrastructure without\\nbeing locked into a specific vendor.\\n- Ease of Migration: Applications packaged in Docker containers can easily\\nbe moved across different environments, and Kubernetes provides a\\nconsistent orchestration layer, ensuring seamless transitions.\\n2. Cost Efficiency:\\n- Avoid Vendor Lock-In: Being locked into a single cloud provider can lead to\\nhigher costs over time. Using open technologies allows you to leverage'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 18, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='be moved across different environments, and Kubernetes provides a\\nconsistent orchestration layer, ensuring seamless transitions.\\n2. Cost Efficiency:\\n- Avoid Vendor Lock-In: Being locked into a single cloud provider can lead to\\nhigher costs over time. Using open technologies allows you to leverage\\ncompetitive pricing from multiple providers or even use on-premises\\nresources.\\n- Optimised Resource Utilisation: Kubernetes helps in efficiently managing\\nresources through automated scaling and load balancing, potentially reducing\\ncosts.\\n19'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 19, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='3. Community and Ecosystem:\\n- Open Source: These tools are backed by strong, active open-source\\ncommunities that continuously improve the software, provide support, and\\nshare best practices.\\n- Ecosystem: A rich ecosystem of tools and integrations is available,\\nproviding flexibility to choose the best components that fit your specific needs.\\n4. Standardisation and Consistency:\\n- Unified Platform: Using Docker for containerization, Kubernetes for\\norchestration, and Terraform for infrastructure as code (IaC) provides a\\nstandardised way to deploy, manage, and scale applications across different\\nenvironments.\\n- Consistency Across Environments: These tools ensure that your\\ndevelopment, staging, and production environments are consistent, reducing\\nbugs and deployment issues.\\n5. Customization and Control:\\n- Full Control: Open-source tools give you complete control over your\\ninfrastructure and deployment pipelines. You can customise and extend the\\nfunctionality to suit specific requirements.\\n- Transparency: Access to the source code means you can audit and modify\\nthe software to meet your security and compliance needs.\\nAdvantages of Using AWS, Azure, or Google Cloud Technologies\\n1. Managed Services:\\n- **Ease of Use:** Cloud providers offer a wide range of managed services\\nthat abstract away the complexity of setting up and managing infrastructure.\\nThis can save time and reduce operational overhead.\\n- Integrated Solutions: These platforms provide integrated services and\\ntools, such as databases, machine learning, analytics, and monitoring, which\\ncan be easily combined to build complex applications.\\n2. Scalability and Reliability:\\n- Global Infrastructure: Cloud providers have extensive global infrastructure,\\nensuring high availability, redundancy, and low latency.\\n- Auto-Scaling: Advanced auto-scaling capabilities can dynamically adjust\\nresources to meet changing demands, ensuring optimal performance.\\n3. Security and Compliance:'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 19, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='ensuring high availability, redundancy, and low latency.\\n- Auto-Scaling: Advanced auto-scaling capabilities can dynamically adjust\\nresources to meet changing demands, ensuring optimal performance.\\n3. Security and Compliance:\\n- Built-In Security: Cloud providers offer robust security features, including\\nidentity and access management, encryption, and compliance certifications,\\nhelping to protect your data and meet regulatory requirements.\\n20'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 20, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"- Automatic Updates: Managed services often include automatic updates\\nand patches, reducing the risk of security vulnerabilities.\\n4. Innovation and Support:\\n- Cutting-Edge Technology: Major cloud providers continuously innovate and\\nintroduce new services and features, allowing you to leverage the latest\\ntechnologies without significant investment.\\n- Support and SLA: Comprehensive support services and Service Level\\nAgreements (SLAs) ensure that you have access to expert help and\\nguaranteed uptime.\\nConclusion\\nChoosing between open-source technologies like Docker, Kubernetes, and\\nTerraform versus proprietary cloud services from AWS, Azure, or Google\\nCloud depends on your specific needs and priorities.\\n- Open Technologies: Offer portability, cost efficiency, customization, and\\ncontrol, making them ideal for multi-cloud strategies, avoiding vendor lock-in,\\nand having more control over your infrastructure.\\n- Cloud Providers: Provide ease of use, managed services, scalability,\\nsecurity, and access to cutting-edge technology, which can be advantageous\\nfor rapid development, scaling, and leveraging advanced services.\\nIn many cases, a hybrid approach that combines the strengths of both\\nopen-source tools and cloud provider services can provide the best of both\\nworlds, allowing you to optimise for cost, flexibility, and innovation.\\n15.Why in this program are we not learning to build LLMs ourselves? How\\ndifficult is it to develop an LLM like ChatGPT 4 or Google’s Gemini?\\nDeveloping an LLM like ChatGPT 4 or Google Gemini is extremely difficult\\nand requires a complex combination of resources, expertise, and\\ninfrastructure. Here's a breakdown of the key challenges:\\nTechnical hurdles:\\nMassive data requirements: Training these models requires an immense\\namount of high-quality data, often exceeding petabytes. Compiling, cleaning,\\nand structuring this data is a monumental task.\\nComputational power: Training LLMs demands incredible computational\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 20, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='Technical hurdles:\\nMassive data requirements: Training these models requires an immense\\namount of high-quality data, often exceeding petabytes. Compiling, cleaning,\\nand structuring this data is a monumental task.\\nComputational power: Training LLMs demands incredible computational\\nresources, like high-performance GPUs and specialised AI hardware. Access\\nto these resources and the ability to optimise training processes are crucial.\\n21'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 21, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"Model architecture: Designing the LLM's architecture involves complex\\ndecisions about parameters, layers, and attention mechanisms. Optimising\\nthis architecture for performance and efficiency is critical.\\nEvaluation and bias: Evaluating the performance of LLMs involves diverse\\nbenchmarks and careful monitoring for biases and harmful outputs. Mitigating\\nthese biases is an ongoing research challenge.\\nResource and expertise:\\nTeam effort: Developing an LLM like ChatGPT 4 or Google Gemini requires a\\nlarge team of experts across various disciplines, including AI researchers,\\nmachine learning engineers, data scientists, and software developers.\\nFinancial investment: The financial resources needed are substantial,\\ncovering costs for data acquisition, hardware, software, and talent. Access to\\nsustained funding is critical.\\nAdditionally:\\nEthical considerations: LLMs raise ethical concerns like potential misuse,\\nmisinformation, and societal impacts. Responsible development and\\ndeployment are crucial.\\nRapidly evolving field: The LLM landscape is constantly evolving, with new\\nresearch, models, and benchmarks emerging. Staying abreast of these\\nadvancements is essential.\\nTherefore, while ChatGPT 4 and Google Gemini have made impressive\\nstrides, developing similar LLMs remains a daunting task accessible only to a\\nhandful of organisations with the necessary resources and expertise.\\nIn simpler terms, it's like building a skyscraper of knowledge and intelligence.\\nYou need the right materials (data), the right tools (hardware and software),\\nthe right architects (experts), and a lot of hard work and attention to detail to\\nmake it stand tall and function flawlessly.\\nDeveloping similar models would be a daunting task for individual developers\\nor smaller teams due to the enormous scale of resources and expertise\\nneeded. However, as technology progresses and research findings become\\nmore accessible, it might become incrementally more feasible for a broader\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 21, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='Developing similar models would be a daunting task for individual developers\\nor smaller teams due to the enormous scale of resources and expertise\\nneeded. However, as technology progresses and research findings become\\nmore accessible, it might become incrementally more feasible for a broader\\nrange of organisations or researchers to work on similar models, albeit at a\\nsmaller scale or with fewer resources. At that time we might also start to focus\\non developing LLMs ourselves.\\n22'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 22, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"To sum up, the focus of the program is not on LLM model development but on\\napplied Cloud GenAI Engineering (GenEng), application development, and\\nfine-tuning of foundational models. The program covers a wide range of topics\\nincluding Python, GenAI, Microserices, API, Database, Cloud Development,\\nand DevOps, which will give students a comprehensive understanding of\\ngenerative AI and prepare them for careers in this field.\\n16.Business wise does it make more sense to develop LLMs ourselves\\nfrom scratch or use LLMs developed by others and build applications\\nusing these tools by using APIs and/or fine-tuning them?\\nWhether it makes more business sense to develop LLMs from scratch or\\nleverage existing ones through APIs and fine-tuning depends on several\\nfactors specific to your situation. Here's a breakdown of the pros and cons to\\nhelp you decide:\\nDeveloping LLMs from scratch:\\nPros:\\nCustomization: You can tailor the LLM to your specific needs and data,\\npotentially achieving higher performance on relevant tasks.\\nIntellectual property: Owning the LLM allows you to claim intellectual property\\nrights and potentially monetize it through licensing or other means.\\nControl: You have full control over the training data, algorithms, and biases,\\nensuring alignment with your ethical and business values.\\nCons:\\nHigh cost: Building and training LLMs require significant technical expertise,\\ncomputational resources, and data, translating to high financial investment.\\nTime commitment: Developing an LLM is a time-consuming process,\\npotentially delaying your go-to-market with your application.\\nTechnical expertise: You need a team of highly skilled AI specialists to\\ndesign, train, and maintain the LLM.\\nUsing existing LLMs:\\nPros:\\nLower cost: Leveraging existing LLMs through APIs or fine-tuning is\\nsignificantly cheaper than building them from scratch.\\nFaster time to market: You can quickly integrate existing LLMs into your\\napplications, accelerating your launch timeline.\\n23\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 23, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='Reduced technical burden: You don\\'t need a large team of AI specialists to\\nmaintain the LLM itself\\nCons:\\nLess customization: Existing LLMs are not specifically designed for your\\nneeds, potentially leading to lower performance on some tasks.\\nLimited control: You rely on the data and biases of the existing LLM, which\\nmight not align with your specific requirements.\\nDependency on external parties: You are dependent on the availability and\\nmaintenance of the LLM by its developers.\\nHere are some additional factors to consider:\\nThe complexity of your application: Simpler applications might benefit\\nmore from existing LLMs, while highly complex ones might require the\\ncustomization of a dedicated LLM.\\nYour available resources: If you have the financial and technical resources,\\ndeveloping your own LLM might be feasible. Otherwise, existing options might\\nbe more practical.\\nYour competitive landscape: If your competitors are using LLMs, you might\\nneed to follow suit to remain competitive.\\nUltimately, the best decision depends on your specific needs, resources, and\\nbusiness goals. Carefully evaluating the pros and cons of each approach will\\nhelp you choose the strategy that best aligns with your success.\\n17.What are Custom GPTs?\\n\"Custom GPTs\" refers to specialised versions of the Generative Pre-trained\\nTransformer (GPT) models that are tailored for specific tasks, industries, or\\ndata types. These custom models are adapted from the base GPT\\narchitecture, which is a type of language model developed by OpenAI.\\nCustom GPT models are trained or fine-tuned on specific datasets or for\\nparticular applications, allowing them to perform better in those contexts\\ncompared to the general-purpose models.\\nHere are some examples of what custom GPT models might be used for:\\n1. Industry-Specific Needs: A custom GPT for legal, medical, or financial\\nindustries could be trained on domain-specific texts to understand and\\ngenerate industry-specific language more accurately.\\n24'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 24, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"2. Language and Localization: Models can be customised for different\\nlanguages or dialects that might not be well-represented in the training data of\\nthe base model.\\n3. Company-Specific Applications: Organisations might develop a custom\\nGPT model trained on their own documents and communications to assist\\nwith internal tasks like drafting emails, generating reports, or providing\\ncustomer support.\\n4. Educational Purposes: Educational institutions might develop custom\\nGPTs trained on educational material to assist in creating teaching materials\\nor providing tutoring in specific subjects.\\n5. Creative Writing and Entertainment: Custom models could be trained on\\nspecific genres of literature or scripts to assist in creative writing or content\\ncreation.\\n6. Technical and Scientific Research: A custom GPT model could be\\ntrained on scientific literature to assist researchers in summarising papers,\\ngenerating hypotheses, or even drafting new research.\\nThese custom models are created through a process of fine-tuning, where the\\nbase GPT model is further trained (or 'fine-tuned') on a specific dataset. This\\nprocess allows the model to become more adept at understanding and\\ngenerating text that is relevant to the specific use case. Fine-tuning requires\\nexpertise in machine learning and natural language processing, as well as\\naccess to relevant training data.\\n18.What are Actions in GPTs?\\nActions are a way to connect custom GPTs to external APIs, allowing them to\\naccess data or interact with the real-world. For example, you can use actions\\nto create a GPT that can book flights, send emails, or order pizza. Actions\\nare defined using the OpenAPI specification, which is a standard for\\ndescribing APIs. You can import an existing OpenAPI specification or create a\\nnew one using the GPT editor.\\n19.What are AI Agents and how do they differ from Custom GPTs?\\nAI Agents and Custom GPTs are both tools that utilise artificial intelligence to\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 24, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='describing APIs. You can import an existing OpenAPI specification or create a\\nnew one using the GPT editor.\\n19.What are AI Agents and how do they differ from Custom GPTs?\\nAI Agents and Custom GPTs are both tools that utilise artificial intelligence to\\nperform tasks, but they have distinct functionalities and use cases. Here’s a\\nbreakdown of their differences:\\nAI Agents\\nAI Agents are autonomous programs that can perceive their environment,\\nmake decisions, and act upon them to achieve specific goals. They often\\n25'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 25, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='interact with other systems or users, continuously learning and adapting\\nbased on their experiences.\\nKey Characteristics:\\n1. Autonomy: AI Agents operate independently without continuous human\\nintervention.\\n2. Learning: They often employ machine learning algorithms to improve\\nperformance over time.\\n3. Interactivity: AI Agents can interact with their environment, other systems,\\nand users.\\n4. Goal-Oriented: They are designed to achieve specific objectives and can\\nadapt their actions to optimise towards these goals.\\n5. Multi-Modal Capabilities: AI Agents can incorporate various forms of AI,\\nsuch as computer vision, natural language processing, and decision-making\\nalgorithms.\\nExamples:\\n- Robotics: Autonomous robots that navigate and perform tasks.\\n- Virtual Assistants: Programs like Siri or Alexa that interact with users and\\nperform tasks based on voice commands.\\n- Game AI: Non-player characters (NPCs) that adapt and react to player\\nactions.\\nCustom GPTs\\nCustom GPTs are tailored instances of OpenAI’s ChatGPT, launched in late\\n2022. They are designed for specific purposes and enhanced with context.\\nEach custom GPT can have a unique “personality,” including tone of voice,\\nlanguage complexity, and responsiveness to specific topics. For example, a\\nfinancial institution’s custom GPT could be trained on financial reports and\\nindustry-specific terminology, while a healthcare provider’s version might\\nfocus on medical literature and health policy documents\\nKey Differences\\n1. Autonomy:\\n- AI Agents: Operate autonomously and continuously interact with their\\nenvironment.\\n- Custom GPTs: Typically respond to specific inputs and generate outputs\\naccordingly, but don’t operate autonomously beyond text generation tasks.\\n2. Learning and Adaptation:\\n- AI Agents: Often incorporate continuous learning and adaptation\\nmechanisms.\\n26'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 26, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='- Custom GPTs: Rely on pre-training and fine-tuning phases, with limited\\ncontinuous learning capabilities.\\n4. Interactivity:\\n- AI Agents: Can interact with both digital and physical environments.\\n- Custom GPTs: Primarily interact through text-based inputs and outputs.\\nIn summary, while both AI Agents and Custom GPTs utilise AI, AI Agents are\\ndesigned for autonomous, goal-oriented actions in diverse environments, and\\nCustom GPTs are specialised in generating and understanding human-like\\ntext for specific applications.\\n20.Do we need to use Design Thinking and BDD for designing custom GPTs\\nand AI Agents?\\nDesign Thinking and Behavior-Driven Development (BDD) are methodologies\\nthat can greatly enhance the process of designing custom GPTs and AI\\nAgents, though they are not strictly necessary. Here’s how each can be\\nbeneficial:\\nDesign Thinking\\nDesign Thinking is a user-centred approach to innovation and problem-solving\\nthat involves understanding the user, challenging assumptions, redefining\\nproblems, and creating innovative solutions through iterative prototyping and\\ntesting.\\nBenefits for Custom GPTs and AI Agents:\\n1. User-Centric Focus: Ensures that the AI solutions are tailored to the actual\\nneeds and pain points of users.\\n2. Empathy: Helps in understanding the context and environment in which the\\nAI will be used, leading to more relevant and effective solutions.\\n3. Iterative Development: Encourages continuous testing and refinement of\\nideas, leading to more robust and user-friendly AI models.\\n4. Collaboration: Promotes cross-disciplinary collaboration, which can bring\\ndiverse perspectives and expertise to the design process.\\nBehaviour-Driven Development (BDD)\\nBDD is a software development methodology that encourages collaboration\\nbetween developers, QA, and non-technical stakeholders through the use of\\nnatural language descriptions of the desired behaviour of the software.\\nBenefits for Custom GPTs and AI Agents:'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 26, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='Behaviour-Driven Development (BDD)\\nBDD is a software development methodology that encourages collaboration\\nbetween developers, QA, and non-technical stakeholders through the use of\\nnatural language descriptions of the desired behaviour of the software.\\nBenefits for Custom GPTs and AI Agents:\\n1. Clear Requirements: Ensures that the requirements are clearly understood\\nand agreed upon by all stakeholders.\\n27'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 27, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='2. Testable Scenarios: Facilitates the creation of testable scenarios that can\\nvalidate the AI’s behaviour against the expected outcomes.\\n3. Documentation: Provides clear and comprehensive documentation of the\\nAI’s intended behaviour, which is useful for future maintenance and\\nenhancements.\\n4. Alignment: Ensures that the development stays aligned with business goals\\nand user expectations.\\nApplication in Designing Custom GPTs and AI Agents\\nFor Custom GPTs:\\n- Design Thinking:\\n- Understand the specific use cases and user interactions where the GPT\\nwill be applied.\\n- Iterate on the model’s performance by gathering user feedback and refining\\nthe fine-tuning process.\\n- Prototype different conversation flows and evaluate their effectiveness with\\nreal users.\\n- BDD:\\n- Define the expected behaviours of the GPT in natural language scenarios.\\n- Create automated tests that validate the GPT’s responses against these\\nscenarios.\\n- Ensure that the GPT’s behaviour aligns with user stories and business\\nrequirements.\\nFor AI Agents:\\n- Design Thinking:\\n- Map out the user journey and identify critical interaction points where the AI\\nAgent will provide value.\\n- Prototype and test the agent’s interactions in various environments to\\nensure robustness and usability.\\n- Use empathy maps and personas to better understand and anticipate user\\nneeds and behaviours.\\n- BDD:\\n- Write behaviour scenarios that describe how the AI Agent should react in\\ndifferent situations.\\n- Develop tests that simulate these scenarios to verify the agent’s\\ndecision-making and learning processes.\\n- Continuously refine the agent’s behaviour based on test results and user\\nfeedback.\\n28'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 28, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"While not strictly necessary, Design Thinking and BDD can significantly\\nenhance the design and development process of custom GPTs and AI Agents\\nby ensuring a user-centred approach, clear requirements, and continuous\\nimprovement through iterative testing and feedback. These methodologies\\nhelp in creating more effective, reliable, and user-friendly AI solutions.\\n21.When Fine-Tuning Open-Source Large Language Models, how is FastAI\\nand PyTorch important and what role do these libraries play?\\nFine-tuning open-source Large Language Models (LLMs) like Meta LLaMA 3\\ninvolves adapting pre-trained models to specific tasks or domains by\\ncontinuing the training process on a smaller, task-specific dataset. FastAI and\\nPyTorch play crucial roles in this process due to their powerful features and\\nease of use. Here's how they contribute:\\nPyTorch\\nPyTorch is an open-source deep learning framework developed by\\nFacebook’s AI Research lab. It provides a flexible and efficient platform for\\nbuilding and training neural networks.\\nImportance in Fine-Tuning LLMs:\\n1. Dynamic Computation Graphs: PyTorch’s dynamic computation graph (also\\nknown as define-by-run) allows for flexibility and ease of debugging. This is\\nparticularly useful when experimenting with different model architectures and\\ntraining strategies.\\n2. Extensive Libraries and Tools: PyTorch has a wide range of libraries and\\ntools that facilitate various deep learning tasks, including natural language\\nprocessing (NLP). Libraries like Hugging Face’s Transformers are built on top\\nof PyTorch, providing pre-trained models and utilities for fine-tuning.\\n3. GPU Acceleration: PyTorch supports GPU acceleration, which is essential\\nfor handling the large computational requirements of fine-tuning LLMs.\\n4. Community and Ecosystem: PyTorch has a strong community and\\nextensive documentation, making it easier to find resources, tutorials, and\\nsupport for fine-tuning tasks.\\nRole in Fine-Tuning:\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 28, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='for handling the large computational requirements of fine-tuning LLMs.\\n4. Community and Ecosystem: PyTorch has a strong community and\\nextensive documentation, making it easier to find resources, tutorials, and\\nsupport for fine-tuning tasks.\\nRole in Fine-Tuning:\\n- Model Customization: Allows users to modify the architecture of LLMs to\\nbetter fit specific tasks.\\n- Efficient Training: Provides efficient backpropagation and optimization\\nroutines to train large models on specialised datasets.\\n- Experimentation: Facilitates rapid experimentation with different\\nhyperparameters and training setups due to its flexible framework.\\n29'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 29, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='FastAI\\nFastAI is a deep learning library built on top of PyTorch that aims to simplify\\ntraining neural networks by providing high-level abstractions and best\\npractices.\\nImportance in Fine-Tuning LLMs:\\n1. Ease of Use: FastAI provides high-level APIs that simplify many complex\\ntasks involved in training and fine-tuning models, making it accessible to both\\nbeginners and experts.\\n2. State-of-the-Art Techniques: FastAI incorporates many state-of-the-art\\ntechniques and best practices in deep learning, such as learning rate\\nschedules, data augmentation, and transfer learning, which can improve the\\nperformance of fine-tuned models.\\n3. Rapid Prototyping: FastAI’s concise and readable code allows for rapid\\nprototyping and iteration, which is crucial for experimenting with different\\nfine-tuning approaches.\\n4. Integrated Data Handling: FastAI offers powerful data handling and\\npreprocessing utilities, which streamline the process of preparing datasets for\\ntraining.\\nRole in Fine-Tuning:\\n- High-Level API: Simplifies the process of loading pre-trained models,\\ndefining custom datasets, and setting up training loops.\\n- Training Utilities: Provides utilities for monitoring training progress, adjusting\\nlearning rates, and saving model checkpoints.\\n- Best Practices: Encourages the use of best practices in model training, such\\nas using discriminative learning rates and employing effective data\\naugmentation techniques.\\nCombined Workflow for Fine-Tuning LLMs\\n1. Model Loading: Use PyTorch (and libraries like Hugging Face\\nTransformers) to load a pre-trained LLM.\\n2. Data Preparation: Leverage FastAI’s data handling capabilities to\\npreprocess and load the fine-tuning dataset.\\n3. Training Setup: Define the model architecture and training parameters\\nusing PyTorch, and use FastAI’s high-level APIs to simplify this process.\\n4. Fine-Tuning: Utilise FastAI’s training utilities to fine-tune the model on the\\nspecific dataset, adjusting hyperparameters as needed.'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 29, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='3. Training Setup: Define the model architecture and training parameters\\nusing PyTorch, and use FastAI’s high-level APIs to simplify this process.\\n4. Fine-Tuning: Utilise FastAI’s training utilities to fine-tune the model on the\\nspecific dataset, adjusting hyperparameters as needed.\\n5. Evaluation and Iteration: Evaluate the fine-tuned model using PyTorch’s\\nevaluation utilities, and iterate on the fine-tuning process by leveraging\\nFastAI’s rapid prototyping capabilities.\\n30'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 30, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content=\"Both PyTorch and FastAI play crucial roles in the fine-tuning of open-source\\nLLMs. PyTorch provides the foundational tools and flexibility needed for deep\\nlearning, while FastAI builds on top of PyTorch to offer high-level abstractions\\nand best practices that streamline the fine-tuning process. Together, they\\nenable efficient, effective, and user-friendly fine-tuning of large language\\nmodels for specific tasks and domains.\\n22.In this course both PyTorch and FastAI play crucial roles in the\\nfine-tuning of open-source LLMs, why don't we use TensorFlow instead?\\nWhile TensorFlow is a powerful and widely-used deep learning framework,\\nPyTorch and FastAI offer several advantages that make them particularly\\nwell-suited for fine-tuning open-source Large Language Models (LLMs).\\nHere’s a detailed comparison highlighting why PyTorch and FastAI might be\\npreferred over TensorFlow for this specific task:\\nPyTorch vs. TensorFlow\\n1. Dynamic Computation Graphs:\\n- PyTorch: Uses dynamic computation graphs (define-by-run), which allow\\nfor greater flexibility and ease of debugging. This is especially useful when\\nexperimenting with new models and training strategies.\\n- TensorFlow: Initially used static computation graphs (define-and-run).\\nAlthough TensorFlow 2.0 introduced eager execution to support dynamic\\ngraphs, PyTorch's implementation is often considered more intuitive and\\neasier to work with for dynamic tasks.\\n2. Ease of Use:\\n- PyTorch: Known for its simplicity and clear, Pythonic code, which makes it\\neasier to learn and use, especially for research and prototyping.\\n- TensorFlow: While TensorFlow 2.0 improved usability, it is still considered\\nmore complex compared to PyTorch, particularly for newcomers.\\n3. Community and Ecosystem:\\n- PyTorch: Has seen rapid adoption in the research community, leading to a\\nrich ecosystem of tools, libraries, and community support. Libraries like\\nHugging Face’s Transformers are built primarily for PyTorch, offering\\nextensive support for LLMs.\"),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 30, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='3. Community and Ecosystem:\\n- PyTorch: Has seen rapid adoption in the research community, leading to a\\nrich ecosystem of tools, libraries, and community support. Libraries like\\nHugging Face’s Transformers are built primarily for PyTorch, offering\\nextensive support for LLMs.\\n- TensorFlow: Has a strong industrial presence and is widely used in\\nproduction environments. However, the research community has increasingly\\nfavoured PyTorch.\\n4. Integration with Hugging Face:\\n31'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 31, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='- PyTorch: Hugging Face’s Transformers library, which is a go-to for working\\nwith LLMs, is deeply integrated with PyTorch. This library provides pre-trained\\nmodels, tokenizers, and utilities that simplify the process of fine-tuning LLMs.\\n- TensorFlow: Although Hugging Face provides TensorFlow support, the\\nintegration is not as seamless or feature-rich as it is with PyTorch.\\nFastAI vs. TensorFlow\\n1. High-Level Abstractions:\\n- FastAI: Provides high-level abstractions that simplify complex tasks in\\nmodel training and fine-tuning, making it accessible and efficient for users.\\nThese abstractions are built on top of PyTorch, leveraging its flexibility.\\n- TensorFlow: While Keras (part of TensorFlow) offers high-level APIs,\\nFastAI’s APIs are often considered more intuitive and tailored towards rapid\\nexperimentation and prototyping.\\n2. Best Practices:\\n- FastAI: Incorporates state-of-the-art techniques and best practices in deep\\nlearning, such as learning rate schedules, transfer learning, and data\\naugmentation, making it easier to achieve high performance with minimal\\neffort.\\n- TensorFlow: Requires more manual effort to implement many of these best\\npractices, which can be a barrier for quick iteration and experimentation.\\n3. Community and Learning Resources:\\n- FastAI: Has an active community and a wealth of educational resources,\\nincluding courses and documentation that focus on practical, hands-on\\nlearning.\\n- TensorFlow: Also has extensive documentation and resources, but the\\nlearning curve can be steeper, especially for those new to deep learning.\\nSummary of Why PyTorch and FastAI Might Be Preferred\\n- Flexibility and Debugging: PyTorch’s dynamic computation graph is more\\nflexible and easier to debug.\\n- User-Friendly: PyTorch and FastAI offer more intuitive and user-friendly\\ninterfaces, making them suitable for rapid prototyping and experimentation.\\n- Research and Development: PyTorch is preferred in the research'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 31, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='flexible and easier to debug.\\n- User-Friendly: PyTorch and FastAI offer more intuitive and user-friendly\\ninterfaces, making them suitable for rapid prototyping and experimentation.\\n- Research and Development: PyTorch is preferred in the research\\ncommunity, leading to faster adoption of new techniques and tools like\\nHugging Face’s Transformers.\\n- Seamless Integration: Hugging Face’s deep integration with PyTorch\\nprovides a robust ecosystem for working with LLMs.\\n32'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 32, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='- Educational Resources: FastAI’s focus on best practices and practical\\neducation makes it easier for users to get started and achieve good results\\nquickly.\\nWhile TensorFlow remains a powerful framework, particularly in production\\nenvironments, PyTorch and FastAI provide a combination of flexibility, ease of\\nuse, and community support that make them particularly well-suited for the\\nfine-tuning of open-source LLMs.\\n23.What is Physical AI?\\nPhysical AI refers to the integration of artificial intelligence with physical\\nentities, such as robots, that can operate and interact in the real world. This\\nconcept involves AI systems that not only process data and make decisions\\nbut also perform physical actions and understand the laws of physics.\\nKey Characteristics:\\n1. Real-World Interaction:\\n- Physical AI systems can perceive their environment through sensors,\\nprocess this information, and take appropriate actions using actuators.\\n2. Embodiment:\\n- Unlike purely digital AI, Physical AI involves AI embedded in physical\\nbodies, like humanoid robots, which can navigate and manipulate the physical\\nworld.\\n3. Understanding Physics:\\n- These AI systems are designed to comprehend and adhere to the physical\\nlaws that govern real-world interactions, such as gravity, friction, and object\\ndynamics.\\n4. Human-like Functionality:\\n- Humanoid robots are a prime example of Physical AI, as they are built to\\nperform tasks in environments designed for humans, utilising a form factor\\nthat mirrors human anatomy.\\n5. Data-Driven Training:\\n- Physical AI leverages vast amounts of real-world data to train AI models,\\nenabling robots to improve their performance through machine learning and\\ninteraction experiences.\\nApplications:\\n- Healthcare:\\n- Assistive robots that help with patient care, rehabilitation, and surgery.\\n33'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 33, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='- Service Industry:\\n- Robots that perform tasks such as cleaning, delivery, and customer\\nservice.\\n- Manufacturing:\\n- Industrial robots that assemble products, manage inventory, and ensure\\nquality control.\\n- Exploration:\\n- Robots designed for exploration in environments like space, underwater, or\\ndisaster zones.\\nPhysical AI represents a significant shift from traditional AI applications\\nconfined to virtual environments. It aims to bridge the gap between digital\\nintelligence and physical capability, creating systems that can understand and\\ninteract with the world in a human-like manner. This evolution has the\\npotential to revolutionise various industries by enhancing automation,\\nimproving efficiency, and enabling new forms of human-machine\\ncollaboration.\\n24.What are the different specialisations offered at the end of the program\\nand what are their benefits?\\nAt the end of the GenEng certification program we offer six specialisations in\\ndifferent fields:\\nHealthcare and Medical GenAI: This specialisation will teach students how\\nto use generative AI to improve healthcare and medical research. This is\\nrelevant to fields such as drug discovery, personalised medicine, and surgery\\nplanning.\\nBenefits:\\n●\\nLearn how to use generative AI to identify diseases, develop new\\ndrugs, and personalise treatment plans.\\n●\\nGain a deeper understanding of the ethical implications of using\\ngenerative AI in healthcare.\\n●\\nPrepare for a career in a growing field with high demand for skilled\\nprofessionals.\\nWeb3, Blockchain, and GenAI Integration: This specialisation will teach\\nstudents how to integrate generative AI with Web3 and blockchain\\ntechnologies. This is relevant to fields such as finance, healthcare, and supply\\nchain management.\\nBenefits:\\n●\\nLearn how to create smart contracts and decentralised applications\\n(dApps).\\n34'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 34, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='●\\nGain a deeper understanding of the potential of blockchain technology\\nand how it can be used to improve business processes.\\n●\\nDevelop the skills necessary to work in a rapidly growing field with high\\ndemand for skilled professionals.\\nMetaverse, 3D, and GenAI Integration: This specialisation will teach\\nstudents how to create and use 3D models and other immersive content\\nmanually and with generative AI. This is relevant to fields such as gaming,\\nmarketing, and architecture.\\nBenefits:\\n●\\nLearn how to use generative AI to create realistic and immersive 3D\\nmodels.\\n●\\nDevelop the skills necessary to work in the growing field of virtual\\nreality (VR) and augmented reality (AR).\\n●\\nApply generative AI to solve real-world problems in areas such as\\nproduct design, marketing, and education.\\nGenAI for Accounting, Finance, and Banking: This specialisation will teach\\nstudents how to use generative AI to improve accounting, finance, and\\nbanking processes. This is relevant to fields such as fraud detection, risk\\nmanagement, and investment analysis.\\nBenefits:\\n●\\nLearn how to use generative AI to automate tasks, identify patterns,\\nand make predictions.\\n●\\nGain a deeper understanding of the financial industry and how\\ngenerative AI can be used to improve its processes.\\n●\\nPrepare for a career in a growing field with high demand for skilled\\nprofessionals.\\nGenAI for Engineers: This specialisation will teach students how to use\\ngenerative AI to improve engineering design and problem-solving. This is\\nrelevant to fields such as manufacturing, construction, and product\\ndevelopment.\\nBenefits:\\n●\\nLearn how to use generative AI to create simulations, optimize designs,\\nand predict failures.\\n●\\nGain a deeper understanding of the engineering design process and\\nhow generative AI can be used to improve it.\\n●\\nPrepare for a career in a growing field with high demand for skilled\\nprofessionals.\\n35'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 35, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='GenAI for Sales and Marketing: This specialisation will teach students how\\nto use generative AI to improve sales and marketing campaigns. This is\\nrelevant to fields such as advertising, public relations, and customer service.\\nBenefits:\\n●\\nLearn how to use generative AI to create personalised marketing\\nmessages, generate leads, and track campaign performance.\\n●\\nGain a deeper understanding of the latest marketing trends and how\\ngenerative AI can be used to improve them.\\n●\\nPrepare for a career in a growing field with high demand for skilled\\nprofessionals.\\nGenAI for Automation and Internet of Things (IoT):\\n●\\nProvide Multi-Modal User Interface for the IoT systems: Multimodal\\ninteraction exploits the synergic use of different modalities to optimise\\nthe interactive tasks accomplished by the users. This allows a user to\\nuse several input modes such as speech, touch, and visual to interact\\nwith IoT systems.\\n●\\nImprove efficiency and accuracy of industrial processes: By\\nimplementing GenAI in automation and IoT systems, industries can\\noptimise their processes, reduce manual labour, and increase\\nproductivity while ensuring higher accuracy and consistency.\\n●\\nEnhance decision-making: GenAI can analyse vast amounts of data\\ncollected by IoT sensors to derive valuable insights, enabling\\nbusinesses to make informed decisions regarding operations,\\nmaintenance, and resource allocation.\\n●\\nPersonalise user experiences: GenAI can leverage IoT data to\\nunderstand user preferences and behaviours, enabling the creation of\\npersonalised experiences across smart devices and IoT-enabled\\nsystems.\\nGenAI for Cyber Security:\\n●\\nStrengthen threat detection and response: GenAI can be used to\\nrapidly detect and respond to cyber threats by analysing large volumes\\nof security data in real time, identifying anomalies, and suggesting\\nappropriate countermeasures.\\n●\\nEnhance security monitoring and analysis: GenAI can assist\\nsecurity analysts in monitoring and analysing security logs, automating'),\n",
       " Document(metadata={'source': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'file_path': 'Panaversity Cloud Native Applied Generative AI Engineer (updated).pdf', 'page': 35, 'total_pages': 36, 'format': 'PDF 1.4', 'title': 'Panaversity Cloud Native Applied Generative AI Engineer', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Skia/PDF m128 Google Docs Renderer', 'creationDate': '', 'modDate': '', 'trapped': ''}, page_content='of security data in real time, identifying anomalies, and suggesting\\nappropriate countermeasures.\\n●\\nEnhance security monitoring and analysis: GenAI can assist\\nsecurity analysts in monitoring and analysing security logs, automating\\nthreat detection, and providing insights into security risks and\\nvulnerabilities.\\n●\\nImprove threat intelligence: GenAI can be used to gather and\\nanalyse threat intelligence from various sources, enabling\\norganisations to stay informed about the latest threats and trends and\\nproactively strengthen their security posture.\\n36')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=300)\n",
    "text_chunks = splitter.split_documents(doc_pages)\n",
    "text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['text'], template='\\nPlease summarize the following text:\\nText: {text}\\nSummary:\\n')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_prompt = \"\"\"\n",
    "Please summarize the following text:\n",
    "Text: {text}\n",
    "Summary:\n",
    "\"\"\"\n",
    "map_prompt_template = PromptTemplate(input_variables=[\"text\"], template=chunks_prompt)\n",
    "map_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary_prompt = \"\"\"\n",
    "Provide the final summary of the entire document with these important points:\n",
    "Add a suitable title then start the summary in proper markdown format:\n",
    "\n",
    "Summary: {text}\n",
    "\"\"\"\n",
    "final_prompt_template = PromptTemplate(input_variables=[\"text\"], template=final_summary_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\", api_key=os.getenv(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Please summarize the following text:\n",
      "Text: Certified Cloud Native Applied\n",
      "Generative AI Engineer\n",
      "Master the Future\n",
      "Build Custom GPTs, AI Agents, Humanoids, and Fine-Tune LLMs\n",
      "Version: 12.5 (Implementation and adoption starting from August 1, 2024)\n",
      "Today's pivotal technological trends are Cloud Native (CN), Generative AI (GenAI),\n",
      "and Physical AI. Cloud Native technology offers a scalable and dependable platform\n",
      "for application operation, while AI equips these applications with intelligent,\n",
      "human-like capabilities. Physical AI aims to bridge the gap between digital\n",
      "intelligence and physical capability, creating systems that can understand and\n",
      "interact with the world in a human-like manner. Our aim is to train you to excel as a\n",
      "Cloud Native Applied Generative and Physical AI developer globally.\n",
      "The Cloud Native Applied Generative AI Certification program equips you to create\n",
      "leading-edge Cloud Native AI and Physical AI solutions using a comprehensive\n",
      "cloud-native, AI, and Physical AI platform.\n",
      "Everything will soon be represented by a conversational interface, or to put it another\n",
      "way, a personal AI, we will cover it extensively in this program. () Currently, OpenAI\n",
      "Custom GPT Platform is the best platform to develop personal AI.\n",
      "Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Please summarize the following text:\n",
      "Text: We will also be covering AI agents, which are autonomous programs or entities that\n",
      "perceive their environment through sensors, process this information, and take\n",
      "actions to achieve specific goals or tasks. They can operate independently, adapt to\n",
      "changing conditions, and make decisions based on their observations and\n",
      "objectives.\n",
      "Material to Understand the Coming AI Age:\n",
      "●\n",
      "Watch the Overview Video of Our Program\n",
      "●\n",
      "Watch AGI could Double GDP\n",
      "●\n",
      "Watch Personal AI Short Video\n",
      "●\n",
      "The Future Is Agentic\n",
      "●\n",
      "The INSANE Race for AI Humanoid Robots\n",
      "●\n",
      "What Is an AI Anyway? Mustafa Suleyman\n",
      "●\n",
      "The Coming Wave: Technology, Power, and the 21st Century’s Greatest\n",
      "Dilemma\n",
      "●\n",
      "The Worlds I See: Curiosity, Exploration, and Discovery at the Dawn of AI\n",
      "●\n",
      "Ethan Mollick’s Substack\n",
      "●\n",
      "David Autor Lecture\n",
      "●\n",
      "Conversation between Suleyman, Yuval Noah Harari, and Zanny Minton\n",
      "Beddoes\n",
      "This twenty one month program equips you with the skills to thrive in the age of\n",
      "Generative AI (GenAI), Physical AI, and cloud native computing (CN). You will\n",
      "become an expert Custom GPT, AI Agent, and Humanoid Robotics Developer. The\n",
      "program is divided into two levels: foundation level and professional level. Students\n",
      "will be able to start working after completing the foundation level. They will\n",
      "continue their professional level studies while working.\n",
      "Why This Program?\n",
      "●\n",
      "Cutting-Edge Skills: Develop in-demand skills to build intelligent, scalable\n",
      "cloud applications using Generative AI and Cloud Native technologies.\n",
      "●\n",
      "Industry-Ready: Prepare for global certifications, startup and freelance\n",
      "opportunities after just six months.\n",
      "●\n",
      "Future-Proof Your Career: Stay ahead of the curve in a rapidly evolving tech\n",
      "landscape.\n",
      "What You'll Learn:\n",
      "●\n",
      "Custom GPTs and Multi AI Agent Systems: Learn to fine-tuning\n",
      "foundational AI models, and market them in GPT stores. Learn key principles\n",
      "of designing effective AI agents, and organising a team of AI agents to\n",
      "2\n",
      "Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Please summarize the following text:\n",
      "Text: perform complex, multi-step tasks. Apply these concepts to automate\n",
      "common business processes.\n",
      "●\n",
      "Develop AI Powered Microservices: Master Python, build APIs using\n",
      "FastAPI, SQLModel, Postgres, Kafka, Kong, and leverage cutting-edge GenAI\n",
      "APIs like OpenAI, and Open Source AI LLMs.\n",
      "●\n",
      "Cloud Native Expertise: Design and deploy cloud-native applications using\n",
      "Docker, DevContainers, TestContainers, Kubernetes, Terraform, and GitHub\n",
      "Actions.\n",
      "●\n",
      "Distributed System Design: Designing systems that run on multiple\n",
      "computers (or nodes) simultaneously, interacting and coordinating their\n",
      "actions by passing messages over a network.\n",
      "●\n",
      "Designing AI Solutions using Design Thinking and Behaviour Driven\n",
      "Development (BDD): We will learn to leverage these methodologies to create\n",
      "AI solutions that are not only technically sound but also highly user-centric\n",
      "and aligned with real-world needs.\n",
      "●\n",
      "Fine-Tuning Open-Source Large Language Models using PyTorch, and\n",
      "Fast AI: We will learn to fine-tuning of open-source Large Language Models\n",
      "(LLMs) like Meta LLaMA 3 using PyTorch and Fast AI, with a focus on\n",
      "cloud-native training and deployment. We will set up development\n",
      "environments, preprocess data, fine-tune models, and deploy them using\n",
      "cloud native platforms.\n",
      "●\n",
      "Physical AI and Humanoid Robotics: We will learn to design, simulate, and\n",
      "deploy advanced humanoid robots capable of natural interactions.\n",
      "Flexible Learning:\n",
      "●\n",
      "Earn While You Learn: Start freelancing or contributing to projects after the\n",
      "third quarter.\n",
      "Program Structure (Foundation: 3 + Professional: 4 = Total: 7 Quarters):\n",
      "Foundation Level (3 Quarters)\n",
      "●\n",
      "Quarter 1: Fundamentals of Prompt Engineering, Docker, GitHub, and\n",
      "Modern Python Programming\n",
      "We begin the course by understanding the basics of GenAI and Prompt\n",
      "Engineering. Then we will understand the basics of Linux, Docker, VSCode,\n",
      "Devcontainer, and GitHub. The main focus will be on mastering the\n",
      "fundamentals of Modern Python with Typing, the go-to language for AI.\n",
      "○\n",
      "Certification:\n",
      "■\n",
      "Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Please summarize the following text:\n",
      "Text: We begin the course by understanding the basics of GenAI and Prompt\n",
      "Engineering. Then we will understand the basics of Linux, Docker, VSCode,\n",
      "Devcontainer, and GitHub. The main focus will be on mastering the\n",
      "fundamentals of Modern Python with Typing, the go-to language for AI.\n",
      "○\n",
      "Certification:\n",
      "■\n",
      "Certified Professional Python Programmer (CPPP1)\n",
      "3\n",
      "Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Please summarize the following text:\n",
      "Text: Learning Repo:\n",
      "https://github.com/panaversity/learn-cloud-native-modern-python\n",
      "●\n",
      "Quarter 2: Applied Generative AI Fundamentals: Prompt Engineering,\n",
      "Developing Custom GPTs and Multi AI Agent Systems\n",
      "With this course, you’ll start by building a strong understanding of generative\n",
      "AI and learn how to apply Large language models (LLMs) and diffusion\n",
      "models practically. We will introduce a set of principles known as prompt\n",
      "engineering, which will help developers to work efficiently with AI. Learn to\n",
      "create custom AI models and GPTs using OpenAI, Azure, and Google\n",
      "technologies. Use open source libraries, like Langchain, CrewAI, and\n",
      "LangGraph to automate repeatable, multi-step tasks and automate business\n",
      "processes that are typically done by a group of people.\n",
      "Certifications:\n",
      "■\n",
      "Microsoft Certified: Azure AI Engineer Associate\n",
      "■\n",
      "Certified crewAI Engineer\n",
      "Learning Repo:\n",
      "https://github.com/panaversity/learn-applied-generative-ai-fundamentals/\n",
      "●\n",
      "Quarter 3: Cloud Native AI Powered Microservices Design, Development,\n",
      "and Deployment:\n",
      "Build scalable AI Powered APIs using FastAPI, Postgres, Kafka, Kong, GenAI\n",
      "APIs like OpenAI Chat Completion APIs, Assistant APIs, LangChain and\n",
      "Open Source AI LLMs, develop them using Containers and Dev Containers,\n",
      "and deploy them using Docker Compose locally and Kubernetes Powered\n",
      "Serverless Container Services on the cloud.\n",
      "We will also learn to integrate design thinking and Behavior-Driven\n",
      "Development (BDD) in developing AI systems. We will learn to create AI\n",
      "solutions that are deeply aligned with user needs and expectations. Design\n",
      "thinking ensures a thorough understanding of the user and problem space,\n",
      "while BDD provides a structured approach to defining and validating the\n",
      "desired behaviours of the AI system. Together, these methodologies lead to\n",
      "the development of AI solutions that are not only technically robust but also\n",
      "highly user-centric and effective in solving real-world problems.\n",
      "○\n",
      "Certifications:\n",
      "■\n",
      "PostgreSQL 13 Associate Certification\n",
      "■\n",
      "Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Please summarize the following text:\n",
      "Text: desired behaviours of the AI system. Together, these methodologies lead to\n",
      "the development of AI solutions that are not only technically robust but also\n",
      "highly user-centric and effective in solving real-world problems.\n",
      "○\n",
      "Certifications:\n",
      "■\n",
      "PostgreSQL 13 Associate Certification\n",
      "■\n",
      "Confluent Certified Developer for Apache Kafka (CCDAK)\n",
      "4\n",
      "Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Please summarize the following text:\n",
      "Text: ■\n",
      "Design Thinking Professional Certificate (DTPC)\n",
      "■\n",
      "Test and Behavior Driven Development (TDD/BDD)\n",
      "Learning Repo:\n",
      "https://github.com/panaversity/learn-cloud-native-ai-powered-microservices/\n",
      "We Will Be Using Microsoft Azure as our Default Cloud Platform\n",
      "Amazon is still the cloud king based on market share. But many analysts\n",
      "agree: In the battle for the cloud, AI is now a game-changer — and Amazon's\n",
      "main competitors, particularly Microsoft, have the momentum.\n",
      "In our program we will be using Azure as our default provider for teaching and\n",
      "deployment. We will be using using these services:\n",
      "Get a free Azure Account now:\n",
      "https://azure.microsoft.com/en-us/free\n",
      "Note: Use GitHub Account to start an Azure free trial\n",
      "Azure Container Apps (We will Start from this service using Dapr and Keda)\n",
      "https://azure.microsoft.com/en-us/products/container-apps\n",
      "Get started with the free tier: The first 180,000 vCPU per second, 360,000\n",
      "GiB/s, and 2 million requests each month are free.\n",
      "Watch: https://www.youtube.com/watch?v=0HwQfsa03K8\n",
      "Deploy:\n",
      "https://learn.microsoft.com/en-us/azure/container-apps/code-to-cloud-options\n",
      "Azure Container Registry\n",
      "https://azure.microsoft.com/en-us/products/container-registry/\n",
      "Deploy to Azure Container Apps with GitHub Actions\n",
      "https://learn.microsoft.com/en-us/azure/container-apps/github-actions\n",
      "Azure Kubernetes Service (AKS)\n",
      "https://azure.microsoft.com/en-us/products/kubernetes-service\n",
      "GitHub\n",
      "https://azure.microsoft.com/en-us/products/github/\n",
      "GitHub Actions for AKS\n",
      "https://learn.microsoft.com/en-us/azure/aks/kubernetes-action\n",
      "5\n",
      "Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Please summarize the following text:\n",
      "Text: Azure OpenAI Service\n",
      "https://azure.microsoft.com/en-us/products/ai-services/openai-service\n",
      "Azure Database for PostgreSQL\n",
      "https://azure.microsoft.com/en-us/products/postgresql/\n",
      "Kafka\n",
      "https://cloudatlas.me/5-different-ways-you-can-run-apache-kafka-on-azure-97\n",
      "3a18925ac7\n",
      "Professional Level (4 Quarters)\n",
      "●\n",
      "Quarter 4: Generative AI with PyTorch:\n",
      "Generative AI tools like ChatGPT, Gemini, and DALL-E have revolutionised\n",
      "our professional landscape. This hands-on course, “Master Generative AI with\n",
      "PyTorch,” guides you through the exciting process of building and training AI\n",
      "models using Python and the versatile, open-source PyTorch framework, all\n",
      "with the hardware you already have. You’ll delve into the core concepts of\n",
      "Generative Adversarial Networks (GANs), Transformers, Large Language\n",
      "Models (LLMs), variational autoencoders, diffusion models, LangChain, and\n",
      "more. Along the way, you’ll gain practical experience and a deep\n",
      "understanding of these cutting-edge technologies.\n",
      "Learning Repo: https://github.com/panaversity/genai-with-pytorch\n",
      "●\n",
      "Quarter 5: Fine-Tuning Open-Source Large Language Models:\n",
      "This comprehensive course is designed to guide learners through the process\n",
      "of fine-tuning open-source Large Language Models (LLMs) such as Meta\n",
      "LLaMA 3 using PyTorch, with a particular emphasis on cloud-native training\n",
      "and deployment. The course covers everything from the fundamentals to\n",
      "advanced concepts, ensuring students acquire both theoretical knowledge\n",
      "and practical skills.\n",
      "The journey begins with an introduction to LLMs, focusing on their\n",
      "architecture, capabilities, and the specific features of Meta LLaMA 3. Next, the\n",
      "course dives into PyTorch fundamentals, teaching students how to perform\n",
      "basic operations with tensors and build simple neural networks. This\n",
      "6\n",
      "Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Please summarize the following text:\n",
      "Text: foundation is crucial for understanding the mechanics behind LLMs. Data\n",
      "preparation is a crucial aspect of training models. The course covers\n",
      "comprehensive data collection and preprocessing techniques, such as\n",
      "tokenization and text normalisation. These steps are essential for preparing\n",
      "datasets suitable for fine-tuning LLMs like Meta LLaMA 3. Through practical\n",
      "exercises, students learn how to handle and preprocess various types of text\n",
      "data, ensuring they can prepare their datasets for optimal model performance.\n",
      "Fine-tuning Meta LLaMA 3 with PyTorch forms a significant part of the course.\n",
      "Students will delve into the architecture of Meta LLaMA 3, learn how to load\n",
      "pre-trained models, and apply fine-tuning techniques. The course covers\n",
      "advanced topics such as regularisation and optimization strategies to\n",
      "enhance model performance. Practical sessions guide students through the\n",
      "entire fine-tuning process on custom datasets, emphasising best practices\n",
      "and troubleshooting techniques.\n",
      "A critical aspect of this course is its focus on cloud-native training and\n",
      "deployment using Nvidia NIM. Furthermore, students learn how to deploy\n",
      "models using Docker and Kubernetes, set up monitoring and maintenance\n",
      "tools, and ensure their models are scalable and efficient.\n",
      "To round off the learning experience, the course includes an in-depth segment\n",
      "on exporting models for inference and building robust inference pipelines.\n",
      "Students will deploy models on cloud platforms, focusing on practical aspects\n",
      "of setting up monitoring tools to maintain model performance and reliability.\n",
      "The course culminates in a capstone project, where students apply all the\n",
      "skills they have learned to fine-tune and deploy Meta LLaMA 3 on a chosen\n",
      "platform. This project allows students to demonstrate their understanding and\n",
      "proficiency in the entire process, from data preparation to cloud-native\n",
      "deployment.\n",
      "Learning Repo:\n",
      "https://github.com/panaversity/learn-fine-tuning-llms\n",
      "●\n",
      "Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Please summarize the following text:\n",
      "Text: platform. This project allows students to demonstrate their understanding and\n",
      "proficiency in the entire process, from data preparation to cloud-native\n",
      "deployment.\n",
      "Learning Repo:\n",
      "https://github.com/panaversity/learn-fine-tuning-llms\n",
      "●\n",
      "Quarter 6: Physical AI and Humanoid Robotics Development:\n",
      "Artificial intelligence (AI) has experienced remarkable advancements in recent\n",
      "years. However, the future of AI extends beyond the digital space into the\n",
      "physical world, driven by robotics. This new frontier, known as “Physical AI,”\n",
      "involves AI systems that can function in the real world and comprehend\n",
      "physical laws. This marks a notable transition from AI models confined to\n",
      "digital environments. Humanoid robots are poised to excel in our\n",
      "7\n",
      "Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Please summarize the following text:\n",
      "Text: human-centred world because they share our physical form and can be\n",
      "trained with abundant data from interacting in human environments.\n",
      "This course provides an in-depth exploration of humanoid robotics, focusing\n",
      "on the integration of ROS 2 (Robot Operating System), Open Source Meta\n",
      "Llama 3, and OpenAI technologies. Students will learn to design, simulate,\n",
      "and deploy advanced humanoid robots capable of natural interactions. The\n",
      "curriculum covers essential topics such as ROS 2 for robotic control,\n",
      "simulations with Gazebo and Unity, and using OpenAI’s GPT models for\n",
      "conversational AI. Through practical projects and real-world applications,\n",
      "students will develop the skills needed to drive innovation in humanoid\n",
      "robotics.\n",
      "Learning Repo:\n",
      "https://github.com/panaversity/learn-physical-ai-humanoid-robotics\n",
      "●\n",
      "Quarter 7: Kubernetes and Distributed System Design:\n",
      "Master Kubernetes, Terraform, and GitHub Actions to deploy your AI APIs and\n",
      "microservices in the cloud. We will cover distributed system design involving\n",
      "creating systems that are distributed across multiple nodes, focusing on\n",
      "scalability, fault tolerance, consistency, availability, and partition tolerance.\n",
      "Certifications:\n",
      "■\n",
      "Certified Kubernetes Application Developer (CKAD)\n",
      "■\n",
      "HashiCorp Certified: Terraform Associate\n",
      "Learning Repo: https://github.com/panaversity/learn-kubernetes\n",
      "Frontend Specialisation\n",
      "●\n",
      "Quarter 8: Front-end Web GUI Development using Next.js and\n",
      "TypeScript (Optional):\n",
      "Next.js is designed to handle complex front-end applications well, making it a\n",
      "good fit for AI applications that might grow in features and data usage over\n",
      "time. Next.js offers features like API routes and file-based routing, which can\n",
      "streamline development for AI applications that need to interact with backend\n",
      "APIs and manage different application views. While Next.js and TypeScript\n",
      "8\n",
      "Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Please summarize the following text:\n",
      "Text: aren't the only options for building AI application frontends, their focus on\n",
      "performance, scalability, and developer experience makes them a compelling\n",
      "choice for many developers.\n",
      "Learning Repo:\n",
      "https://github.com/panaverse/learn-nextjs\n",
      "9\n",
      "Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Please summarize the following text:\n",
      "Text: In 2015, Klaus Schwab, founder of the World Economic Forum, asserted that we\n",
      "were on the brink of a “Fourth Industrial Revolution,” one powered by a fusion of\n",
      "technologies, such as advanced robotics, artificial intelligence, and the Internet of\n",
      "Things.\n",
      "“[This revolution] will fundamentally alter the way we live, work, and relate to one\n",
      "another,” wrote Schwab in an essay published in Foreign Affairs. “In its scale, scope,\n",
      "and complexity, the transformation will be unlike anything humankind has\n",
      "experienced before.”\n",
      "Generative AI is set to revolutionise our daily lives and work environments.\n",
      "According to McKinsey & Company, generative AI could contribute an annual\n",
      "economic value of $2.6 trillion to $4.4 trillion across various sectors by enhancing\n",
      "automation, bolstering decision-making, and providing personalised experiences.\n",
      "Investor Cathie Wood predicts that the market for humanoid robots could grow to $1\n",
      "trillion by 2030.\n",
      "Cloud native is an approach in software development that enables application\n",
      "creation, deployment, and management in cloud environments. It involves\n",
      "constructing applications as a collection of small, interconnected services known as\n",
      "microservices, a shift from traditional monolithic structures. This modular approach\n",
      "enhances the agility of cloud-native applications, allowing them to operate more\n",
      "efficiently with fewer resources.\n",
      "Cloud Native has already been adopted by the majority of the companies, by 2024,\n",
      "more than 90% of global organisations will be running containerized applications in\n",
      "production. The adoption of Docker and Kubernetes has seen significant growth over\n",
      "recent years. As of 2022, about 61% of organisations reported using Kubernetes for\n",
      "container orchestration. This number has been steadily increasing as more\n",
      "companies realise the benefits of these technologies for managing containerized\n",
      "applications ￼￼.\n",
      "Technologies such as Kubernetes, Docker, serverless containers, APIs, SQL\n",
      "Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Please summarize the following text:\n",
      "Text: container orchestration. This number has been steadily increasing as more\n",
      "companies realise the benefits of these technologies for managing containerized\n",
      "applications ￼￼.\n",
      "Technologies such as Kubernetes, Docker, serverless containers, APIs, SQL\n",
      "Databases, and Kafka support developers in swiftly constructing cloud-native\n",
      "applications. These tools offer a standardised platform for application development\n",
      "and management across various cloud services like Azure, Google Cloud, and AWS.\n",
      "This revolution is pivotal for technology and job landscapes, making it essential\n",
      "knowledge in fast-evolving tech cycles. The rapid emergence of Gen AI-powered\n",
      "and Physical AI technologies, and the evolving demand for skills necessitate\n",
      "extensive and timely professional training.\n",
      "10\n",
      "Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Please summarize the following text:\n",
      "Text: Vertical Specialization Level\n",
      "Students will have the option of selecting one of the following specialisations after\n",
      "the completion of sixth quarter i.e. in the seventh quarter:\n",
      "1. Healthcare and Medical GenAI Specialization\n",
      "2. Web3, Blockchain, and GenAI Integration Specialization\n",
      "3. Metaverse, 3D, and GenAI Integration Specialization\n",
      "4. GenAI for Accounting, Finance, and Banking Specialization\n",
      "5. GenAI for Engineers Specialization\n",
      "6. GenAI for Sales and Marketing Specialization\n",
      "7. GenAI for Automation and Internet of Things (IoT) Specialisation\n",
      "8. GenAI for Cyber Security\n",
      "Common Questions (FAQs) with Detailed Answers\n",
      "1. What is Cloud Native Applied Generative AI Engineering?\n",
      "Cloud Applied Generative AI Engineering (GenEng) is the application of\n",
      "generative AI technologies to solve real-world problems in the cloud.\n",
      "●\n",
      "Generative AI is a type of artificial intelligence that can create new data\n",
      "or content from existing data.\n",
      "●\n",
      "Cloud Native computing is the delivery of computing\n",
      "services—including servers, storage, databases, networking, software,\n",
      "analytics, and intelligence—over the Internet (“the cloud”).\n",
      "By combining generative AI with cloud native computing, businesses can\n",
      "solve a variety of problems, such as:\n",
      "●\n",
      "Creating personalised experiences for customers\n",
      "●\n",
      "Automating tasks\n",
      "●\n",
      "Improving decision-making\n",
      "●\n",
      "Detecting fraud\n",
      "●\n",
      "Developing new products and services\n",
      "The potential applications of cloud native-applied generative AI are endless.\n",
      "As generative AI and cloud native computing continue to develop, we can\n",
      "expect to see even more innovative and groundbreaking uses for this\n",
      "technology.\n",
      "2. How valuable are the Cloud Native Applied Generative AI developers?\n",
      "Developers with expertise in Cloud Native Applied Generative AI were in\n",
      "extremely high demand due to the increasing adoption of GenAI technologies\n",
      "across various industries. However, the supply of developers skilled\n",
      "11\n",
      "Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Please summarize the following text:\n",
      "Text: specifically in this niche area might not have been as abundant compared to\n",
      "more generalised AI or cloud computing roles.\n",
      "The demand for AI developers, especially those proficient in applying\n",
      "generative AI techniques within cloud native environments, has been rising\n",
      "due to the growing interest in using AI for creative applications, content\n",
      "generation, image synthesis, natural language processing, and other\n",
      "innovative purposes.\n",
      "According to some sources, the average salary for a Cloud Native Applied\n",
      "Generative AI developer in the global market is around $150,000 per year.\n",
      "However, this may vary depending on the experience level, industry, location,\n",
      "and skills of the developer. For example, a senior Cloud Applied Generative\n",
      "AI developer with more than five years of experience can earn up to $200,000\n",
      "per year. A Cloud Applied Generative AI developer working in the financial\n",
      "services industry can earn more than a developer working in the\n",
      "entertainment industry. A Cloud Applied Generative AI developer working in\n",
      "New York City can earn more than a developer working in Dubai. In general,\n",
      "highly skilled AI developers, especially those specialising in applied\n",
      "generative AI within cloud environments, tend to earn competitive salaries that\n",
      "are often above the average for software developers or AI engineers due to\n",
      "the specialised nature of their skills. Moreover, as generative AI technology\n",
      "becomes more widely adopted and integrated into various products and\n",
      "services, the demand for Cloud Applied Generative AI developers is likely to\n",
      "increase.\n",
      "Therefore, Cloud Applied Generative AI developers are valuable professionals\n",
      "who have a bright future ahead of them. They can leverage their creativity and\n",
      "technical skills to create innovative solutions that can benefit various\n",
      "industries and domains. They can also enjoy very competitive salary and\n",
      "career growth opportunities.\n",
      "3. What is the potential for Cloud Applied Generative AI Developers to start\n",
      "their own companies?\n",
      "Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Please summarize the following text:\n",
      "Text: technical skills to create innovative solutions that can benefit various\n",
      "industries and domains. They can also enjoy very competitive salary and\n",
      "career growth opportunities.\n",
      "3. What is the potential for Cloud Applied Generative AI Developers to start\n",
      "their own companies?\n",
      "Cloud Applied Generative AI Developers have a significant potential to start\n",
      "their own companies due to several factors:\n",
      "1. Emerging Field: Generative AI, particularly when applied within cloud\n",
      "environments, is still an evolving field with immense potential for innovation.\n",
      "Developers who understand the intricacies of both generative AI techniques\n",
      "and cloud technologies can identify unique opportunities to create novel\n",
      "products, services, or solutions.\n",
      "2. Market Demand: There is a growing demand for AI-driven applications,\n",
      "especially those that involve generative capabilities such as image\n",
      "12\n",
      "Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Please summarize the following text:\n",
      "Text: generation, content creation, style transfer, etc. Developers with expertise in\n",
      "this area can leverage this demand to create specialized products that cater\n",
      "to specific industries or consumer needs.\n",
      "3. Innovation and Differentiation: The ability to develop unique and innovative\n",
      "solutions using generative AI in the cloud can set apart these developers'\n",
      "startups from more conventional companies. They can explore new ways of\n",
      "generating content, enhancing user experiences, or solving complex problems\n",
      "with AI-generated solutions.\n",
      "4. Access to Cloud Resources: Cloud platforms provide scalable and\n",
      "cost-effective resources that are crucial for AI development. Developers\n",
      "starting their own companies can leverage cloud services to access powerful\n",
      "computing resources, storage, and AI-related services without significant\n",
      "upfront investment.\n",
      "5. Entrepreneurial Opportunities: Developers with entrepreneurial spirit and a\n",
      "deep understanding of AI technologies can identify gaps in the market and\n",
      "build startups to fill those gaps. They can create platforms, tools, or services\n",
      "that simplify the adoption of generative AI for businesses or developers.\n",
      "6. Collaboration and Partnerships: These developers can collaborate with\n",
      "other experts in AI, domain specialists, or businesses to create innovative\n",
      "solutions or explore new application areas for generative AI in the cloud.\n",
      "However, starting a company, especially in a specialised field like Cloud\n",
      "Applied Generative AI, requires more than technical expertise. It also\n",
      "demands business acumen, understanding market needs, networking,\n",
      "securing funding, managing resources effectively, and navigating legal and\n",
      "regulatory landscapes.\n",
      "Successful entrepreneurship in this domain involves a combination of\n",
      "technical skills, innovation, a deep understanding of market dynamics, and the\n",
      "ability to transform technical expertise into viable products or services that\n",
      "address real-world challenges or opportunities.\n",
      "Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Please summarize the following text:\n",
      "Text: regulatory landscapes.\n",
      "Successful entrepreneurship in this domain involves a combination of\n",
      "technical skills, innovation, a deep understanding of market dynamics, and the\n",
      "ability to transform technical expertise into viable products or services that\n",
      "address real-world challenges or opportunities.\n",
      "Developers aspiring to start their own companies in the Cloud Applied\n",
      "Generative AI space can do so by conducting thorough market research,\n",
      "networking with industry experts, building a strong team, and developing a\n",
      "clear business plan that highlights the unique value proposition of their\n",
      "offerings.\n",
      "To sum up, the potential for Cloud Applied Generative AI Developers to start\n",
      "their own companies is high.\n",
      "●\n",
      "Generative AI is a rapidly growing field with a high demand for skilled\n",
      "professionals.\n",
      "13\n",
      "Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Please summarize the following text:\n",
      "Text: ●\n",
      "The Certified Generative AI (GenEng) Developer and Engineering\n",
      "Program provides students with the skills and knowledge they need to\n",
      "develop and apply cutting-edge generative AI technologies.\n",
      "●\n",
      "The program also teaches students how to start and run a successful\n",
      "business.\n",
      "●\n",
      "Graduates of the program will be well-positioned to start their own\n",
      "companies and capitalise on the growing demand for generative AI\n",
      "solutions.\n",
      "4. Is the program not too long, twenty one months is a long time?\n",
      "The length of the program is twenty one months which is broken down into\n",
      "seven quarters of three months each. The program covers a wide range of\n",
      "topics including Python, GenAI, Microservices, Database, Cloud\n",
      "Development, Fine-tuning, DevOps, GPTs, AI Agents, and Humanoids. The\n",
      "program is designed to give students a comprehensive understanding of\n",
      "generative AI and prepare them for careers in this field. Nothing valuable can\n",
      "be achieved overnight, there are no shortcuts in life.\n",
      "5. Why don't we use TypeScript (Node.js) to develop APIs instead of using\n",
      "Python?\n",
      "We will not use Typescript in GenAI API development because Python is a\n",
      "priority with the AI community when working with AI and if any updates come\n",
      "in libraries they will first come for Python. Python is always a better choice\n",
      "when dealing with AI and API.\n",
      "●\n",
      "Python is the de facto standard for AI Development.\n",
      "●\n",
      "TypeScript is a more modern language that is gaining popularity for\n",
      "Web Development, but Python is more widely used and has a larger\n",
      "ecosystem of libraries and frameworks available, especially for AI.\n",
      "●\n",
      "TypeScript is used for web user interfaces, while Python is used for\n",
      "APIs.\n",
      "●\n",
      "In the second quarter, students will learn to develop APIs using Python\n",
      "instead of TypeScript.\n",
      "●\n",
      "Python is a more commonly used language for AI and API\n",
      "development, and it has a larger ecosystem of libraries and\n",
      "frameworks available for these purposes.\n",
      "●\n",
      "TypeScript is a more modern language that is becoming increasingly\n",
      "Summary:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Provide the final summary of the entire document with these important points:\n",
      "Add a suitable title then start the summary in proper markdown format:\n",
      "\n",
      "Summary: Here is a summary of the text:\n",
      "\n",
      "The Certified Cloud Native Applied Generative AI Engineer program aims to train developers to excel in creating Cloud Native AI and Physical AI solutions. The program covers the latest technological trends, including Cloud Native, Generative AI, and Physical AI, and equips students with the skills to build custom GPTs, AI agents, humanoids, and fine-tune large language models (LLMs). The program focuses on the OpenAI Custom GPT Platform and prepares students for a future where conversational interfaces and personal AI will become ubiquitous.\n",
      "\n",
      "Here is a summary of the text:\n",
      "\n",
      "**Program Overview**\n",
      "\n",
      "The program is a 21-month course that aims to equip students with the skills to thrive in the age of Generative AI, Physical AI, and cloud native computing. Students will become experts in Custom GPT, AI Agent, and Humanoid Robotics Development.\n",
      "\n",
      "**Course Objectives**\n",
      "\n",
      "* Understand AI agents and their capabilities\n",
      "* Develop in-demand skills in Generative AI and Cloud Native technologies\n",
      "* Prepare for global certifications and industry-ready opportunities\n",
      "* Stay ahead of the curve in a rapidly evolving tech landscape\n",
      "\n",
      "**Course Structure**\n",
      "\n",
      "* The program is divided into two levels: foundation level and professional level\n",
      "* Students can start working after completing the foundation level and continue their professional level studies while working\n",
      "\n",
      "**Recommended Reading and Viewing**\n",
      "\n",
      "The program suggests watching several videos and reading articles to understand the coming AI age, including a lecture by David Autor and a conversation between Mustafa Suleyman, Yuval Noah Harari, and Zanny Minton Beddoes.\n",
      "\n",
      "**Skills to be Learned**\n",
      "\n",
      "* Custom GPTs and Multi AI Agent Systems\n",
      "* Fine-tuning foundational AI models and marketing them in GPT stores\n",
      "* Designing effective AI agents and organizing a team of AI agents\n",
      "\n",
      "Here's a summary of the text:\n",
      "\n",
      "This program is designed to teach students how to develop complex AI and software systems. The program covers a wide range of topics, including:\n",
      "\n",
      "* Developing AI-powered microservices using Python and GenAI APIs\n",
      "* Cloud native expertise, including Docker, Kubernetes, and Terraform\n",
      "* Designing distributed systems and AI solutions using design thinking and BDD\n",
      "* Fine-tuning open-source large language models using PyTorch and Fast AI\n",
      "* Physical AI and humanoid robotics\n",
      "\n",
      "The program structure consists of 7 quarters, divided into 3 foundation quarters and 4 professional quarters. Here's a brief overview of what's covered in each quarter:\n",
      "\n",
      "* Quarter 1: Fundamentals of prompt engineering, Docker, GitHub, and modern Python programming\n",
      "* Foundation level (3 quarters): Build a strong foundation in AI, software development, and cloud native expertise\n",
      "* Professional level (4 quarters): Apply skills to develop complex AI and software systems, including AI-powered microservices, distributed systems, and more\n",
      "\n",
      "Throughout the program, students will have opportunities to earn money through freelancing or contributing to projects, starting from the third quarter.\n",
      "\n",
      "The text appears to be an overview of a course, which covers the basics of:\n",
      "\n",
      "1. General AI (GenAI) and Prompt Engineering\n",
      "2. Linux, Docker, VSCode, and GitHub\n",
      "3. Modern Python with Typing, specifically aiming to master its fundamentals\n",
      "\n",
      "The course also offers a certification, specifically the \"Certified Professional Python Programmer (CPPP1)\".\n",
      "\n",
      "Here is a summary of the text:\n",
      "\n",
      "The text describes a learning program with two quarters:\n",
      "\n",
      "**Quarter 2: Applied Generative AI Fundamentals**\n",
      "\n",
      "* Learn about generative AI, large language models, and diffusion models\n",
      "* Understand prompt engineering principles to work efficiently with AI\n",
      "* Create custom AI models and GPTs using OpenAI, Azure, and Google technologies\n",
      "* Automate repeatable tasks and business processes using open-source libraries\n",
      "* Earn certifications:\n",
      "\t+ Microsoft Certified: Azure AI Engineer Associate\n",
      "\t+ Certified crewAI Engineer\n",
      "\n",
      "**Quarter 3: Cloud Native AI Powered Microservices Design, Development, and Deployment**\n",
      "\n",
      "* Build scalable AI-powered APIs using FastAPI, Postgres, Kafka, and GenAI APIs\n",
      "* Develop and deploy AI solutions using containers, Dev Containers, Docker Compose, and Kubernetes\n",
      "* Integrate design thinking and Behavior-Driven Development (BDD) to create user-centric AI solutions\n",
      "* Earn certifications:\n",
      "\t+ PostgreSQL 13 Associate Certification\n",
      "\n",
      "The learning program is hosted on GitHub and includes a repository for each quarter.\n",
      "\n",
      "There is no text provided to summarize. It appears that the text you provided is incomplete, mentioning desired behaviors of an AI system and some certifications, but no further information is given. If you provide the complete text, I'll be happy to help you summarize it.\n",
      "\n",
      "Here is a summary of the text:\n",
      "\n",
      "* The program will focus on Cloud Native AI-Powered Microservices and will use Microsoft Azure as the default cloud platform.\n",
      "* The program will cover the following topics:\n",
      "\t+ Design Thinking Professional Certificate (DTPC)\n",
      "\t+ Test and Behavior Driven Development (TDD/BDD)\n",
      "\t+ Azure Container Apps\n",
      "\t+ Azure Container Registry\n",
      "\t+ Azure Kubernetes Service (AKS)\n",
      "\t+ GitHub and GitHub Actions\n",
      "* The program will use Dapr and Keda with Azure Container Apps.\n",
      "* A free Azure account is required for the program, which can be obtained by linking a GitHub account to start a free trial.\n",
      "* The program will provide resources and tutorials for each topic, including videos and documentation from Microsoft.\n",
      "\n",
      "The text appears to be a summary of a professional development program with a focus on artificial intelligence (AI) and machine learning (ML). The program is divided into two quarters:\n",
      "\n",
      "**Quarter 4:**\n",
      "\n",
      "* The course \"Master Generative AI with PyTorch\" teaches students how to build and train AI models using PyTorch, covering topics such as:\n",
      "\t+ Generative Adversarial Networks (GANs)\n",
      "\t+ Transformers\n",
      "\t+ Large Language Models (LLMs)\n",
      "\t+ Variational autoencoders\n",
      "\t+ Diffusion models\n",
      "\t+ LangChain\n",
      "\n",
      "**Quarter 5:**\n",
      "\n",
      "* The course \"Fine-Tuning Open-Source Large Language Models\" teaches students how to fine-tune open-source LLMs, specifically Meta LLaMA 3, using PyTorch, with a focus on cloud-native training and deployment.\n",
      "* Topics covered include:\n",
      "\t+ Introduction to LLMs and their architecture\n",
      "\t+ PyTorch fundamentals (tensors, neural networks)\n",
      "\t+ Advanced concepts for fine-tuning LLMs\n",
      "\n",
      "The program is designed to provide learners with both theoretical knowledge and practical skills in the field of AI and ML.\n",
      "\n",
      "Here is a summary of the text:\n",
      "\n",
      "This course covers the entire process of fine-tuning a Large Language Model (LLM) like Meta LLaMA 3, from data preparation to cloud-native deployment. Key topics include:\n",
      "\n",
      "* Comprehensive data collection and preprocessing techniques (tokenization, text normalization, etc.)\n",
      "* Fine-tuning Meta LLaMA 3 with PyTorch, including loading pre-trained models and applying regularisation and optimization strategies\n",
      "* Cloud-native training and deployment using Nvidia NIM, Docker, and Kubernetes\n",
      "* Exporting models for inference and building robust inference pipelines\n",
      "* Deploying models on cloud platforms and setting up monitoring tools for model performance and reliability\n",
      "\n",
      "The course culminates in a capstone project where students fine-tune and deploy Meta LLaMA 3 on a chosen platform, demonstrating their understanding and proficiency in the entire process.\n",
      "\n",
      "Here is a summary of the text:\n",
      "\n",
      "This project allows students to demonstrate their understanding of AI and cloud-native deployment. Additionally, the text mentions a new frontier in AI called \"Physical AI\" which involves AI systems that can function in the real world and comprehend physical laws, and notes that humanoid robots are poised to excel in this area.\n",
      "\n",
      "The provided text does not explicitly have 8 options but mentions various training topics across several \"Quarters\" that offer specific specializations or learning experiences in different fields such as AI and Robotics. The options that have specific training names associated with them can be summarized as follows:\n",
      "\n",
      "- Quarter 6 seems to focus on AI for robotics and has detailed curriculums focusing on the development and simulation of advanced humanoid robots with interaction capabilities through tools and models provided by various technology leaders.\n",
      "  \n",
      "- Quarter 7 specializes in Cloud Architecture for distributed system design focusing on systems distributed across nodes ensuring key requirements are met - this seems to come with optional certification, Master Kubernetes Developer for building complex application processes through advanced DevOps platforms including Kubernetes and Hashicorp certified Associate certifications through the Learning Repos provided on Github for source files, related issues and potentially problems documented, sorted based on them based.\n",
      "\n",
      "There doesn't appear to be much from what Quarter 8 options included Front-End specialization- because options indicate all within in given few info fields describing functionalities etc mainly when software develops either way after complete re working could clearly assume anything listed overall covered skills while different here across quite set possibly-\n",
      "\n",
      "There is no text to summarize. The text you provided starts in the middle of a sentence, and there is no mention of what the text is summarizing. However, based on the context, it appears to be a brief mention of Next.js, a technology for building AI application frontends, and mentions a link to a repository for learning Next.js.\n",
      "\n",
      "Here's a summary of the text:\n",
      "\n",
      "The World Economic Forum's founder, Klaus Schwab, predicted in 2015 that the world was on the cusp of a \"Fourth Industrial Revolution\" driven by emerging technologies such as advanced robotics, AI, and the Internet of Things. Fast forward to today, and these technologies are now set to transform our lives and workplaces. Specifically:\n",
      "\n",
      "* Generative AI is expected to generate $2.6 trillion to $4.4 trillion in economic value annually by enhancing automation, decision-making, and personalized experiences.\n",
      "* Humanoid robots could reach a market value of $1 trillion by 2030.\n",
      "* Cloud Native, an approach to software development, is becoming increasingly popular, with over 90% of global organizations expected to use containerized applications in production by 2024.\n",
      "* Technologies like Kubernetes, Docker, and serverless containers are driving this shift, with 61% of organizations already using Kubernetes for container orchestration in 2022.\n",
      "\n",
      "Overall, these emerging technologies are expected to revolutionize our daily lives and work environments, bringing significant economic benefits and transforming the way we live and work.\n",
      "\n",
      "Here is a summary of the text:\n",
      "\n",
      "The adoption of container orchestration technologies, such as Kubernetes and Docker, is increasing rapidly as companies realize the benefits of managing containerized applications. These technologies, along with others like APIs, databases, and serverless containers, are essential for building cloud-native applications and provide a standardized platform for development and management across various cloud services. As a result, professionals in the tech industry need to stay up-to-date with the latest skills and technologies, particularly with the emergence of Gen AI and Physical AI technologies.\n",
      "\n",
      "Here is a summary of the text:\n",
      "\n",
      "The text describes a program that allows students to specialize in various areas after completing their 6th quarter. The specializations include:\n",
      "\n",
      "1. Healthcare and Medical GenAI\n",
      "2. Web3, Blockchain, and GenAI Integration\n",
      "3. Metaverse, 3D, and GenAI Integration\n",
      "4. GenAI for Accounting, Finance, and Banking\n",
      "5. GenAI for Engineers\n",
      "6. GenAI for Sales and Marketing\n",
      "7. GenAI for Automation and IoT\n",
      "8. GenAI for Cyber Security\n",
      "\n",
      "Additionally, the text explains what Cloud Native Applied Generative AI Engineering (GenEng) is, including:\n",
      "\n",
      "* Generative AI: a type of AI that creates new data or content from existing data\n",
      "* Cloud Native computing: delivering computing services over the Internet\n",
      "* The potential applications of GenEng, including creating personalized experiences, automating tasks, and improving decision-making\n",
      "\n",
      "The text also notes that developers with expertise in GenEng are in high demand due to the increasing adoption of GenAI technologies, but the supply of skilled developers is limited.\n",
      "\n",
      "Here is a summary of the text:\n",
      "\n",
      "The demand for Cloud Native Applied Generative AI developers is high due to the growing interest in using AI for creative applications. These developers are in high demand and can earn competitive salaries, ranging from $150,000 to over $200,000 per year, depending on experience, industry, location, and skills. The industry expects the demand to increase as generative AI technology becomes more widely adopted. Cloud Applied Generative AI developers are valuable professionals with a bright future ahead, offering opportunities for creative innovation, competitive salaries, and career growth.\n",
      "\n",
      "Here is a summary of the text:\n",
      "\n",
      "Cloud Applied Generative AI Developers have a promising career with opportunities for:\n",
      "\n",
      "* Developing innovative solutions that can benefit various industries\n",
      "* High salary and career growth opportunities\n",
      "* Potentially starting their own companies, given the emerging and growing demand for AI-driven applications, particularly in generative capabilities.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Provide the final summary of the entire document with these important points:\n",
      "Add a suitable title then start the summary in proper markdown format:\n",
      "\n",
      "Summary: The text highlights six key opportunities for developers in the field of Cloud Applied Generative AI:\n",
      "\n",
      "1. **Meeting industry demand**: Developing specialized products that cater to specific industries or consumer needs.\n",
      "2. **Innovation and differentiation**: Creating unique and innovative solutions that set their startups apart from conventional companies.\n",
      "3. **Access to cloud resources**: Leveraging cloud services for scalable and cost-effective resources to develop AI solutions.\n",
      "4. **Entrepreneurial opportunities**: Identifying market gaps and building startups to fill them, creating platforms, tools, or services for businesses or developers.\n",
      "5. **Collaboration and partnerships**: Working with experts in AI, domain specialists, or businesses to create innovative solutions or explore new application areas.\n",
      "6. **Transforming technical expertise into viable products**: Turning technical skills and innovation into viable products or services that address real-world challenges or opportunities.\n",
      "\n",
      "However, the text also notes that successful entrepreneurship in this domain requires a combination of technical skills, innovation, market understanding, and business acumen.\n",
      "\n",
      "Here is a summary of the text:\n",
      "\n",
      "To be successful as a Cloud Applied Generative AI entrepreneur, one needs a combination of technical skills, innovation, market understanding, and the ability to turn technical expertise into viable products or services. To start a company in this space, developers should conduct market research, network with experts, build a strong team, and create a clear business plan highlighting their unique value proposition. The potential for entrepreneurship in this field is high due to the rapid growth and high demand for skilled professionals in Generative AI.\n",
      "\n",
      "Here's a summary of the text:\n",
      "\n",
      "**Certified GenEng Developer and Engineering Program**\n",
      "\n",
      "The program is designed to equip students with skills and knowledge in developing generative AI technologies, including business startup and growth. It takes 21 months (7 quarters) to complete, covering various topics such as Python, AI, database management, cloud development, and DevOps. The program prepares students for careers in generative AI and enables them to start their own companies.\n",
      "\n",
      "**Why Python and not TypeScript for GenAI development?**\n",
      "\n",
      "Python is the preferred language for AI and API development due to its wide use, large ecosystem of libraries, and timely updates in AI-related libraries. In contrast, TypeScript is better suited for web development, while Python excels at API development. In the second quarter, students will learn to develop APIs using Python instead of TypeScript.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Provide the final summary of the entire document with these important points:\n",
      "Add a suitable title then start the summary in proper markdown format:\n",
      "\n",
      "Summary: Here is a comprehensive summary of the entire document in proper markdown format:\n",
      "\n",
      "**Program Overview**\n",
      "===============\n",
      "\n",
      "The Certified Cloud Native Applied Generative AI Engineer program is a 21-month course that aims to equip students with the skills to thrive in the age of Generative AI, Physical AI, and cloud native computing.\n",
      "\n",
      "**Course Objectives**\n",
      "-------------------\n",
      "\n",
      "* Understand AI agents and their capabilities\n",
      "* Develop in-demand skills in Generative AI and Cloud Native technologies\n",
      "* Prepare for global certifications and industry-ready opportunities\n",
      "* Stay ahead of the curve in a rapidly evolving tech landscape\n",
      "\n",
      "**Course Structure**\n",
      "------------------\n",
      "\n",
      "* The program is divided into two levels: foundation level and professional level\n",
      "* Students can start working after completing the foundation level and continue their professional level studies while working\n",
      "\n",
      "**Recommended Reading and Viewing**\n",
      "---------------------------------\n",
      "\n",
      "The program suggests watching several videos and reading articles to understand the coming AI age, including a lecture by David Autor and a conversation between Mustafa Suleyman, Yuval Noah Harari, and Zanny Minton Beddoes.\n",
      "\n",
      "**Skills to be Learned**\n",
      "----------------------\n",
      "\n",
      "* Custom GPTs and Multi AI Agent Systems\n",
      "* Fine-tuning foundational AI models and marketing them in GPT stores\n",
      "* Designing effective AI agents and organizing a team of AI agents\n",
      "\n",
      "**Program Details**\n",
      "-----------------\n",
      "\n",
      "* The program covers a wide range of topics, including developing AI-powered microservices using Python and GenAI APIs, cloud native expertise, designing distributed systems and AI solutions using design thinking and BDD, fine-tuning open-source large language models using PyTorch and Fast AI, and Physical AI and humanoid robotics.\n",
      "* The program structure consists of 7 quarters, divided into 3 foundation quarters and 4 professional quarters.\n",
      "* Students will have opportunities to earn money through freelancing or contributing to projects, starting from the third quarter.\n",
      "\n",
      "**Certifications**\n",
      "----------------\n",
      "\n",
      "* The program offers several certifications, including the \"Certified Professional Python Programmer (CPPP1)\".\n",
      "\n",
      "**Specializations**\n",
      "-----------------\n",
      "\n",
      "* After completing the 6th quarter, students can specialize in various areas, including Healthcare and Medical GenAI, Web3, Blockchain, and GenAI Integration, Metaverse, 3D, and GenAI Integration, GenAI for Accounting, Finance, and Banking, GenAI for Engineers, GenAI for Sales and Marketing, GenAI for Automation and IoT, and GenAI for Cyber Security.\n",
      "\n",
      "**Career Opportunities**\n",
      "----------------------\n",
      "\n",
      "* Cloud Native Applied Generative AI developers are in high demand due to the growing interest in using AI for creative applications.\n",
      "* These developers can earn competitive salaries, ranging from $150,000 to over $200,000 per year, depending on experience, industry, location, and skills.\n",
      "* The industry expects the demand to increase as generative AI technology becomes more widely adopted.\n",
      "\n",
      "**Cloud Applied Generative AI Opportunities and Entrepreneurship**\n",
      "\n",
      "Here is a summary of the key points:\n",
      "\n",
      "**Key Opportunities:**\n",
      "\n",
      "* Meeting industry demand with specialized products\n",
      "* Innovation and differentiation through unique solutions\n",
      "* Access to cloud resources for scalable and cost-effective AI development\n",
      "* Entrepreneurial opportunities through market gap identification and startup creation\n",
      "* Collaboration and partnerships for innovative solutions and new application areas\n",
      "* Transforming technical expertise into viable products or services\n",
      "\n",
      "**Successful Entrepreneurship Requirements:**\n",
      "\n",
      "* Combination of technical skills, innovation, market understanding, and business acumen\n",
      "* Market research, networking, team building, and clear business planning\n",
      "* High potential for entrepreneurship due to rapid growth and high demand for Generative AI professionals\n",
      "\n",
      "**Certified GenEng Developer and Engineering Program:**\n",
      "\n",
      "* 21-month program equipping students with skills and knowledge in generative AI development, business startup, and growth\n",
      "* Covers topics such as Python, AI, database management, cloud development, and DevOps\n",
      "\n",
      "**Python vs. TypeScript for GenAI Development:**\n",
      "\n",
      "* Python preferred for AI and API development due to wide use, large ecosystem, and timely updates\n",
      "* TypeScript better suited for web development, while Python excels at API development\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Here is a comprehensive summary of the entire document in proper markdown format:\\n\\n**Program Summary**\\n================\\n\\nThe Certified Cloud Native Applied Generative AI Engineer program is a 21-month course that equips students with skills in Generative AI, Cloud Native technologies, and prepares them for global certifications and industry-ready opportunities. Key points include:\\n\\n**Key Points**\\n---------------\\n\\n* Develop in-demand skills in Generative AI and Cloud Native technologies\\n* Stay ahead of the curve in a rapidly evolving tech landscape\\n* Learn custom GPTs, multi AI agent systems, and fine-tune foundational AI models\\n* Design effective AI agents and organize a team of AI agents\\n* Earn certifications, including the \"Certified Professional Python Programmer (CPPP1)\"\\n* Specialize in various areas, including Healthcare and Medical GenAI, Web3, and Metaverse\\n\\n**Career Opportunities**\\n----------------------\\n\\n* Cloud Native Applied Generative AI developers are in high demand, with competitive salaries ranging from $150,000 to over $200,000 per year\\n* Industry expects the demand to increase as generative AI technology becomes more widely adopted\\n* Opportunities for entrepreneurship through market gap identification and startup creation\\n* Transforming technical expertise into viable products or services\\n\\n**Program Details**\\n-----------------\\n\\n* 21-month program divided into 7 quarters, with opportunities to earn money through freelancing or contributing to projects\\n* Covers a wide range of topics, including developing AI-powered microservices, cloud native expertise, and designing distributed systems and AI solutions\\n* Specializations available in various areas, including Healthcare, Web3, and Metaverse\\n\\n**Entrepreneurship and Career Opportunities**\\n------------------------------------------\\n\\n* Successful entrepreneurship requires a combination of technical skills, innovation, market understanding, and business acumen\\n* Market research, networking, team building, and clear business planning are essential for startup success\\n* High potential for entrepreneurship due to rapid growth and high demand for Generative AI professionals\\n\\n**Key Takeaways**\\n----------------\\n\\n* Python is preferred for AI and API development due to its wide use, large ecosystem, and timely updates\\n* TypeScript is better suited for web development, while Python excels at API development\\n* The program offers opportunities for entrepreneurship, innovation, and career growth in the field of Generative AI.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_chain = load_summarize_chain(llm=llm,\n",
    "                                     chain_type=\"map_reduce\",\n",
    "                                     map_prompt=map_prompt_template,\n",
    "                                     combine_prompt=final_prompt_template,\n",
    "                                     verbose=True)\n",
    "output = summary_chain.run(text_chunks[:20])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Here is the summary in markdown format:\n",
       "\n",
       "Summary\n",
       "===============\n",
       "\n",
       "The <span style=\"color: #008000; text-decoration-color: #008000\">\"Certified Cloud Native Applied Generative AI Engineer\"</span> program is a <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>-month program that trains professionals\n",
       "to develop leading-edge Cloud Native AI and Physical AI solutions. The program covers AI agents, autonomous \n",
       "programs, cloud-native expertise, distributed system design, and design thinking. Students will learn to develop \n",
       "intelligent, scalable cloud applications using GenAI and CN technologies and will be certified in Custom GPT, AI \n",
       "Agent, and Humanoid Robotics Development.\n",
       "\n",
       "**Key Highlights**\n",
       "\n",
       "* Trains professionals to develop leading-edge Cloud Native AI and Physical AI solutions\n",
       "* Covers AI agents, autonomous programs, cloud-native expertise, distributed system design, and design thinking\n",
       "* Emphasizes industry-readiness, with global certifications and startup/freelance opportunities available after \n",
       "just six months\n",
       "* Provides a free Azure account and uses these services to deploy and manage cloud-native AI-powered microservices\n",
       "* Students have the opportunity to earn while they learn, starting with freelancing or contributing to projects \n",
       "after the third quarter\n",
       "\n",
       "**Career Opportunities**\n",
       "\n",
       "* Cloud Applied Generative AI Developers have a bright future ahead, with opportunities for competitive salaries \n",
       "and career growth\n",
       "* The demand for Cloud Applied Generative AI developers is driven by the increasing interest in using AI for \n",
       "creative applications, content generation, and other innovative purposes\n",
       "* The average salary for Cloud Applied Generative AI developers is around $<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">150</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">000</span> per year, with experienced \n",
       "developers earning up to $<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">000</span> per year\n",
       "\n",
       "Overall, the program provides students with the skills and knowledge they need to develop and apply cutting-edge \n",
       "generative AI technologies, and prepares them for careers in this rapidly growing field.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Here is the summary in markdown format:\n",
       "\n",
       "Summary\n",
       "===============\n",
       "\n",
       "The \u001b[32m\"Certified Cloud Native Applied Generative AI Engineer\"\u001b[0m program is a \u001b[1;36m21\u001b[0m-month program that trains professionals\n",
       "to develop leading-edge Cloud Native AI and Physical AI solutions. The program covers AI agents, autonomous \n",
       "programs, cloud-native expertise, distributed system design, and design thinking. Students will learn to develop \n",
       "intelligent, scalable cloud applications using GenAI and CN technologies and will be certified in Custom GPT, AI \n",
       "Agent, and Humanoid Robotics Development.\n",
       "\n",
       "**Key Highlights**\n",
       "\n",
       "* Trains professionals to develop leading-edge Cloud Native AI and Physical AI solutions\n",
       "* Covers AI agents, autonomous programs, cloud-native expertise, distributed system design, and design thinking\n",
       "* Emphasizes industry-readiness, with global certifications and startup/freelance opportunities available after \n",
       "just six months\n",
       "* Provides a free Azure account and uses these services to deploy and manage cloud-native AI-powered microservices\n",
       "* Students have the opportunity to earn while they learn, starting with freelancing or contributing to projects \n",
       "after the third quarter\n",
       "\n",
       "**Career Opportunities**\n",
       "\n",
       "* Cloud Applied Generative AI Developers have a bright future ahead, with opportunities for competitive salaries \n",
       "and career growth\n",
       "* The demand for Cloud Applied Generative AI developers is driven by the increasing interest in using AI for \n",
       "creative applications, content generation, and other innovative purposes\n",
       "* The average salary for Cloud Applied Generative AI developers is around $\u001b[1;36m150\u001b[0m,\u001b[1;36m000\u001b[0m per year, with experienced \n",
       "developers earning up to $\u001b[1;36m200\u001b[0m,\u001b[1;36m000\u001b[0m per year\n",
       "\n",
       "Overall, the program provides students with the skills and knowledge they need to develop and apply cutting-edge \n",
       "generative AI technologies, and prepares them for careers in this rapidly growing field.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import print\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Refine Chain Text Summarization\n",
    "Each previous summary is taken as context and new summary is refined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"Certified Cloud Native Applied\n",
      "Generative AI Engineer\n",
      "Master the Future\n",
      "Build Custom GPTs, AI Agents, Humanoids, and Fine-Tune LLMs\n",
      "Version: 12.5 (Implementation and adoption starting from August 1, 2024)\n",
      "Today's pivotal technological trends are Cloud Native (CN), Generative AI (GenAI),\n",
      "and Physical AI. Cloud Native technology offers a scalable and dependable platform\n",
      "for application operation, while AI equips these applications with intelligent,\n",
      "human-like capabilities. Physical AI aims to bridge the gap between digital\n",
      "intelligence and physical capability, creating systems that can understand and\n",
      "interact with the world in a human-like manner. Our aim is to train you to excel as a\n",
      "Cloud Native Applied Generative and Physical AI developer globally.\n",
      "The Cloud Native Applied Generative AI Certification program equips you to create\n",
      "leading-edge Cloud Native AI and Physical AI solutions using a comprehensive\n",
      "cloud-native, AI, and Physical AI platform.\n",
      "Everything will soon be represented by a conversational interface, or to put it another\n",
      "way, a personal AI, we will cover it extensively in this program. () Currently, OpenAI\n",
      "Custom GPT Platform is the best platform to develop personal AI.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here is a concise summary:\n",
      "\n",
      "This certification program (starting August 1, 2024) trains developers to build Cloud Native, Generative AI, and Physical AI solutions. It focuses on creating custom GPTs, AI agents, and humanoids, as well as fine-tuning Large Language Models (LLMs). The goal is to equip learners with the skills to develop leading-edge AI solutions for conversational interfaces and personal AI.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "We will also be covering AI agents, which are autonomous programs or entities that\n",
      "perceive their environment through sensors, process this information, and take\n",
      "actions to achieve specific goals or tasks. They can operate independently, adapt to\n",
      "changing conditions, and make decisions based on their observations and\n",
      "objectives.\n",
      "Material to Understand the Coming AI Age:\n",
      "●\n",
      "Watch the Overview Video of Our Program\n",
      "●\n",
      "Watch AGI could Double GDP\n",
      "●\n",
      "Watch Personal AI Short Video\n",
      "●\n",
      "The Future Is Agentic\n",
      "●\n",
      "The INSANE Race for AI Humanoid Robots\n",
      "●\n",
      "What Is an AI Anyway? Mustafa Suleyman\n",
      "●\n",
      "The Coming Wave: Technology, Power, and the 21st Century’s Greatest\n",
      "Dilemma\n",
      "●\n",
      "The Worlds I See: Curiosity, Exploration, and Discovery at the Dawn of AI\n",
      "●\n",
      "Ethan Mollick’s Substack\n",
      "●\n",
      "David Autor Lecture\n",
      "●\n",
      "Conversation between Suleyman, Yuval Noah Harari, and Zanny Minton\n",
      "Beddoes\n",
      "This twenty one month program equips you with the skills to thrive in the age of\n",
      "Generative AI (GenAI), Physical AI, and cloud native computing (CN). You will\n",
      "become an expert Custom GPT, AI Agent, and Humanoid Robotics Developer. The\n",
      "program is divided into two levels: foundation level and professional level. Students\n",
      "will be able to start working after completing the foundation level. They will\n",
      "continue their professional level studies while working.\n",
      "Why This Program?\n",
      "●\n",
      "Cutting-Edge Skills: Develop in-demand skills to build intelligent, scalable\n",
      "cloud applications using Generative AI and Cloud Native technologies.\n",
      "●\n",
      "Industry-Ready: Prepare for global certifications, startup and freelance\n",
      "opportunities after just six months.\n",
      "●\n",
      "Future-Proof Your Career: Stay ahead of the curve in a rapidly evolving tech\n",
      "landscape.\n",
      "What You'll Learn:\n",
      "●\n",
      "Custom GPTs and Multi AI Agent Systems: Learn to fine-tuning\n",
      "foundational AI models, and market them in GPT stores. Learn key principles\n",
      "of designing effective AI agents, and organising a team of AI agents to\n",
      "2\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here is the refined summary:\n",
      "\n",
      "This 21-month certification program, starting August 1, 2024, trains developers to build cutting-edge Cloud Native, Generative AI, and Physical AI solutions. The program focuses on creating custom GPTs, AI agents, and humanoids, as well as fine-tuning Large Language Models (LLMs). Learners will gain skills to develop leading-edge AI solutions for conversational interfaces and personal AI. The program is divided into two levels: foundation and professional, allowing students to start working after completing the foundation level and continue their professional studies while working. The goal is to equip learners with industry-recognized skills to thrive in the age of Generative AI, Physical AI, and cloud native computing.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "perform complex, multi-step tasks. Apply these concepts to automate\n",
      "common business processes.\n",
      "●\n",
      "Develop AI Powered Microservices: Master Python, build APIs using\n",
      "FastAPI, SQLModel, Postgres, Kafka, Kong, and leverage cutting-edge GenAI\n",
      "APIs like OpenAI, and Open Source AI LLMs.\n",
      "●\n",
      "Cloud Native Expertise: Design and deploy cloud-native applications using\n",
      "Docker, DevContainers, TestContainers, Kubernetes, Terraform, and GitHub\n",
      "Actions.\n",
      "●\n",
      "Distributed System Design: Designing systems that run on multiple\n",
      "computers (or nodes) simultaneously, interacting and coordinating their\n",
      "actions by passing messages over a network.\n",
      "●\n",
      "Designing AI Solutions using Design Thinking and Behaviour Driven\n",
      "Development (BDD): We will learn to leverage these methodologies to create\n",
      "AI solutions that are not only technically sound but also highly user-centric\n",
      "and aligned with real-world needs.\n",
      "●\n",
      "Fine-Tuning Open-Source Large Language Models using PyTorch, and\n",
      "Fast AI: We will learn to fine-tuning of open-source Large Language Models\n",
      "(LLMs) like Meta LLaMA 3 using PyTorch and Fast AI, with a focus on\n",
      "cloud-native training and deployment. We will set up development\n",
      "environments, preprocess data, fine-tune models, and deploy them using\n",
      "cloud native platforms.\n",
      "●\n",
      "Physical AI and Humanoid Robotics: We will learn to design, simulate, and\n",
      "deploy advanced humanoid robots capable of natural interactions.\n",
      "Flexible Learning:\n",
      "●\n",
      "Earn While You Learn: Start freelancing or contributing to projects after the\n",
      "third quarter.\n",
      "Program Structure (Foundation: 3 + Professional: 4 = Total: 7 Quarters):\n",
      "Foundation Level (3 Quarters)\n",
      "●\n",
      "Quarter 1: Fundamentals of Prompt Engineering, Docker, GitHub, and\n",
      "Modern Python Programming\n",
      "We begin the course by understanding the basics of GenAI and Prompt\n",
      "Engineering. Then we will understand the basics of Linux, Docker, VSCode,\n",
      "Devcontainer, and GitHub. The main focus will be on mastering the\n",
      "fundamentals of Modern Python with Typing, the go-to language for AI.\n",
      "○\n",
      "Certification:\n",
      "■\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here's the refined summary:\n",
      "\n",
      "This 21-month certification program, starting August 1, 2024, trains developers to build cutting-edge Cloud Native, Generative AI, and Physical AI solutions. The program focuses on creating custom GPTs, AI agents, and humanoids, as well as fine-tuning Large Language Models (LLMs). Learners will gain skills to develop leading-edge AI solutions for conversational interfaces and personal AI. The program is divided into two levels: foundation and professional, allowing students to start working after completing the foundation level and continue their professional studies while working.\n",
      "\n",
      "Upon completion of this program, learners will be equipped with industry-recognized skills to thrive in the age of Generative AI, Physical AI, and cloud native computing. They will be able to:\n",
      "\n",
      "* Develop AI-powered microservices using Python, FastAPI, and cutting-edge GenAI APIs\n",
      "* Design and deploy cloud-native applications using Docker, Kubernetes, and Terraform\n",
      "* Design distributed systems and AI solutions using Design Thinking and Behaviour Driven Development (BDD)\n",
      "* Fine-tune open-source Large Language Models using PyTorch and Fast AI\n",
      "* Design, simulate, and deploy advanced humanoid robots capable of natural interactions\n",
      "\n",
      "The program is structured into 7 quarters, with a flexible learning approach that allows learners to start freelancing or contributing to projects after the third quarter. The foundation level (3 quarters) covers the basics of GenAI, Prompt Engineering, Docker, GitHub, and Modern Python Programming, while the professional level (4 quarters) delves into more advanced topics such as AI-powered microservices, cloud-native expertise, and Physical AI and Humanoid Robotics.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "We begin the course by understanding the basics of GenAI and Prompt\n",
      "Engineering. Then we will understand the basics of Linux, Docker, VSCode,\n",
      "Devcontainer, and GitHub. The main focus will be on mastering the\n",
      "fundamentals of Modern Python with Typing, the go-to language for AI.\n",
      "○\n",
      "Certification:\n",
      "■\n",
      "Certified Professional Python Programmer (CPPP1)\n",
      "3\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here is the refined summary:\n",
      "\n",
      "This 21-month certification program, starting August 1, 2024, trains developers to build cutting-edge Cloud Native, Generative AI, and Physical AI solutions. The program focuses on creating custom GPTs, AI agents, and humanoids, as well as fine-tuning Large Language Models (LLMs). Learners will gain skills to develop leading-edge AI solutions for conversational interfaces and personal AI. The program is divided into two levels: foundation and professional, allowing students to start working after completing the foundation level and continue their professional studies while working.\n",
      "\n",
      "Upon completion of this program, learners will be equipped with industry-recognized skills to thrive in the age of Generative AI, Physical AI, and cloud native computing. They will be able to:\n",
      "\n",
      "* Develop AI-powered microservices using Python, FastAPI, and cutting-edge GenAI APIs\n",
      "* Design and deploy cloud-native applications using Docker, Kubernetes, and Terraform\n",
      "* Design distributed systems and AI solutions using Design Thinking and Behaviour Driven Development (BDD)\n",
      "* Fine-tune open-source Large Language Models using PyTorch and Fast AI\n",
      "* Design, simulate, and deploy advanced humanoid robots capable of natural interactions\n",
      "\n",
      "The program starts by covering the basics of GenAI and Prompt Engineering, followed by an introduction to Linux, Docker, VSCode, Devcontainer, and GitHub. Learners will master the fundamentals of Modern Python programming, including typing, which is the go-to language for AI. This foundational knowledge will be recognized with the Certified Professional Python Programmer (CPPP1) certification.\n",
      "\n",
      "The program is structured into 7 quarters, with a flexible learning approach that allows learners to start freelancing or contributing to projects after the third quarter. The foundation level (3 quarters) covers the basics of GenAI, Prompt Engineering, Docker, GitHub, and Modern Python Programming, while the professional level (4 quarters) delves into more advanced topics such as AI-powered microservices, cloud-native expertise, and Physical AI and Humanoid Robotics.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "Learning Repo:\n",
      "https://github.com/panaversity/learn-cloud-native-modern-python\n",
      "●\n",
      "Quarter 2: Applied Generative AI Fundamentals: Prompt Engineering,\n",
      "Developing Custom GPTs and Multi AI Agent Systems\n",
      "With this course, you’ll start by building a strong understanding of generative\n",
      "AI and learn how to apply Large language models (LLMs) and diffusion\n",
      "models practically. We will introduce a set of principles known as prompt\n",
      "engineering, which will help developers to work efficiently with AI. Learn to\n",
      "create custom AI models and GPTs using OpenAI, Azure, and Google\n",
      "technologies. Use open source libraries, like Langchain, CrewAI, and\n",
      "LangGraph to automate repeatable, multi-step tasks and automate business\n",
      "processes that are typically done by a group of people.\n",
      "Certifications:\n",
      "■\n",
      "Microsoft Certified: Azure AI Engineer Associate\n",
      "■\n",
      "Certified crewAI Engineer\n",
      "Learning Repo:\n",
      "https://github.com/panaversity/learn-applied-generative-ai-fundamentals/\n",
      "●\n",
      "Quarter 3: Cloud Native AI Powered Microservices Design, Development,\n",
      "and Deployment:\n",
      "Build scalable AI Powered APIs using FastAPI, Postgres, Kafka, Kong, GenAI\n",
      "APIs like OpenAI Chat Completion APIs, Assistant APIs, LangChain and\n",
      "Open Source AI LLMs, develop them using Containers and Dev Containers,\n",
      "and deploy them using Docker Compose locally and Kubernetes Powered\n",
      "Serverless Container Services on the cloud.\n",
      "We will also learn to integrate design thinking and Behavior-Driven\n",
      "Development (BDD) in developing AI systems. We will learn to create AI\n",
      "solutions that are deeply aligned with user needs and expectations. Design\n",
      "thinking ensures a thorough understanding of the user and problem space,\n",
      "while BDD provides a structured approach to defining and validating the\n",
      "desired behaviours of the AI system. Together, these methodologies lead to\n",
      "the development of AI solutions that are not only technically robust but also\n",
      "highly user-centric and effective in solving real-world problems.\n",
      "○\n",
      "Certifications:\n",
      "■\n",
      "PostgreSQL 13 Associate Certification\n",
      "■\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here is the refined summary:\n",
      "\n",
      "This 21-month certification program, starting August 1, 2024, trains developers to build cutting-edge Cloud Native, Generative AI, and Physical AI solutions. The program focuses on creating custom GPTs, AI agents, and humanoids, as well as fine-tuning Large Language Models (LLMs). Learners will gain skills to develop leading-edge AI solutions for conversational interfaces and personal AI. The program is divided into two levels: foundation and professional, allowing students to start working after completing the foundation level and continue their professional studies while working.\n",
      "\n",
      "Upon completion of this program, learners will be equipped with industry-recognized skills to thrive in the age of Generative AI, Physical AI, and cloud native computing. They will be able to:\n",
      "\n",
      "* Develop AI-powered microservices using Python, FastAPI, and cutting-edge GenAI APIs\n",
      "* Design and deploy cloud-native applications using Docker, Kubernetes, and Terraform\n",
      "* Design distributed systems and AI solutions using Design Thinking and Behaviour Driven Development (BDD)\n",
      "* Fine-tune open-source Large Language Models using PyTorch and Fast AI\n",
      "* Design, simulate, and deploy advanced humanoid robots capable of natural interactions\n",
      "\n",
      "The program starts by covering the basics of GenAI and Prompt Engineering, followed by an introduction to Linux, Docker, VSCode, Devcontainer, and GitHub. Learners will master the fundamentals of Modern Python programming, including typing, which is the go-to language for AI. This foundational knowledge will be recognized with the Certified Professional Python Programmer (CPPP1) certification.\n",
      "\n",
      "The program is structured into 7 quarters, with a flexible learning approach that allows learners to start freelancing or contributing to projects after the third quarter. The foundation level (3 quarters) covers the basics of GenAI, Prompt Engineering, Docker, GitHub, and Modern Python Programming, while the professional level (4 quarters) delves into more advanced topics such as:\n",
      "\n",
      "* Quarter 2: Applied Generative AI Fundamentals, where learners will build a strong understanding of generative AI and learn to apply Large Language Models (LLMs) and diffusion models practically, with certifications in Microsoft Certified: Azure AI Engineer Associate and Certified CrewAI Engineer.\n",
      "* Quarter 3: Cloud Native AI Powered Microservices Design, Development, and Deployment, where learners will build scalable AI Powered APIs using FastAPI, Postgres, Kafka, Kong, GenAI APIs, and deploy them using Docker Compose locally and Kubernetes Powered Serverless Container Services on the cloud, with certifications in PostgreSQL 13 Associate Certification.\n",
      "\n",
      "Upon completing the program, learners will be equipped to design, develop, and deploy leading-edge AI solutions that are deeply aligned with user needs and expectations, using methodologies such as Design Thinking and Behaviour-Driven Development (BDD).\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "desired behaviours of the AI system. Together, these methodologies lead to\n",
      "the development of AI solutions that are not only technically robust but also\n",
      "highly user-centric and effective in solving real-world problems.\n",
      "○\n",
      "Certifications:\n",
      "■\n",
      "PostgreSQL 13 Associate Certification\n",
      "■\n",
      "Confluent Certified Developer for Apache Kafka (CCDAK)\n",
      "4\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here is the refined summary:\n",
      "\n",
      "This 21-month certification program, starting August 1, 2024, trains developers to build cutting-edge Cloud Native, Generative AI, and Physical AI solutions. The program focuses on creating custom GPTs, AI agents, and humanoids, as well as fine-tuning Large Language Models (LLMs). Learners will gain skills to develop leading-edge AI solutions for conversational interfaces and personal AI. The program is divided into two levels: foundation and professional, allowing students to start working after completing the foundation level and continue their professional studies while working.\n",
      "\n",
      "Upon completion of this program, learners will be equipped with industry-recognized skills to thrive in the age of Generative AI, Physical AI, and cloud native computing. They will be able to:\n",
      "\n",
      "* Develop AI-powered microservices using Python, FastAPI, and cutting-edge GenAI APIs\n",
      "* Design and deploy cloud-native applications using Docker, Kubernetes, and Terraform\n",
      "* Design distributed systems and AI solutions using Design Thinking and Behaviour Driven Development (BDD)\n",
      "* Fine-tune open-source Large Language Models using PyTorch and Fast AI\n",
      "* Design, simulate, and deploy advanced humanoid robots capable of natural interactions\n",
      "\n",
      "The program starts by covering the basics of GenAI and Prompt Engineering, followed by an introduction to Linux, Docker, VSCode, Devcontainer, and GitHub. Learners will master the fundamentals of Modern Python programming, including typing, which is the go-to language for AI. This foundational knowledge will be recognized with the Certified Professional Python Programmer (CPPP1) certification.\n",
      "\n",
      "The program is structured into 7 quarters, with a flexible learning approach that allows learners to start freelancing or contributing to projects after the third quarter. The foundation level (3 quarters) covers the basics of GenAI, Prompt Engineering, Docker, GitHub, and Modern Python Programming, while the professional level (4 quarters) delves into more advanced topics such as:\n",
      "\n",
      "* Quarter 2: Applied Generative AI Fundamentals, where learners will build a strong understanding of generative AI and learn to apply Large Language Models (LLMs) and diffusion models practically, with certifications in Microsoft Certified: Azure AI Engineer Associate and Certified CrewAI Engineer.\n",
      "* Quarter 3: Cloud Native AI Powered Microservices Design, Development, and Deployment, where learners will build scalable AI Powered APIs using FastAPI, Postgres, Kafka, Kong, GenAI APIs, and deploy them using Docker Compose locally and Kubernetes Powered Serverless Container Services on the cloud, with certifications in PostgreSQL 13 Associate Certification and Confluent Certified Developer for Apache Kafka (CCDAK).\n",
      "\n",
      "Upon completing the program, learners will be equipped to design, develop, and deploy leading-edge AI solutions that are deeply aligned with user needs and expectations, using methodologies such as Design Thinking and Behaviour-Driven Development (BDD). They will be able to create AI solutions that are not only technically robust but also highly user-centric and effective in solving real-world problems.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "■\n",
      "Design Thinking Professional Certificate (DTPC)\n",
      "■\n",
      "Test and Behavior Driven Development (TDD/BDD)\n",
      "Learning Repo:\n",
      "https://github.com/panaversity/learn-cloud-native-ai-powered-microservices/\n",
      "We Will Be Using Microsoft Azure as our Default Cloud Platform\n",
      "Amazon is still the cloud king based on market share. But many analysts\n",
      "agree: In the battle for the cloud, AI is now a game-changer — and Amazon's\n",
      "main competitors, particularly Microsoft, have the momentum.\n",
      "In our program we will be using Azure as our default provider for teaching and\n",
      "deployment. We will be using using these services:\n",
      "Get a free Azure Account now:\n",
      "https://azure.microsoft.com/en-us/free\n",
      "Note: Use GitHub Account to start an Azure free trial\n",
      "Azure Container Apps (We will Start from this service using Dapr and Keda)\n",
      "https://azure.microsoft.com/en-us/products/container-apps\n",
      "Get started with the free tier: The first 180,000 vCPU per second, 360,000\n",
      "GiB/s, and 2 million requests each month are free.\n",
      "Watch: https://www.youtube.com/watch?v=0HwQfsa03K8\n",
      "Deploy:\n",
      "https://learn.microsoft.com/en-us/azure/container-apps/code-to-cloud-options\n",
      "Azure Container Registry\n",
      "https://azure.microsoft.com/en-us/products/container-registry/\n",
      "Deploy to Azure Container Apps with GitHub Actions\n",
      "https://learn.microsoft.com/en-us/azure/container-apps/github-actions\n",
      "Azure Kubernetes Service (AKS)\n",
      "https://azure.microsoft.com/en-us/products/kubernetes-service\n",
      "GitHub\n",
      "https://azure.microsoft.com/en-us/products/github/\n",
      "GitHub Actions for AKS\n",
      "https://learn.microsoft.com/en-us/azure/aks/kubernetes-action\n",
      "5\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: I've reviewed the additional context and refined the summary as follows:\n",
      "\n",
      "**Cloud Native AI Powered Microservices Certification Program**\n",
      "\n",
      "This 21-month certification program, starting August 1, 2024, trains developers to build cutting-edge Cloud Native, Generative AI, and Physical AI solutions. The program focuses on creating custom GPTs, AI agents, and humanoids, as well as fine-tuning Large Language Models (LLMs). Learners will gain skills to develop leading-edge AI solutions for conversational interfaces and personal AI. The program is divided into two levels: foundation and professional, allowing students to start working after completing the foundation level and continue their professional studies while working.\n",
      "\n",
      "Upon completion of this program, learners will be equipped with industry-recognized skills to thrive in the age of Generative AI, Physical AI, and cloud native computing. They will be able to:\n",
      "\n",
      "* Develop AI-powered microservices using Python, FastAPI, and cutting-edge GenAI APIs\n",
      "* Design and deploy cloud-native applications using Docker, Kubernetes, and Terraform\n",
      "* Design distributed systems and AI solutions using Design Thinking and Behaviour Driven Development (BDD)\n",
      "* Fine-tune open-source Large Language Models using PyTorch and Fast AI\n",
      "* Design, simulate, and deploy advanced humanoid robots capable of natural interactions\n",
      "\n",
      "The program starts by covering the basics of GenAI and Prompt Engineering, followed by an introduction to Linux, Docker, VSCode, Devcontainer, and GitHub. Learners will master the fundamentals of Modern Python programming, including typing, which is the go-to language for AI. This foundational knowledge will be recognized with the Certified Professional Python Programmer (CPPP1) certification.\n",
      "\n",
      "The program is structured into 7 quarters, with a flexible learning approach that allows learners to start freelancing or contributing to projects after the third quarter. The foundation level (3 quarters) covers the basics of GenAI, Prompt Engineering, Docker, GitHub, and Modern Python Programming, while the professional level (4 quarters) delves into more advanced topics such as:\n",
      "\n",
      "* Quarter 2: Applied Generative AI Fundamentals, where learners will build a strong understanding of generative AI and learn to apply Large Language Models (LLMs) and diffusion models practically, with certifications in Microsoft Certified: Azure AI Engineer Associate and Certified CrewAI Engineer.\n",
      "* Quarter 3: Cloud Native AI Powered Microservices Design, Development, and Deployment, where learners will build scalable AI Powered APIs using FastAPI, Postgres, Kafka, Kong, GenAI APIs, and deploy them using Docker Compose locally and Kubernetes Powered Serverless Container Services on the cloud, with certifications in PostgreSQL 13 Associate Certification and Confluent Certified Developer for Apache Kafka (CCDAK).\n",
      "* Subsequent quarters focus on Advanced Generative AI Applications, Robotics and IoT Development, and Microservice Architectures on the Microsoft Azure platform, incorporating real-world examples, group projects, and Design Thinking for professional work. Notable proficiencies expected for Program Completors on Course end may contain AZ900 Security from cloud pioneer based into multi-sub-section examples areas/ segments details **including** certification of cloud for developer and services certifications for which is free to attain **upon** the completion of course.\n",
      "\n",
      "Upon completing the program, learners will be equipped to design, develop, and deploy leading-edge AI solutions that are deeply aligned with user needs and expectations, using methodologies such as Design Thinking and Behaviour-Driven Development (BDD). They will be able to create AI solutions that are not only technically robust but also highly user-centric and effective in solving real-world problems.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "Azure OpenAI Service\n",
      "https://azure.microsoft.com/en-us/products/ai-services/openai-service\n",
      "Azure Database for PostgreSQL\n",
      "https://azure.microsoft.com/en-us/products/postgresql/\n",
      "Kafka\n",
      "https://cloudatlas.me/5-different-ways-you-can-run-apache-kafka-on-azure-97\n",
      "3a18925ac7\n",
      "Professional Level (4 Quarters)\n",
      "●\n",
      "Quarter 4: Generative AI with PyTorch:\n",
      "Generative AI tools like ChatGPT, Gemini, and DALL-E have revolutionised\n",
      "our professional landscape. This hands-on course, “Master Generative AI with\n",
      "PyTorch,” guides you through the exciting process of building and training AI\n",
      "models using Python and the versatile, open-source PyTorch framework, all\n",
      "with the hardware you already have. You’ll delve into the core concepts of\n",
      "Generative Adversarial Networks (GANs), Transformers, Large Language\n",
      "Models (LLMs), variational autoencoders, diffusion models, LangChain, and\n",
      "more. Along the way, you’ll gain practical experience and a deep\n",
      "understanding of these cutting-edge technologies.\n",
      "Learning Repo: https://github.com/panaversity/genai-with-pytorch\n",
      "●\n",
      "Quarter 5: Fine-Tuning Open-Source Large Language Models:\n",
      "This comprehensive course is designed to guide learners through the process\n",
      "of fine-tuning open-source Large Language Models (LLMs) such as Meta\n",
      "LLaMA 3 using PyTorch, with a particular emphasis on cloud-native training\n",
      "and deployment. The course covers everything from the fundamentals to\n",
      "advanced concepts, ensuring students acquire both theoretical knowledge\n",
      "and practical skills.\n",
      "The journey begins with an introduction to LLMs, focusing on their\n",
      "architecture, capabilities, and the specific features of Meta LLaMA 3. Next, the\n",
      "course dives into PyTorch fundamentals, teaching students how to perform\n",
      "basic operations with tensors and build simple neural networks. This\n",
      "6\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: After reviewing the additional context and refining the original summary, I'll provide the updated summary:\n",
      "\n",
      "**Cloud Native AI Powered Microservices Certification Program**\n",
      "\n",
      "This 21-month certification program, starting August 1, 2024, trains developers to build cutting-edge Cloud Native, Generative AI, and Physical AI solutions. The program focuses on creating custom GPTs, AI agents, and humanoids, as well as fine-tuning Large Language Models (LLMs). Learners will gain skills to develop leading-edge AI solutions for conversational interfaces and personal AI. The program is divided into two levels: foundation and professional, allowing students to start working after completing the foundation level and continue their professional studies while working.\n",
      "\n",
      "Upon completion of this program, learners will be equipped with industry-recognized skills to thrive in the age of Generative AI, Physical AI, and cloud native computing. They will be able to:\n",
      "\n",
      "* Develop AI-powered microservices using Python, FastAPI, and cutting-edge GenAI APIs\n",
      "* Design and deploy cloud-native applications using Docker, Kubernetes, and Terraform\n",
      "* Design distributed systems and AI solutions using Design Thinking and Behaviour Driven Development (BDD)\n",
      "* Fine-tune open-source Large Language Models using PyTorch and Fast AI\n",
      "* Design, simulate, and deploy advanced humanoid robots capable of natural interactions\n",
      "\n",
      "The program starts by covering the basics of GenAI and Prompt Engineering, followed by an introduction to Linux, Docker, VSCode, Devcontainer, and GitHub. Learners will master the fundamentals of Modern Python programming, including typing, which is the go-to language for AI. This foundational knowledge will be recognized with the Certified Professional Python Programmer (CPPP1) certification.\n",
      "\n",
      "The program is structured into 7 quarters, with a flexible learning approach that allows learners to start freelancing or contributing to projects after the third quarter.\n",
      "\n",
      "**Professional Level (4 Quarters)**\n",
      "\n",
      "Quarter 1:\n",
      "Applied Generative AI Fundamentals:\n",
      "Build a strong understanding of generative AI, and apply Large Language Models (LLMs) and diffusion models practically. This will also earn you the certifications:\n",
      "- Microsoft Certified: Azure AI Engineer Associate\n",
      "- Certified CrewAI Engineer\n",
      "\n",
      "Quarter 2:\n",
      "Cloud Native AI Powered Microservices Design, Development, and Deployment:\n",
      "Design and build scalable AI-powered APIs using FastAPI, Postgres, Kafka, Kong, GenAI APIs, and deploy them on Kubernetes and serverless containers.\n",
      "Earn the following certifications:\n",
      "- PostgreSQL 13 Associate Certification\n",
      "- Confluent Certified Developer for Apache Kafka (CCDAK)\n",
      "\n",
      "The next 2 quarters, students delve deeper into more advanced topics including Generative AI with PyTorch and fine-tuning Open-Source Large Language Models on PyTorch with Meta LLaMA 3.\n",
      "Additional expertise, throughout all program can enhance performance gains significantly once experience accrued takes another optional.\n",
      "  \n",
      " \n",
      "Throughout this certification, you’ll design and build more effective user interfaces through Master generative AI & applications will obtain actual key methods relevant \n",
      "\n",
      " This curriculum progresses incrementally until training which fosters excellent exposure , showcasing individual professionals solutions having major system output further enables ongoing job task workflow abilities work completed on a regular basis!\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "foundation is crucial for understanding the mechanics behind LLMs. Data\n",
      "preparation is a crucial aspect of training models. The course covers\n",
      "comprehensive data collection and preprocessing techniques, such as\n",
      "tokenization and text normalisation. These steps are essential for preparing\n",
      "datasets suitable for fine-tuning LLMs like Meta LLaMA 3. Through practical\n",
      "exercises, students learn how to handle and preprocess various types of text\n",
      "data, ensuring they can prepare their datasets for optimal model performance.\n",
      "Fine-tuning Meta LLaMA 3 with PyTorch forms a significant part of the course.\n",
      "Students will delve into the architecture of Meta LLaMA 3, learn how to load\n",
      "pre-trained models, and apply fine-tuning techniques. The course covers\n",
      "advanced topics such as regularisation and optimization strategies to\n",
      "enhance model performance. Practical sessions guide students through the\n",
      "entire fine-tuning process on custom datasets, emphasising best practices\n",
      "and troubleshooting techniques.\n",
      "A critical aspect of this course is its focus on cloud-native training and\n",
      "deployment using Nvidia NIM. Furthermore, students learn how to deploy\n",
      "models using Docker and Kubernetes, set up monitoring and maintenance\n",
      "tools, and ensure their models are scalable and efficient.\n",
      "To round off the learning experience, the course includes an in-depth segment\n",
      "on exporting models for inference and building robust inference pipelines.\n",
      "Students will deploy models on cloud platforms, focusing on practical aspects\n",
      "of setting up monitoring tools to maintain model performance and reliability.\n",
      "The course culminates in a capstone project, where students apply all the\n",
      "skills they have learned to fine-tune and deploy Meta LLaMA 3 on a chosen\n",
      "platform. This project allows students to demonstrate their understanding and\n",
      "proficiency in the entire process, from data preparation to cloud-native\n",
      "deployment.\n",
      "Learning Repo:\n",
      "https://github.com/panaversity/learn-fine-tuning-llms\n",
      "●\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here is the refined summary:\n",
      "\n",
      "**Cloud Native AI Powered Microservices Certification Program**\n",
      "\n",
      "This 21-month certification program, starting August 1, 2024, trains developers to build cutting-edge Cloud Native, Generative AI, and Physical AI solutions. The program focuses on creating custom GPTs, AI agents, and humanoids, as well as fine-tuning Large Language Models (LLMs). Learners will gain skills to develop leading-edge AI solutions for conversational interfaces and personal AI. The program is divided into two levels: foundation and professional, allowing students to start working after completing the foundation level and continue their professional studies while working.\n",
      "\n",
      "Upon completion of this program, learners will be equipped with industry-recognized skills to thrive in the age of Generative AI, Physical AI, and cloud native computing. They will be able to:\n",
      "\n",
      "* Develop AI-powered microservices using Python, FastAPI, and cutting-edge GenAI APIs\n",
      "* Design and deploy cloud-native applications using Docker, Kubernetes, and Terraform\n",
      "* Design distributed systems and AI solutions using Design Thinking and Behaviour Driven Development (BDD)\n",
      "* Fine-tune open-source Large Language Models using PyTorch and Fast AI\n",
      "* Design, simulate, and deploy advanced humanoid robots capable of natural interactions\n",
      "\n",
      "The program starts by covering the basics of GenAI and Prompt Engineering, followed by an introduction to Linux, Docker, VSCode, Devcontainer, and GitHub. Learners will master the fundamentals of Modern Python programming, including typing, which is the go-to language for AI. This foundational knowledge will be recognized with the Certified Professional Python Programmer (CPPP1) certification.\n",
      "\n",
      "The program is structured into 7 quarters, with a flexible learning approach that allows learners to start freelancing or contributing to projects after the third quarter.\n",
      "\n",
      "**Professional Level (4 Quarters)**\n",
      "\n",
      "Quarter 1:\n",
      "Applied Generative AI Fundamentals:\n",
      "Build a strong understanding of generative AI, and apply Large Language Models (LLMs) and diffusion models practically. This will also earn you the certifications:\n",
      "- Microsoft Certified: Azure AI Engineer Associate\n",
      "- Certified CrewAI Engineer\n",
      "\n",
      "Quarter 2:\n",
      "Cloud Native AI Powered Microservices Design, Development, and Deployment:\n",
      "Design and build scalable AI-powered APIs using FastAPI, Postgres, Kafka, Kong, GenAI APIs, and deploy them on Kubernetes and serverless containers.\n",
      "Earn the following certifications:\n",
      "- PostgreSQL 13 Associate Certification\n",
      "- Confluent Certified Developer for Apache Kafka (CCDAK)\n",
      "\n",
      "Quarters 3 and 4 delve into more advanced topics, including fine-tuning Open-Source Large Language Models with PyTorch on Meta LLaMA 3, with a focus on cloud-native training and deployment using Nvidia NIM, Docker, and Kubernetes. Students will learn how to deploy models, set up monitoring and maintenance tools, and ensure their models are scalable and efficient.\n",
      "\n",
      "Throughout the program, learners will gain hands-on experience with data preparation, fine-tuning, and deploying Large Language Models, as well as designing and deploying cloud-native applications. The program culminates in a capstone project, where students apply all the skills they have learned to fine-tune and deploy a Large Language Model on a chosen platform.\n",
      "\n",
      "Upon completion of the program, learners will have the skills and expertise to succeed in the field of Cloud Native AI Powered Microservices, and will be recognized with industry-recognized certifications.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "platform. This project allows students to demonstrate their understanding and\n",
      "proficiency in the entire process, from data preparation to cloud-native\n",
      "deployment.\n",
      "Learning Repo:\n",
      "https://github.com/panaversity/learn-fine-tuning-llms\n",
      "●\n",
      "Quarter 6: Physical AI and Humanoid Robotics Development:\n",
      "Artificial intelligence (AI) has experienced remarkable advancements in recent\n",
      "years. However, the future of AI extends beyond the digital space into the\n",
      "physical world, driven by robotics. This new frontier, known as “Physical AI,”\n",
      "involves AI systems that can function in the real world and comprehend\n",
      "physical laws. This marks a notable transition from AI models confined to\n",
      "digital environments. Humanoid robots are poised to excel in our\n",
      "7\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here is the refined summary:\n",
      "\n",
      "**Cloud Native AI Powered Microservices Certification Program**\n",
      "\n",
      "This 21-month certification program, starting August 1, 2024, trains developers to build cutting-edge Cloud Native, Generative AI, and Physical AI solutions. The program focuses on creating custom GPTs, AI agents, and humanoids, as well as fine-tuning Large Language Models (LLMs). Learners will gain skills to develop leading-edge AI solutions for conversational interfaces and personal AI. The program is divided into two levels: foundation and professional, allowing students to start working after completing the foundation level and continue their professional studies while working.\n",
      "\n",
      "Upon completion of this program, learners will be equipped with industry-recognized skills to thrive in the age of Generative AI, Physical AI, and cloud native computing. They will be able to:\n",
      "\n",
      "* Develop AI-powered microservices using Python, FastAPI, and cutting-edge GenAI APIs\n",
      "* Design and deploy cloud-native applications using Docker, Kubernetes, and Terraform\n",
      "* Design distributed systems and AI solutions using Design Thinking and Behaviour Driven Development (BDD)\n",
      "* Fine-tune open-source Large Language Models using PyTorch and Fast AI\n",
      "* Design, simulate, and deploy advanced humanoid robots capable of natural interactions\n",
      "\n",
      "The program starts by covering the basics of GenAI and Prompt Engineering, followed by an introduction to Linux, Docker, VSCode, Devcontainer, and GitHub. Learners will master the fundamentals of Modern Python programming, including typing, which is the go-to language for AI. This foundational knowledge will be recognized with the Certified Professional Python Programmer (CPPP1) certification.\n",
      "\n",
      "**Program Structure**\n",
      "\n",
      "The program is structured into 7 quarters, with a flexible learning approach that allows learners to start freelancing or contributing to projects after the third quarter.\n",
      "\n",
      "**Foundation Level (3 Quarters)**\n",
      "\n",
      "* Quarter 1: Applied Generative AI Fundamentals (certifications: Microsoft Certified: Azure AI Engineer Associate, Certified CrewAI Engineer)\n",
      "* Quarter 2: Cloud Native AI Powered Microservices Design, Development, and Deployment (certifications: PostgreSQL 13 Associate Certification, Confluent Certified Developer for Apache Kafka (CCDAK))\n",
      "* Quarter 3: Cloud-Native AI Model Training and Deployment (hands-on experience with data preparation, fine-tuning, and deploying Large Language Models)\n",
      "\n",
      "**Professional Level (4 Quarters)**\n",
      "\n",
      "* Quarter 1: Applied Generative AI Fundamentals\n",
      "* Quarter 2: Cloud Native AI Powered Microservices Design, Development, and Deployment\n",
      "* Quarter 3: Advanced Cloud-Native AI Model Training and Deployment (fine-tuning Open-Source Large Language Models with PyTorch on Meta LLaMA 3, cloud-native training and deployment using Nvidia NIM, Docker, and Kubernetes)\n",
      "* Quarter 4: Physical AI and Humanoid Robotics Development (design, simulate, and deploy advanced humanoid robots capable of natural interactions)\n",
      "\n",
      "Throughout the program, learners will gain hands-on experience with data preparation, fine-tuning, and deploying Large Language Models, as well as designing and deploying cloud-native applications. The program culminates in a capstone project, where students apply all the skills they have learned to fine-tune and deploy a Large Language Model on a chosen platform.\n",
      "\n",
      "Upon completion of the program, learners will have the skills and expertise to succeed in the field of Cloud Native AI Powered Microservices, and will be recognized with industry-recognized certifications.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "human-centred world because they share our physical form and can be\n",
      "trained with abundant data from interacting in human environments.\n",
      "This course provides an in-depth exploration of humanoid robotics, focusing\n",
      "on the integration of ROS 2 (Robot Operating System), Open Source Meta\n",
      "Llama 3, and OpenAI technologies. Students will learn to design, simulate,\n",
      "and deploy advanced humanoid robots capable of natural interactions. The\n",
      "curriculum covers essential topics such as ROS 2 for robotic control,\n",
      "simulations with Gazebo and Unity, and using OpenAI’s GPT models for\n",
      "conversational AI. Through practical projects and real-world applications,\n",
      "students will develop the skills needed to drive innovation in humanoid\n",
      "robotics.\n",
      "Learning Repo:\n",
      "https://github.com/panaversity/learn-physical-ai-humanoid-robotics\n",
      "●\n",
      "Quarter 7: Kubernetes and Distributed System Design:\n",
      "Master Kubernetes, Terraform, and GitHub Actions to deploy your AI APIs and\n",
      "microservices in the cloud. We will cover distributed system design involving\n",
      "creating systems that are distributed across multiple nodes, focusing on\n",
      "scalability, fault tolerance, consistency, availability, and partition tolerance.\n",
      "Certifications:\n",
      "■\n",
      "Certified Kubernetes Application Developer (CKAD)\n",
      "■\n",
      "HashiCorp Certified: Terraform Associate\n",
      "Learning Repo: https://github.com/panaversity/learn-kubernetes\n",
      "Frontend Specialisation\n",
      "●\n",
      "Quarter 8: Front-end Web GUI Development using Next.js and\n",
      "TypeScript (Optional):\n",
      "Next.js is designed to handle complex front-end applications well, making it a\n",
      "good fit for AI applications that might grow in features and data usage over\n",
      "time. Next.js offers features like API routes and file-based routing, which can\n",
      "streamline development for AI applications that need to interact with backend\n",
      "APIs and manage different application views. While Next.js and TypeScript\n",
      "8\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here is the refined summary:\n",
      "\n",
      "**Cloud Native AI Powered Microservices Certification Program**\n",
      "\n",
      "This 21-month certification program, starting August 1, 2024, trains developers to build cutting-edge Cloud Native, Generative AI, and Physical AI solutions. The program focuses on creating custom GPTs, AI agents, and humanoids, as well as fine-tuning Large Language Models (LLMs). Learners will gain skills to develop leading-edge AI solutions for conversational interfaces and personal AI. The program is divided into two levels: foundation and professional, allowing students to start working after completing the foundation level and continue their professional studies while working.\n",
      "\n",
      "Upon completion of this program, learners will be equipped with industry-recognized skills to thrive in the age of Generative AI, Physical AI, and cloud native computing. They will be able to:\n",
      "\n",
      "* Develop AI-powered microservices using Python, FastAPI, and cutting-edge GenAI APIs\n",
      "* Design and deploy cloud-native applications using Docker, Kubernetes, and Terraform\n",
      "* Design distributed systems and AI solutions using Design Thinking and Behaviour Driven Development (BDD)\n",
      "* Fine-tune open-source Large Language Models using PyTorch and Fast AI\n",
      "* Design, simulate, and deploy advanced humanoid robots capable of natural interactions\n",
      "\n",
      "The program starts by covering the basics of GenAI and Prompt Engineering, followed by an introduction to Linux, Docker, VSCode, Devcontainer, and GitHub. Learners will master the fundamentals of Modern Python programming, including typing, which is the go-to language for AI. This foundational knowledge will be recognized with the Certified Professional Python Programmer (CPPP1) certification.\n",
      "\n",
      "**Program Structure**\n",
      "\n",
      "The program is structured into 7 quarters, with a flexible learning approach that allows learners to start freelancing or contributing to projects after the third quarter.\n",
      "\n",
      "**Foundation Level (3 Quarters)**\n",
      "\n",
      "* Quarter 1: Applied Generative AI Fundamentals (certifications: Microsoft Certified: Azure AI Engineer Associate, Certified CrewAI Engineer)\n",
      "* Quarter 2: Cloud Native AI Powered Microservices Design, Development, and Deployment (certifications: PostgreSQL 13 Associate Certification, Confluent Certified Developer for Apache Kafka (CCDAK))\n",
      "* Quarter 3: Cloud-Native AI Model Training and Deployment (hands-on experience with data preparation, fine-tuning, and deploying Large Language Models)\n",
      "\n",
      "**Professional Level (4 Quarters)**\n",
      "\n",
      "* Quarter 1: Applied Generative AI Fundamentals\n",
      "* Quarter 2: Cloud Native AI Powered Microservices Design, Development, and Deployment\n",
      "* Quarter 3: Advanced Cloud-Native AI Model Training and Deployment (fine-tuning Open-Source Large Language Models with PyTorch on Meta LLaMA 3, cloud-native training and deployment using Nvidia NIM, Docker, and Kubernetes)\n",
      "* Quarter 4: Physical AI and Humanoid Robotics Development (design, simulate, and deploy advanced humanoid robots capable of natural interactions)\n",
      "\n",
      "Additionally, the program includes three optional specializations:\n",
      "\n",
      "* **Physical AI and Humanoid Robotics**: This specialization focuses on designing, simulating, and deploying advanced humanoid robots capable of natural interactions using ROS 2, Open Source Meta Llama 3, and OpenAI technologies.\n",
      "* **Kubernetes and Distributed System Design**: Learners will master Kubernetes, Terraform, and GitHub Actions to deploy their AI APIs and microservices in the cloud, and design distributed systems that are scalable, fault-tolerant, consistent, available, and partition-tolerant.\n",
      "* **Frontend Specialization**: Learners will develop front-end web GUIs using Next.js and TypeScript, enabling them to create interactive and data-driven user interfaces for AI applications.\n",
      "\n",
      "Upon completion of the program, learners will have the skills and expertise to succeed in the field of Cloud Native AI Powered Microservices, and will be recognized with industry-recognized certifications.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "aren't the only options for building AI application frontends, their focus on\n",
      "performance, scalability, and developer experience makes them a compelling\n",
      "choice for many developers.\n",
      "Learning Repo:\n",
      "https://github.com/panaverse/learn-nextjs\n",
      "9\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Based on the additional context, I will refine the original summary to include the information about Next.js and its relevance to building AI application frontends.\n",
      "\n",
      "**Cloud Native AI Powered Microservices Certification Program**\n",
      "\n",
      "This 21-month certification program, starting August 1, 2024, trains developers to build cutting-edge Cloud Native, Generative AI, and Physical AI solutions. The program focuses on creating custom GPTs, AI agents, and humanoids, as well as fine-tuning Large Language Models (LLMs). Learners will gain skills to develop leading-edge AI solutions for conversational interfaces and personal AI. The program is divided into two levels: foundation and professional, allowing students to start working after completing the foundation level and continue their professional studies while working.\n",
      "\n",
      "Upon completion of this program, learners will be equipped with industry-recognized skills to thrive in the age of Generative AI, Physical AI, and cloud native computing. They will be able to:\n",
      "\n",
      "* Develop AI-powered microservices using Python, FastAPI, and cutting-edge GenAI APIs\n",
      "* Design and deploy cloud-native applications using Docker, Kubernetes, and Terraform\n",
      "* Design distributed systems and AI solutions using Design Thinking and Behaviour Driven Development (BDD)\n",
      "* Fine-tune open-source Large Language Models using PyTorch and Fast AI\n",
      "* Design, simulate, and deploy advanced humanoid robots capable of natural interactions\n",
      "\n",
      "The program starts by covering the basics of GenAI and Prompt Engineering, followed by an introduction to Linux, Docker, VSCode, Devcontainer, and GitHub. Learners will master the fundamentals of Modern Python programming, including typing, which is the go-to language for AI. This foundational knowledge will be recognized with the Certified Professional Python Programmer (CPPP1) certification.\n",
      "\n",
      "**Program Structure**\n",
      "\n",
      "The program is structured into 7 quarters, with a flexible learning approach that allows learners to start freelancing or contributing to projects after the third quarter.\n",
      "\n",
      "**Foundation Level (3 Quarters)**\n",
      "\n",
      "* Quarter 1: Applied Generative AI Fundamentals (certifications: Microsoft Certified: Azure AI Engineer Associate, Certified CrewAI Engineer)\n",
      "* Quarter 2: Cloud Native AI Powered Microservices Design, Development, and Deployment (certifications: PostgreSQL 13 Associate Certification, Confluent Certified Developer for Apache Kafka (CCDAK))\n",
      "* Quarter 3: Cloud-Native AI Model Training and Deployment (hands-on experience with data preparation, fine-tuning, and deploying Large Language Models)\n",
      "\n",
      "**Professional Level (4 Quarters)**\n",
      "\n",
      "* Quarter 1: Applied Generative AI Fundamentals\n",
      "* Quarter 2: Cloud Native AI Powered Microservices Design, Development, and Deployment\n",
      "* Quarter 3: Advanced Cloud-Native AI Model Training and Deployment (fine-tuning Open-Source Large Language Models with PyTorch on Meta LLaMA 3, cloud-native training and deployment using Nvidia NIM, Docker, and Kubernetes)\n",
      "* Quarter 4: Physical AI and Humanoid Robotics Development (design, simulate, and deploy advanced humanoid robots capable of natural interactions)\n",
      "\n",
      "Additionally, the program includes three optional specializations:\n",
      "\n",
      "* **Physical AI and Humanoid Robotics**: This specialization focuses on designing, simulating, and deploying advanced humanoid robots capable of natural interactions using ROS 2, Open Source Meta Llama 3, and OpenAI technologies.\n",
      "* **Kubernetes and Distributed System Design**: Learners will master Kubernetes, Terraform, and GitHub Actions to deploy their AI APIs and microservices in the cloud, and design distributed systems that are scalable, fault-tolerant, consistent, available, and partition-tolerant.\n",
      "* **Frontend Specialization**: Learners will develop front-end web GUIs using Next.js, a popular framework for building high-performance, scalable, and developer-friendly applications, in addition to other frameworks such as TypeScript, enabling them to create interactive and data-driven user interfaces for AI applications.\n",
      "\n",
      "Upon completion of the program, learners will have the skills and expertise to succeed in the field of Cloud Native AI Powered Microservices, and will be recognized with industry-recognized certifications.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "In 2015, Klaus Schwab, founder of the World Economic Forum, asserted that we\n",
      "were on the brink of a “Fourth Industrial Revolution,” one powered by a fusion of\n",
      "technologies, such as advanced robotics, artificial intelligence, and the Internet of\n",
      "Things.\n",
      "“[This revolution] will fundamentally alter the way we live, work, and relate to one\n",
      "another,” wrote Schwab in an essay published in Foreign Affairs. “In its scale, scope,\n",
      "and complexity, the transformation will be unlike anything humankind has\n",
      "experienced before.”\n",
      "Generative AI is set to revolutionise our daily lives and work environments.\n",
      "According to McKinsey & Company, generative AI could contribute an annual\n",
      "economic value of $2.6 trillion to $4.4 trillion across various sectors by enhancing\n",
      "automation, bolstering decision-making, and providing personalised experiences.\n",
      "Investor Cathie Wood predicts that the market for humanoid robots could grow to $1\n",
      "trillion by 2030.\n",
      "Cloud native is an approach in software development that enables application\n",
      "creation, deployment, and management in cloud environments. It involves\n",
      "constructing applications as a collection of small, interconnected services known as\n",
      "microservices, a shift from traditional monolithic structures. This modular approach\n",
      "enhances the agility of cloud-native applications, allowing them to operate more\n",
      "efficiently with fewer resources.\n",
      "Cloud Native has already been adopted by the majority of the companies, by 2024,\n",
      "more than 90% of global organisations will be running containerized applications in\n",
      "production. The adoption of Docker and Kubernetes has seen significant growth over\n",
      "recent years. As of 2022, about 61% of organisations reported using Kubernetes for\n",
      "container orchestration. This number has been steadily increasing as more\n",
      "companies realise the benefits of these technologies for managing containerized\n",
      "applications ￼￼.\n",
      "Technologies such as Kubernetes, Docker, serverless containers, APIs, SQL\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here's the refined summary:\n",
      "\n",
      "**Cloud Native AI Powered Microservices Certification Program**\n",
      "\n",
      "This 21-month certification program, starting August 1, 2024, trains developers to build cutting-edge Cloud Native, Generative AI, and Physical AI solutions. The program focuses on creating custom GPTs, AI agents, and humanoids, as well as fine-tuning Large Language Models (LLMs). Learners will gain skills to develop leading-edge AI solutions for conversational interfaces and personal AI. The program is divided into two levels: foundation and professional, allowing students to start working after completing the foundation level and continue their professional studies while working.\n",
      "\n",
      "Upon completion of this program, learners will be equipped with industry-recognized skills to thrive in the age of Generative AI, Physical AI, and cloud native computing. They will be able to:\n",
      "\n",
      "* Develop AI-powered microservices using Python, FastAPI, and cutting-edge GenAI APIs\n",
      "* Design and deploy cloud-native applications using Docker, Kubernetes, and Terraform\n",
      "* Design distributed systems and AI solutions using Design Thinking and Behaviour Driven Development (BDD)\n",
      "* Fine-tune open-source Large Language Models using PyTorch and Fast AI\n",
      "* Design, simulate, and deploy advanced humanoid robots capable of natural interactions\n",
      "\n",
      "The program starts by covering the basics of GenAI and Prompt Engineering, followed by an introduction to Linux, Docker, VSCode, Devcontainer, and GitHub. Learners will master the fundamentals of Modern Python programming, including typing, which is the go-to language for AI. This foundational knowledge will be recognized with the Certified Professional Python Programmer (CPPP1) certification.\n",
      "\n",
      "**Program Structure**\n",
      "\n",
      "The program is structured into 7 quarters, with a flexible learning approach that allows learners to start freelancing or contributing to projects after the third quarter.\n",
      "\n",
      "**Foundation Level (3 Quarters)**\n",
      "\n",
      "* Quarter 1: Applied Generative AI Fundamentals (certifications: Microsoft Certified: Azure AI Engineer Associate, Certified CrewAI Engineer)\n",
      "* Quarter 2: Cloud Native AI Powered Microservices Design, Development, and Deployment (certifications: PostgreSQL 13 Associate Certification, Confluent Certified Developer for Apache Kafka (CCDAK))\n",
      "* Quarter 3: Cloud-Native AI Model Training and Deployment (hands-on experience with data preparation, fine-tuning, and deploying Large Language Models)\n",
      "\n",
      "**Professional Level (4 Quarters)**\n",
      "\n",
      "* Quarter 1: Applied Generative AI Fundamentals\n",
      "* Quarter 2: Cloud Native AI Powered Microservices Design, Development, and Deployment\n",
      "* Quarter 3: Advanced Cloud-Native AI Model Training and Deployment (fine-tuning Open-Source Large Language Models with PyTorch on Meta LLaMA 3, cloud-native training and deployment using Nvidia NIM, Docker, and Kubernetes)\n",
      "* Quarter 4: Physical AI and Humanoid Robotics Development (design, simulate, and deploy advanced humanoid robots capable of natural interactions)\n",
      "\n",
      "Additionally, the program includes three optional specializations:\n",
      "\n",
      "* **Physical AI and Humanoid Robotics**: This specialization focuses on designing, simulating, and deploying advanced humanoid robots capable of natural interactions using ROS 2, Open Source Meta Llama 3, and OpenAI technologies.\n",
      "* **Kubernetes and Distributed System Design**: Learners will master Kubernetes, Terraform, and GitHub Actions to deploy their AI APIs and microservices in the cloud, and design distributed systems that are scalable, fault-tolerant, consistent, available, and partition-tolerant.\n",
      "* **Frontend Specialization**: Learners will develop front-end web GUIs using Next.js, a popular framework for building high-performance, scalable, and developer-friendly applications, in addition to other frameworks such as TypeScript, enabling them to create interactive and data-driven user interfaces for AI applications.\n",
      "\n",
      "Notable mentions in the new context include:\n",
      "\n",
      "* The Fourth Industrial Revolution, powered by advanced robotics, artificial intelligence, and the Internet of Things, will fundamentally alter the way we live, work, and relate to one another.\n",
      "* Generative AI is set to revolutionize our daily lives and work environments, with an estimated annual economic value of $2.6 trillion to $4.4 trillion across various sectors.\n",
      "* Cloud native is an approach in software development that enables application creation, deployment, and management in cloud environments, with over 90% of global organizations expected to be running containerized applications in production by 2024.\n",
      "\n",
      "I removed the unnecessary context and kept only the relevant information, including the new specializations and the emphasis on Next.js for frontend development.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "container orchestration. This number has been steadily increasing as more\n",
      "companies realise the benefits of these technologies for managing containerized\n",
      "applications ￼￼.\n",
      "Technologies such as Kubernetes, Docker, serverless containers, APIs, SQL\n",
      "Databases, and Kafka support developers in swiftly constructing cloud-native\n",
      "applications. These tools offer a standardised platform for application development\n",
      "and management across various cloud services like Azure, Google Cloud, and AWS.\n",
      "This revolution is pivotal for technology and job landscapes, making it essential\n",
      "knowledge in fast-evolving tech cycles. The rapid emergence of Gen AI-powered\n",
      "and Physical AI technologies, and the evolving demand for skills necessitate\n",
      "extensive and timely professional training.\n",
      "10\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here is the refined summary:\n",
      "\n",
      "**Cloud Native AI Powered Microservices Certification Program**\n",
      "\n",
      "This 21-month certification program, starting August 1, 2024, trains developers to build cutting-edge Cloud Native, Generative AI, and Physical AI solutions. The program focuses on creating custom GPTs, AI agents, and humanoids, as well as fine-tuning Large Language Models (LLMs). Learners will gain skills to develop leading-edge AI solutions for conversational interfaces and personal AI. The program is divided into two levels: foundation and professional, allowing students to start working after completing the foundation level and continue their professional studies while working.\n",
      "\n",
      "Upon completion of this program, learners will be equipped with industry-recognized skills to thrive in the age of Generative AI, Physical AI, and cloud native computing. They will be able to:\n",
      "\n",
      "* Develop AI-powered microservices using Python, FastAPI, and cutting-edge GenAI APIs\n",
      "* Design and deploy cloud-native applications using Docker, Kubernetes, and Terraform\n",
      "* Design distributed systems and AI solutions using Design Thinking and Behaviour Driven Development (BDD)\n",
      "* Fine-tune open-source Large Language Models using PyTorch and Fast AI\n",
      "* Design, simulate, and deploy advanced humanoid robots capable of natural interactions\n",
      "\n",
      "The program starts by covering the basics of GenAI and Prompt Engineering, followed by an introduction to Linux, Docker, VSCode, Devcontainer, and GitHub. Learners will master the fundamentals of Modern Python programming, including typing, which is the go-to language for AI. This foundational knowledge will be recognized with the Certified Professional Python Programmer (CPPP1) certification.\n",
      "\n",
      "**Program Structure**\n",
      "\n",
      "The program is structured into 7 quarters, with a flexible learning approach that allows learners to start freelancing or contributing to projects after the third quarter.\n",
      "\n",
      "**Foundation Level (3 Quarters)**\n",
      "\n",
      "* Quarter 1: Applied Generative AI Fundamentals (certifications: Microsoft Certified: Azure AI Engineer Associate, Certified CrewAI Engineer)\n",
      "* Quarter 2: Cloud Native AI Powered Microservices Design, Development, and Deployment (certifications: PostgreSQL 13 Associate Certification, Confluent Certified Developer for Apache Kafka (CCDAK))\n",
      "* Quarter 3: Cloud-Native AI Model Training and Deployment (hands-on experience with data preparation, fine-tuning, and deploying Large Language Models)\n",
      "\n",
      "**Professional Level (4 Quarters)**\n",
      "\n",
      "* Quarter 1: Applied Generative AI Fundamentals\n",
      "* Quarter 2: Cloud Native AI Powered Microservices Design, Development, and Deployment\n",
      "* Quarter 3: Advanced Cloud-Native AI Model Training and Deployment (fine-tuning Open-Source Large Language Models with PyTorch on Meta LLaMA 3, cloud-native training and deployment using Nvidia NIM, Docker, and Kubernetes)\n",
      "* Quarter 4: Physical AI and Humanoid Robotics Development (design, simulate, and deploy advanced humanoid robots capable of natural interactions)\n",
      "\n",
      "Additionally, the program includes three optional specializations:\n",
      "\n",
      "* **Physical AI and Humanoid Robotics**: This specialization focuses on designing, simulating, and deploying advanced humanoid robots capable of natural interactions using ROS 2, Open Source Meta Llama 3, and OpenAI technologies.\n",
      "* **Kubernetes and Distributed System Design**: Learners will master Kubernetes, Terraform, and GitHub Actions to deploy their AI APIs and microservices in the cloud, and design distributed systems that are scalable, fault-tolerant, consistent, available, and partition-tolerant.\n",
      "* **Frontend Specialization**: Learners will develop front-end web GUIs using Next.js, a popular framework for building high-performance, scalable, and developer-friendly applications, enabling them to create interactive and data-driven user interfaces for AI applications.\n",
      "\n",
      "In the context of the rapidly evolving tech landscape, driven by technologies like Kubernetes, Docker, and serverless containers, this program is essential for developing skills in cloud native computing, Generative AI, and Physical AI. With an estimated annual economic value of $2.6 trillion to $4.4 trillion across various sectors, Generative AI is set to revolutionize our daily lives and work environments. By completing this program, learners will be equipped to thrive in this new era of technological advancements.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "Vertical Specialization Level\n",
      "Students will have the option of selecting one of the following specialisations after\n",
      "the completion of sixth quarter i.e. in the seventh quarter:\n",
      "1. Healthcare and Medical GenAI Specialization\n",
      "2. Web3, Blockchain, and GenAI Integration Specialization\n",
      "3. Metaverse, 3D, and GenAI Integration Specialization\n",
      "4. GenAI for Accounting, Finance, and Banking Specialization\n",
      "5. GenAI for Engineers Specialization\n",
      "6. GenAI for Sales and Marketing Specialization\n",
      "7. GenAI for Automation and Internet of Things (IoT) Specialisation\n",
      "8. GenAI for Cyber Security\n",
      "Common Questions (FAQs) with Detailed Answers\n",
      "1. What is Cloud Native Applied Generative AI Engineering?\n",
      "Cloud Applied Generative AI Engineering (GenEng) is the application of\n",
      "generative AI technologies to solve real-world problems in the cloud.\n",
      "●\n",
      "Generative AI is a type of artificial intelligence that can create new data\n",
      "or content from existing data.\n",
      "●\n",
      "Cloud Native computing is the delivery of computing\n",
      "services—including servers, storage, databases, networking, software,\n",
      "analytics, and intelligence—over the Internet (“the cloud”).\n",
      "By combining generative AI with cloud native computing, businesses can\n",
      "solve a variety of problems, such as:\n",
      "●\n",
      "Creating personalised experiences for customers\n",
      "●\n",
      "Automating tasks\n",
      "●\n",
      "Improving decision-making\n",
      "●\n",
      "Detecting fraud\n",
      "●\n",
      "Developing new products and services\n",
      "The potential applications of cloud native-applied generative AI are endless.\n",
      "As generative AI and cloud native computing continue to develop, we can\n",
      "expect to see even more innovative and groundbreaking uses for this\n",
      "technology.\n",
      "2. How valuable are the Cloud Native Applied Generative AI developers?\n",
      "Developers with expertise in Cloud Native Applied Generative AI were in\n",
      "extremely high demand due to the increasing adoption of GenAI technologies\n",
      "across various industries. However, the supply of developers skilled\n",
      "11\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here is the refined summary:\n",
      "\n",
      "**Cloud Native AI Powered Microservices Certification Program**\n",
      "\n",
      "This 21-month certification program, starting August 1, 2024, trains developers to build cutting-edge Cloud Native, Generative AI, and Physical AI solutions. The program focuses on creating custom GPTs, AI agents, and humanoids, as well as fine-tuning Large Language Models (LLMs). Learners will gain skills to develop leading-edge AI solutions for conversational interfaces and personal AI.\n",
      "\n",
      "Upon completion of this program, learners will be equipped with industry-recognized skills to thrive in the age of Generative AI, Physical AI, and cloud native computing. They will be able to:\n",
      "\n",
      "* Develop AI-powered microservices using Python, FastAPI, and cutting-edge GenAI APIs\n",
      "* Design and deploy cloud-native applications using Docker, Kubernetes, and Terraform\n",
      "* Design distributed systems and AI solutions using Design Thinking and Behaviour Driven Development (BDD)\n",
      "* Fine-tune open-source Large Language Models using PyTorch and Fast AI\n",
      "* Design, simulate, and deploy advanced humanoid robots capable of natural interactions\n",
      "\n",
      "The program starts by covering the basics of GenAI and Prompt Engineering, followed by an introduction to Linux, Docker, VSCode, Devcontainer, and GitHub. Learners will master the fundamentals of Modern Python programming, including typing, which is the go-to language for AI. This foundational knowledge will be recognized with the Certified Professional Python Programmer (CPPP1) certification.\n",
      "\n",
      "**Program Structure**\n",
      "\n",
      "The program is structured into 7 quarters, with a flexible learning approach that allows learners to start freelancing or contributing to projects after the third quarter.\n",
      "\n",
      "**Foundation Level (3 Quarters)**\n",
      "\n",
      "* Quarter 1: Applied Generative AI Fundamentals (certifications: Microsoft Certified: Azure AI Engineer Associate, Certified CrewAI Engineer)\n",
      "* Quarter 2: Cloud Native AI Powered Microservices Design, Development, and Deployment (certifications: PostgreSQL 13 Associate Certification, Confluent Certified Developer for Apache Kafka (CCDAK))\n",
      "* Quarter 3: Cloud-Native AI Model Training and Deployment (hands-on experience with data preparation, fine-tuning, and deploying Large Language Models)\n",
      "\n",
      "**Professional Level (4 Quarters)**\n",
      "\n",
      "* Quarter 1: Applied Generative AI Fundamentals\n",
      "* Quarter 2: Cloud Native AI Powered Microservices Design, Development, and Deployment\n",
      "* Quarter 3: Advanced Cloud-Native AI Model Training and Deployment (fine-tuning Open-Source Large Language Models with PyTorch on Meta LLaMA 3, cloud-native training and deployment using Nvidia NIM, Docker, and Kubernetes)\n",
      "* Quarter 4: Physical AI and Humanoid Robotics Development (design, simulate, and deploy advanced humanoid robots capable of natural interactions)\n",
      "\n",
      "**Vertical Specialization Level**\n",
      "\n",
      "In the seventh quarter, learners can select from eight vertical specialization options:\n",
      "\n",
      "1. Healthcare and Medical GenAI Specialization\n",
      "2. Web3, Blockchain, and GenAI Integration Specialization\n",
      "3. Metaverse, 3D, and GenAI Integration Specialization\n",
      "4. GenAI for Accounting, Finance, and Banking Specialization\n",
      "5. GenAI for Engineers Specialization\n",
      "6. GenAI for Sales and Marketing Specialization\n",
      "7. GenAI for Automation and Internet of Things (IoT) Specialization\n",
      "8. GenAI for Cyber Security\n",
      "\n",
      "**Career Opportunities**\n",
      "\n",
      "Developers with expertise in Cloud Native Applied Generative AI are in extremely high demand, with an estimated annual economic value of $2.6 trillion to $4.4 trillion across various sectors. By completing this program, learners will be equipped to thrive in this new era of technological advancements.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "specifically in this niche area might not have been as abundant compared to\n",
      "more generalised AI or cloud computing roles.\n",
      "The demand for AI developers, especially those proficient in applying\n",
      "generative AI techniques within cloud native environments, has been rising\n",
      "due to the growing interest in using AI for creative applications, content\n",
      "generation, image synthesis, natural language processing, and other\n",
      "innovative purposes.\n",
      "According to some sources, the average salary for a Cloud Native Applied\n",
      "Generative AI developer in the global market is around $150,000 per year.\n",
      "However, this may vary depending on the experience level, industry, location,\n",
      "and skills of the developer. For example, a senior Cloud Applied Generative\n",
      "AI developer with more than five years of experience can earn up to $200,000\n",
      "per year. A Cloud Applied Generative AI developer working in the financial\n",
      "services industry can earn more than a developer working in the\n",
      "entertainment industry. A Cloud Applied Generative AI developer working in\n",
      "New York City can earn more than a developer working in Dubai. In general,\n",
      "highly skilled AI developers, especially those specialising in applied\n",
      "generative AI within cloud environments, tend to earn competitive salaries that\n",
      "are often above the average for software developers or AI engineers due to\n",
      "the specialised nature of their skills. Moreover, as generative AI technology\n",
      "becomes more widely adopted and integrated into various products and\n",
      "services, the demand for Cloud Applied Generative AI developers is likely to\n",
      "increase.\n",
      "Therefore, Cloud Applied Generative AI developers are valuable professionals\n",
      "who have a bright future ahead of them. They can leverage their creativity and\n",
      "technical skills to create innovative solutions that can benefit various\n",
      "industries and domains. They can also enjoy very competitive salary and\n",
      "career growth opportunities.\n",
      "3. What is the potential for Cloud Applied Generative AI Developers to start\n",
      "their own companies?\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here's a refined summary based on the original content and the additional context:\n",
      "\n",
      "**Cloud Native AI Powered Microservices Certification Program**\n",
      "\n",
      "This 21-month certification program, starting August 1, 2024, trains developers to build cutting-edge Cloud Native, Generative AI, and Physical AI solutions. The program focuses on creating custom GPTs, AI agents, and humanoids, as well as fine-tuning Large Language Models (LLMs). Learners will gain skills to develop leading-edge AI solutions for conversational interfaces and personal AI.\n",
      "\n",
      "Upon completion of this program, learners will be equipped with industry-recognized skills to thrive in the age of Generative AI, Physical AI, and cloud native computing. They will be able to:\n",
      "\n",
      "* Develop AI-powered microservices using Python, FastAPI, and cutting-edge GenAI APIs\n",
      "* Design and deploy cloud-native applications using Docker, Kubernetes, and Terraform\n",
      "* Design distributed systems and AI solutions using Design Thinking and Behaviour Driven Development (BDD)\n",
      "* Fine-tune open-source Large Language Models using PyTorch and Fast AI\n",
      "* Design, simulate, and deploy advanced humanoid robots capable of natural interactions\n",
      "\n",
      "**Career Opportunities and Salary Potential**\n",
      "\n",
      "Developers with expertise in Cloud Native Applied Generative AI are in extremely high demand, with an estimated annual economic value of $2.6 trillion to $4.4 trillion across various sectors. According to sources, the average salary for a Cloud Native Applied Generative AI developer is around $150,000 per year, with senior developers earning up to $200,000 per year. As generative AI technology becomes more widely adopted, the demand for Cloud Applied Generative AI developers is likely to increase.\n",
      "\n",
      "**Program Structure and Career Advancement**\n",
      "\n",
      "The program is structured into 7 quarters, with a flexible learning approach that allows learners to start freelancing or contributing to projects after the third quarter. Learners will have the opportunity to specialize in various verticals, including:\n",
      "\n",
      "1. Healthcare and Medical GenAI Specialization\n",
      "2. Web3, Blockchain, and GenAI Integration Specialization\n",
      "3. Metaverse, 3D, and GenAI Integration Specialization\n",
      "4. GenAI for Accounting, Finance, and Banking Specialization\n",
      "5. GenAI for Engineers Specialization\n",
      "6. GenAI for Sales and Marketing Specialization\n",
      "7. GenAI for Automation and Internet of Things (IoT) Specialization\n",
      "8. GenAI for Cyber Security\n",
      "\n",
      "With the skills and knowledge gained from this program, learners can leverage their creativity and technical expertise to create innovative solutions, enjoy competitive salaries, and have a bright future ahead of them. Additionally, the program prepares learners for career advancement opportunities, including entrepreneurship, with the potential to start their own companies in the field of Cloud Applied Generative AI.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "technical skills to create innovative solutions that can benefit various\n",
      "industries and domains. They can also enjoy very competitive salary and\n",
      "career growth opportunities.\n",
      "3. What is the potential for Cloud Applied Generative AI Developers to start\n",
      "their own companies?\n",
      "Cloud Applied Generative AI Developers have a significant potential to start\n",
      "their own companies due to several factors:\n",
      "1. Emerging Field: Generative AI, particularly when applied within cloud\n",
      "environments, is still an evolving field with immense potential for innovation.\n",
      "Developers who understand the intricacies of both generative AI techniques\n",
      "and cloud technologies can identify unique opportunities to create novel\n",
      "products, services, or solutions.\n",
      "2. Market Demand: There is a growing demand for AI-driven applications,\n",
      "especially those that involve generative capabilities such as image\n",
      "12\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here's a refined summary based on the original content and the additional context:\n",
      "\n",
      "**Cloud Native AI Powered Microservices Certification Program**\n",
      "\n",
      "This 21-month certification program, starting August 1, 2024, trains developers to build cutting-edge Cloud Native, Generative AI, and Physical AI solutions. The program focuses on creating custom GPTs, AI agents, and humanoids, as well as fine-tuning Large Language Models (LLMs). Learners will gain skills to develop leading-edge AI solutions for conversational interfaces and personal AI.\n",
      "\n",
      "Upon completion of this program, learners will be equipped with industry-recognized skills to thrive in the age of Generative AI, Physical AI, and cloud native computing. They will be able to:\n",
      "\n",
      "* Develop AI-powered microservices using Python, FastAPI, and cutting-edge GenAI APIs\n",
      "* Design and deploy cloud-native applications using Docker, Kubernetes, and Terraform\n",
      "* Design distributed systems and AI solutions using Design Thinking and Behaviour Driven Development (BDD)\n",
      "* Fine-tune open-source Large Language Models using PyTorch and Fast AI\n",
      "* Design, simulate, and deploy advanced humanoid robots capable of natural interactions\n",
      "\n",
      "**Career Opportunities and Salary Potential**\n",
      "\n",
      "Developers with expertise in Cloud Native Applied Generative AI are in extremely high demand, with an estimated annual economic value of $2.6 trillion to $4.4 trillion across various sectors. According to sources, the average salary for a Cloud Native Applied Generative AI developer is around $150,000 per year, with senior developers earning up to $200,000 per year. As generative AI technology becomes more widely adopted, the demand for Cloud Applied Generative AI developers is likely to increase.\n",
      "\n",
      "**Program Structure and Career Advancement**\n",
      "\n",
      "The program is structured into 7 quarters, with a flexible learning approach that allows learners to start freelancing or contributing to projects after the third quarter. Learners will have the opportunity to specialize in various verticals, including:\n",
      "\n",
      "1. Healthcare and Medical GenAI Specialization\n",
      "2. Web3, Blockchain, and GenAI Integration Specialization\n",
      "3. Metaverse, 3D, and GenAI Integration Specialization\n",
      "4. GenAI for Accounting, Finance, and Banking Specialization\n",
      "5. GenAI for Engineers Specialization\n",
      "6. GenAI for Sales and Marketing Specialization\n",
      "7. GenAI for Automation and Internet of Things (IoT) Specialization\n",
      "8. GenAI for Cyber Security\n",
      "\n",
      "**Entrepreneurial Opportunities**\n",
      "\n",
      "With the skills and knowledge gained from this program, learners have a significant potential to start their own companies in the field of Cloud Applied Generative AI. The emerging field of Generative AI, particularly when applied within cloud environments, offers immense opportunities for innovation. Learners can identify unique opportunities to create novel products, services, or solutions, driven by the growing demand for AI-driven applications with generative capabilities.\n",
      "\n",
      "**Career Growth and Salary Potential**\n",
      "\n",
      "Cloud Applied Generative AI developers can enjoy very competitive salaries and career growth opportunities, with the potential to earn up to $200,000 per year. With the industry-recognized skills gained from this program, learners can create innovative solutions that benefit various industries and domains, enjoy competitive salaries, and have a bright future ahead of them.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "generation, content creation, style transfer, etc. Developers with expertise in\n",
      "this area can leverage this demand to create specialized products that cater\n",
      "to specific industries or consumer needs.\n",
      "3. Innovation and Differentiation: The ability to develop unique and innovative\n",
      "solutions using generative AI in the cloud can set apart these developers'\n",
      "startups from more conventional companies. They can explore new ways of\n",
      "generating content, enhancing user experiences, or solving complex problems\n",
      "with AI-generated solutions.\n",
      "4. Access to Cloud Resources: Cloud platforms provide scalable and\n",
      "cost-effective resources that are crucial for AI development. Developers\n",
      "starting their own companies can leverage cloud services to access powerful\n",
      "computing resources, storage, and AI-related services without significant\n",
      "upfront investment.\n",
      "5. Entrepreneurial Opportunities: Developers with entrepreneurial spirit and a\n",
      "deep understanding of AI technologies can identify gaps in the market and\n",
      "build startups to fill those gaps. They can create platforms, tools, or services\n",
      "that simplify the adoption of generative AI for businesses or developers.\n",
      "6. Collaboration and Partnerships: These developers can collaborate with\n",
      "other experts in AI, domain specialists, or businesses to create innovative\n",
      "solutions or explore new application areas for generative AI in the cloud.\n",
      "However, starting a company, especially in a specialised field like Cloud\n",
      "Applied Generative AI, requires more than technical expertise. It also\n",
      "demands business acumen, understanding market needs, networking,\n",
      "securing funding, managing resources effectively, and navigating legal and\n",
      "regulatory landscapes.\n",
      "Successful entrepreneurship in this domain involves a combination of\n",
      "technical skills, innovation, a deep understanding of market dynamics, and the\n",
      "ability to transform technical expertise into viable products or services that\n",
      "address real-world challenges or opportunities.\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here is the refined summary based on the original content and the additional context:\n",
      "\n",
      "**Cloud Native AI Powered Microservices Certification Program**\n",
      "\n",
      "This 21-month certification program, starting August 1, 2024, trains developers to build cutting-edge Cloud Native, Generative AI, and Physical AI solutions. The program focuses on creating custom GPTs, AI agents, and humanoids, as well as fine-tuning Large Language Models (LLMs). Learners will gain skills to develop leading-edge AI solutions for conversational interfaces and personal AI.\n",
      "\n",
      "Upon completion of this program, learners will be equipped with industry-recognized skills to thrive in the age of Generative AI, Physical AI, and cloud native computing. They will be able to:\n",
      "\n",
      "* Develop AI-powered microservices using Python, FastAPI, and cutting-edge GenAI APIs\n",
      "* Design and deploy cloud-native applications using Docker, Kubernetes, and Terraform\n",
      "* Design distributed systems and AI solutions using Design Thinking and Behaviour Driven Development (BDD)\n",
      "* Fine-tune open-source Large Language Models using PyTorch and Fast AI\n",
      "* Design, simulate, and deploy advanced humanoid robots capable of natural interactions\n",
      "\n",
      "**Career Opportunities and Salary Potential**\n",
      "\n",
      "Developers with expertise in Cloud Native Applied Generative AI are in extremely high demand, with an estimated annual economic value of $2.6 trillion to $4.4 trillion across various sectors. According to sources, the average salary for a Cloud Native Applied Generative AI developer is around $150,000 per year, with senior developers earning up to $200,000 per year. As generative AI technology becomes more widely adopted, the demand for Cloud Applied Generative AI developers is likely to increase.\n",
      "\n",
      "**Program Structure and Career Advancement**\n",
      "\n",
      "The program is structured into 7 quarters, with a flexible learning approach that allows learners to start freelancing or contributing to projects after the third quarter. Learners will have the opportunity to specialize in various verticals, including:\n",
      "\n",
      "1. Healthcare and Medical GenAI Specialization\n",
      "2. Web3, Blockchain, and GenAI Integration Specialization\n",
      "3. Metaverse, 3D, and GenAI Integration Specialization\n",
      "4. GenAI for Accounting, Finance, and Banking Specialization\n",
      "5. GenAI for Engineers Specialization\n",
      "6. GenAI for Sales and Marketing Specialization\n",
      "7. GenAI for Automation and Internet of Things (IoT) Specialization\n",
      "8. GenAI for Cyber Security\n",
      "\n",
      "**Entrepreneurial Opportunities**\n",
      "\n",
      "With the skills and knowledge gained from this program, learners have a significant potential to start their own companies in the field of Cloud Applied Generative AI. The emerging field of Generative AI, particularly when applied within cloud environments, offers immense opportunities for innovation. Learners can identify unique opportunities to create novel products, services, or solutions, driven by the growing demand for AI-driven applications with generative capabilities.\n",
      "\n",
      "**Career Growth and Salary Potential**\n",
      "\n",
      "Cloud Applied Generative AI developers can enjoy very competitive salaries and career growth opportunities, with the potential to earn up to $200,000 per year. With the industry-recognized skills gained from this program, learners can create innovative solutions that benefit various industries and domains, enjoy competitive salaries, and have a bright future ahead of them.\n",
      "\n",
      "**Additional Career Advantages**\n",
      "\n",
      "Beyond technical skills and salary potential, Cloud Applied Generative AI developers can also leverage their expertise to:\n",
      "\n",
      "* Create specialized products that cater to specific industries or consumer needs\n",
      "* Develop unique and innovative solutions using generative AI in the cloud, setting apart their startups from more conventional companies\n",
      "* Leverage cloud resources to access powerful computing resources, storage, and AI-related services without significant upfront investment\n",
      "* Collaborate with other experts in AI, domain specialists, or businesses to create innovative solutions or explore new application areas for generative AI in the cloud\n",
      "* Identify gaps in the market and build startups to fill those gaps, creating platforms, tools, or services that simplify the adoption of generative AI for businesses or developers.\n",
      "\n",
      "**Transforming Technical Expertise into Entrepreneurial Success**\n",
      "\n",
      "While technical expertise is essential, successful entrepreneurship in Cloud Applied Generative AI also demands business acumen, understanding of market needs, networking, securing funding, managing resources effectively, and navigating legal and regulatory landscapes. Learners from this program will be well-equipped to transform their technical expertise into viable products or services that address real-world challenges or opportunities.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "regulatory landscapes.\n",
      "Successful entrepreneurship in this domain involves a combination of\n",
      "technical skills, innovation, a deep understanding of market dynamics, and the\n",
      "ability to transform technical expertise into viable products or services that\n",
      "address real-world challenges or opportunities.\n",
      "Developers aspiring to start their own companies in the Cloud Applied\n",
      "Generative AI space can do so by conducting thorough market research,\n",
      "networking with industry experts, building a strong team, and developing a\n",
      "clear business plan that highlights the unique value proposition of their\n",
      "offerings.\n",
      "To sum up, the potential for Cloud Applied Generative AI Developers to start\n",
      "their own companies is high.\n",
      "●\n",
      "Generative AI is a rapidly growing field with a high demand for skilled\n",
      "professionals.\n",
      "13\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here's a refined summary based on the original content and the additional context:\n",
      "\n",
      "**Cloud Native AI Powered Microservices Certification Program**\n",
      "\n",
      "This 21-month certification program, starting August 1, 2024, trains developers to build cutting-edge Cloud Native, Generative AI, and Physical AI solutions. The program focuses on creating custom GPTs, AI agents, and humanoids, as well as fine-tuning Large Language Models (LLMs). Learners will gain skills to develop leading-edge AI solutions for conversational interfaces and personal AI.\n",
      "\n",
      "Upon completion of this program, learners will be equipped with industry-recognized skills to thrive in the age of Generative AI, Physical AI, and cloud native computing. They will be able to:\n",
      "\n",
      "* Develop AI-powered microservices using Python, FastAPI, and cutting-edge GenAI APIs\n",
      "* Design and deploy cloud-native applications using Docker, Kubernetes, and Terraform\n",
      "* Design distributed systems and AI solutions using Design Thinking and Behaviour Driven Development (BDD)\n",
      "* Fine-tune open-source Large Language Models using PyTorch and Fast AI\n",
      "* Design, simulate, and deploy advanced humanoid robots capable of natural interactions\n",
      "\n",
      "**Career Opportunities and Salary Potential**\n",
      "\n",
      "Developers with expertise in Cloud Native Applied Generative AI are in extremely high demand, with an estimated annual economic value of $2.6 trillion to $4.4 trillion across various sectors. According to sources, the average salary for a Cloud Native Applied Generative AI developer is around $150,000 per year, with senior developers earning up to $200,000 per year. As generative AI technology becomes more widely adopted, the demand for Cloud Applied Generative AI developers is likely to increase.\n",
      "\n",
      "**Program Structure and Career Advancement**\n",
      "\n",
      "The program is structured into 7 quarters, with a flexible learning approach that allows learners to start freelancing or contributing to projects after the third quarter. Learners will have the opportunity to specialize in various verticals, including:\n",
      "\n",
      "1. Healthcare and Medical GenAI Specialization\n",
      "2. Web3, Blockchain, and GenAI Integration Specialization\n",
      "3. Metaverse, 3D, and GenAI Integration Specialization\n",
      "4. GenAI for Accounting, Finance, and Banking Specialization\n",
      "5. GenAI for Engineers Specialization\n",
      "6. GenAI for Sales and Marketing Specialization\n",
      "7. GenAI for Automation and Internet of Things (IoT) Specialization\n",
      "8. GenAI for Cyber Security\n",
      "\n",
      "**Entrepreneurial Opportunities and Career Growth**\n",
      "\n",
      "With the skills and knowledge gained from this program, learners have a significant potential to start their own companies in the field of Cloud Applied Generative AI. The emerging field of Generative AI, particularly when applied within cloud environments, offers immense opportunities for innovation. Learners can identify unique opportunities to create novel products, services, or solutions, driven by the growing demand for AI-driven applications with generative capabilities.\n",
      "\n",
      "Successful entrepreneurship in Cloud Applied Generative AI demands a combination of technical skills, innovation, a deep understanding of market dynamics, and the ability to transform technical expertise into viable products or services. Developers aspiring to start their own companies can do so by conducting thorough market research, networking with industry experts, building a strong team, and developing a clear business plan.\n",
      "\n",
      "**Transforming Technical Expertise into Entrepreneurial Success**\n",
      "\n",
      "Cloud Applied Generative AI developers can enjoy very competitive salaries and career growth opportunities, with the potential to earn up to $200,000 per year. With the industry-recognized skills gained from this program, learners can create innovative solutions that benefit various industries and domains, enjoy competitive salaries, and have a bright future ahead of them.\n",
      "\n",
      "**Additional Career Advantages**\n",
      "\n",
      "Beyond technical skills and salary potential, Cloud Applied Generative AI developers can also leverage their expertise to:\n",
      "\n",
      "* Create specialized products that cater to specific industries or consumer needs\n",
      "* Develop unique and innovative solutions using generative AI in the cloud, setting apart their startups from more conventional companies\n",
      "* Leverage cloud resources to access powerful computing resources, storage, and AI-related services without significant upfront investment\n",
      "* Collaborate with other experts in AI, domain specialists, or businesses to create innovative solutions or explore new application areas for generative AI in the cloud\n",
      "* Identify gaps in the market and build startups to fill those gaps, creating platforms, tools, or services that simplify the adoption of generative AI for businesses or developers.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "●\n",
      "The Certified Generative AI (GenEng) Developer and Engineering\n",
      "Program provides students with the skills and knowledge they need to\n",
      "develop and apply cutting-edge generative AI technologies.\n",
      "●\n",
      "The program also teaches students how to start and run a successful\n",
      "business.\n",
      "●\n",
      "Graduates of the program will be well-positioned to start their own\n",
      "companies and capitalise on the growing demand for generative AI\n",
      "solutions.\n",
      "4. Is the program not too long, twenty one months is a long time?\n",
      "The length of the program is twenty one months which is broken down into\n",
      "seven quarters of three months each. The program covers a wide range of\n",
      "topics including Python, GenAI, Microservices, Database, Cloud\n",
      "Development, Fine-tuning, DevOps, GPTs, AI Agents, and Humanoids. The\n",
      "program is designed to give students a comprehensive understanding of\n",
      "generative AI and prepare them for careers in this field. Nothing valuable can\n",
      "be achieved overnight, there are no shortcuts in life.\n",
      "5. Why don't we use TypeScript (Node.js) to develop APIs instead of using\n",
      "Python?\n",
      "We will not use Typescript in GenAI API development because Python is a\n",
      "priority with the AI community when working with AI and if any updates come\n",
      "in libraries they will first come for Python. Python is always a better choice\n",
      "when dealing with AI and API.\n",
      "●\n",
      "Python is the de facto standard for AI Development.\n",
      "●\n",
      "TypeScript is a more modern language that is gaining popularity for\n",
      "Web Development, but Python is more widely used and has a larger\n",
      "ecosystem of libraries and frameworks available, especially for AI.\n",
      "●\n",
      "TypeScript is used for web user interfaces, while Python is used for\n",
      "APIs.\n",
      "●\n",
      "In the second quarter, students will learn to develop APIs using Python\n",
      "instead of TypeScript.\n",
      "●\n",
      "Python is a more commonly used language for AI and API\n",
      "development, and it has a larger ecosystem of libraries and\n",
      "frameworks available for these purposes.\n",
      "●\n",
      "TypeScript is a more modern language that is becoming increasingly\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type=\"refine\",\n",
    "    verbose=True\n",
    ")\n",
    "output = chain.run(text_chunks[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Here's the refined summary:\n",
       "\n",
       "**Cloud Native AI Powered Microservices Certification Program**\n",
       "\n",
       "This <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>-month certification program, starting August <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>, trains developers to build cutting-edge Cloud Native,\n",
       "Generative AI, and Physical AI solutions. The program focuses on creating custom GPTs, AI agents, and humanoids, as\n",
       "well as fine-tuning Large Language Models <span style=\"font-weight: bold\">(</span>LLMs<span style=\"font-weight: bold\">)</span>. Learners will gain skills to develop leading-edge AI solutions \n",
       "for conversational interfaces and personal AI.\n",
       "\n",
       "Upon completion of this program, learners will be equipped with industry-recognized skills to thrive in the age of \n",
       "Generative AI, Physical AI, and cloud native computing. They will be able to:\n",
       "\n",
       "* Develop AI-powered microservices using Python, FastAPI, and cutting-edge GenAI APIs\n",
       "* Design and deploy cloud-native applications using Docker, Kubernetes, and Terraform\n",
       "* Design distributed systems and AI solutions using Design Thinking and Behaviour Driven Development <span style=\"font-weight: bold\">(</span>BDD<span style=\"font-weight: bold\">)</span>\n",
       "* Fine-tune open-source Large Language Models using PyTorch and Fast AI\n",
       "* Design, simulate, and deploy advanced humanoid robots capable of natural interactions\n",
       "\n",
       "**Career Opportunities and Salary Potential**\n",
       "\n",
       "Developers with expertise in Cloud Native Applied Generative AI are in extremely high demand, with an estimated \n",
       "annual economic value of $<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.6</span> trillion to $<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.4</span> trillion across various sectors. According to sources, the average \n",
       "salary for a Cloud Native Applied Generative AI developer is around $<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">150</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">000</span> per year, with senior developers \n",
       "earning up to $<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">000</span> per year. As generative AI technology becomes more widely adopted, the demand for Cloud \n",
       "Applied Generative AI developers is likely to increase.\n",
       "\n",
       "**Program Structure and Career Advancement**\n",
       "\n",
       "The program is structured into <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> quarters, with a flexible learning approach that allows learners to start \n",
       "freelancing or contributing to projects after the third quarter. Learners will have the opportunity to specialize \n",
       "in various verticals, including:\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Healthcare and Medical GenAI Specialization\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Web3, Blockchain, and GenAI Integration Specialization\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Metaverse, 3D, and GenAI Integration Specialization\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. GenAI for Accounting, Finance, and Banking Specialization\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>. GenAI for Engineers Specialization\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>. GenAI for Sales and Marketing Specialization\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>. GenAI for Automation and Internet of Things <span style=\"font-weight: bold\">(</span>IoT<span style=\"font-weight: bold\">)</span> Specialization\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>. GenAI for Cyber Security\n",
       "\n",
       "**Key Highlights**\n",
       "\n",
       "* The program will cover Python as the primary language for GenAI API development, due to its widespread adoption \n",
       "and larger ecosystem of libraries and frameworks.\n",
       "* The <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>-month program duration is designed to provide comprehensive training in Cloud Native, Generative AI, and \n",
       "Physical AI, and is not considered too long given the breadth of topics covered.\n",
       "* Learners will gain skills to develop and apply cutting-edge generative AI technologies, as well as start and run \n",
       "a successful business.\n",
       "* Graduates will be well-positioned to start their own companies and capitalize on the growing demand for \n",
       "generative AI solutions.\n",
       "\n",
       "**Entrepreneurial Opportunities and Career Growth**\n",
       "\n",
       "With the skills and knowledge gained from this program, learners have a significant potential to start their own \n",
       "companies in the field of Cloud Applied Generative AI. The emerging field of Generative AI, particularly when \n",
       "applied within cloud environments, offers immense opportunities for innovation. Learners can identify unique \n",
       "opportunities to create novel products, services, or solutions, driven by the growing demand for AI-driven \n",
       "applications with generative capabilities.\n",
       "\n",
       "Successful entrepreneurship in Cloud Applied Generative AI demands a combination of technical skills, innovation, a\n",
       "deep understanding of market dynamics, and the ability to transform technical expertise into viable products or \n",
       "services. Developers aspiring to start their own companies can do so by conducting thorough market research, \n",
       "networking with industry experts, building a strong team, and developing a clear business plan.\n",
       "\n",
       "**Transforming Technical Expertise into Entrepreneurial Success**\n",
       "\n",
       "Cloud Applied Generative AI developers can enjoy very competitive salaries and career growth opportunities, with \n",
       "the potential to earn up to $<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">000</span> per year. With the industry-recognized skills gained from this program, \n",
       "learners can create innovative solutions that benefit various industries and domains, enjoy competitive salaries, \n",
       "and have a bright future ahead of them.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Here's the refined summary:\n",
       "\n",
       "**Cloud Native AI Powered Microservices Certification Program**\n",
       "\n",
       "This \u001b[1;36m21\u001b[0m-month certification program, starting August \u001b[1;36m1\u001b[0m, \u001b[1;36m2024\u001b[0m, trains developers to build cutting-edge Cloud Native,\n",
       "Generative AI, and Physical AI solutions. The program focuses on creating custom GPTs, AI agents, and humanoids, as\n",
       "well as fine-tuning Large Language Models \u001b[1m(\u001b[0mLLMs\u001b[1m)\u001b[0m. Learners will gain skills to develop leading-edge AI solutions \n",
       "for conversational interfaces and personal AI.\n",
       "\n",
       "Upon completion of this program, learners will be equipped with industry-recognized skills to thrive in the age of \n",
       "Generative AI, Physical AI, and cloud native computing. They will be able to:\n",
       "\n",
       "* Develop AI-powered microservices using Python, FastAPI, and cutting-edge GenAI APIs\n",
       "* Design and deploy cloud-native applications using Docker, Kubernetes, and Terraform\n",
       "* Design distributed systems and AI solutions using Design Thinking and Behaviour Driven Development \u001b[1m(\u001b[0mBDD\u001b[1m)\u001b[0m\n",
       "* Fine-tune open-source Large Language Models using PyTorch and Fast AI\n",
       "* Design, simulate, and deploy advanced humanoid robots capable of natural interactions\n",
       "\n",
       "**Career Opportunities and Salary Potential**\n",
       "\n",
       "Developers with expertise in Cloud Native Applied Generative AI are in extremely high demand, with an estimated \n",
       "annual economic value of $\u001b[1;36m2.6\u001b[0m trillion to $\u001b[1;36m4.4\u001b[0m trillion across various sectors. According to sources, the average \n",
       "salary for a Cloud Native Applied Generative AI developer is around $\u001b[1;36m150\u001b[0m,\u001b[1;36m000\u001b[0m per year, with senior developers \n",
       "earning up to $\u001b[1;36m200\u001b[0m,\u001b[1;36m000\u001b[0m per year. As generative AI technology becomes more widely adopted, the demand for Cloud \n",
       "Applied Generative AI developers is likely to increase.\n",
       "\n",
       "**Program Structure and Career Advancement**\n",
       "\n",
       "The program is structured into \u001b[1;36m7\u001b[0m quarters, with a flexible learning approach that allows learners to start \n",
       "freelancing or contributing to projects after the third quarter. Learners will have the opportunity to specialize \n",
       "in various verticals, including:\n",
       "\n",
       "\u001b[1;36m1\u001b[0m. Healthcare and Medical GenAI Specialization\n",
       "\u001b[1;36m2\u001b[0m. Web3, Blockchain, and GenAI Integration Specialization\n",
       "\u001b[1;36m3\u001b[0m. Metaverse, 3D, and GenAI Integration Specialization\n",
       "\u001b[1;36m4\u001b[0m. GenAI for Accounting, Finance, and Banking Specialization\n",
       "\u001b[1;36m5\u001b[0m. GenAI for Engineers Specialization\n",
       "\u001b[1;36m6\u001b[0m. GenAI for Sales and Marketing Specialization\n",
       "\u001b[1;36m7\u001b[0m. GenAI for Automation and Internet of Things \u001b[1m(\u001b[0mIoT\u001b[1m)\u001b[0m Specialization\n",
       "\u001b[1;36m8\u001b[0m. GenAI for Cyber Security\n",
       "\n",
       "**Key Highlights**\n",
       "\n",
       "* The program will cover Python as the primary language for GenAI API development, due to its widespread adoption \n",
       "and larger ecosystem of libraries and frameworks.\n",
       "* The \u001b[1;36m21\u001b[0m-month program duration is designed to provide comprehensive training in Cloud Native, Generative AI, and \n",
       "Physical AI, and is not considered too long given the breadth of topics covered.\n",
       "* Learners will gain skills to develop and apply cutting-edge generative AI technologies, as well as start and run \n",
       "a successful business.\n",
       "* Graduates will be well-positioned to start their own companies and capitalize on the growing demand for \n",
       "generative AI solutions.\n",
       "\n",
       "**Entrepreneurial Opportunities and Career Growth**\n",
       "\n",
       "With the skills and knowledge gained from this program, learners have a significant potential to start their own \n",
       "companies in the field of Cloud Applied Generative AI. The emerging field of Generative AI, particularly when \n",
       "applied within cloud environments, offers immense opportunities for innovation. Learners can identify unique \n",
       "opportunities to create novel products, services, or solutions, driven by the growing demand for AI-driven \n",
       "applications with generative capabilities.\n",
       "\n",
       "Successful entrepreneurship in Cloud Applied Generative AI demands a combination of technical skills, innovation, a\n",
       "deep understanding of market dynamics, and the ability to transform technical expertise into viable products or \n",
       "services. Developers aspiring to start their own companies can do so by conducting thorough market research, \n",
       "networking with industry experts, building a strong team, and developing a clear business plan.\n",
       "\n",
       "**Transforming Technical Expertise into Entrepreneurial Success**\n",
       "\n",
       "Cloud Applied Generative AI developers can enjoy very competitive salaries and career growth opportunities, with \n",
       "the potential to earn up to $\u001b[1;36m200\u001b[0m,\u001b[1;36m000\u001b[0m per year. With the industry-recognized skills gained from this program, \n",
       "learners can create innovative solutions that benefit various industries and domains, enjoy competitive salaries, \n",
       "and have a bright future ahead of them.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
