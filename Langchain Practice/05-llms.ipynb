{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from rich import print\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "os.environ['COHERE_API_KEY'] = os.getenv('COHERE_API_KEY')\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatGoogleGenerativeAI</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'models/gemini-1.5-flash'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">client</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient</span><span style=\"color: #000000; text-decoration-color: #000000\"> object </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x000002459E638A10</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #808000; text-decoration-color: #808000\">async_client</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;google.ai.generativelanguage_v1beta.services.generative_service.async_client.GenerativeServiceAsy</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">ncClient object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x000002459E673090</span><span style=\"font-weight: bold\">&gt;</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">default_metadata</span>=<span style=\"font-weight: bold\">()</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatGoogleGenerativeAI\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'models/gemini-1.5-flash'\u001b[0m,\n",
       "    \u001b[33mclient\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mgoogle.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient\u001b[0m\u001b[39m object \u001b[0m\n",
       "\u001b[39mat \u001b[0m\u001b[1;36m0x000002459E638A10\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[33masync_client\u001b[0m\u001b[39m=<google.ai.generativelanguage_v1beta.services.generative_service.async_client.GenerativeServiceAsy\u001b[0m\n",
       "\u001b[39mncClient object at \u001b[0m\u001b[1;36m0x000002459E673090\u001b[0m\u001b[1m>\u001b[0m,\n",
       "    \u001b[33mdefault_metadata\u001b[0m=\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">LlamaIndex is an open-source framework designed to **make large language models <span style=\"font-weight: bold\">(</span>LLMs<span style=\"font-weight: bold\">)</span> more useful for real-world \n",
       "applications**. It does this by bridging the gap between LLMs and external data sources, allowing them to access \n",
       "and process information from various sources.\n",
       "\n",
       "Here's a breakdown of what LlamaIndex does:\n",
       "\n",
       "**Key Features:**\n",
       "\n",
       "* **Data Connection:** LlamaIndex connects LLMs to data sources like:\n",
       "    * **Documents:** PDFs, Word documents, web pages\n",
       "    * **Databases:** SQL, NoSQL\n",
       "    * **APIs:** Weather, stock data, etc.\n",
       "* **Data Indexing:** It indexes data into a format LLMs can understand, allowing them to retrieve and process \n",
       "information efficiently.\n",
       "* **Querying:** Users can ask natural language questions, and LlamaIndex translates them into queries that retrieve\n",
       "relevant information from the indexed data.\n",
       "* **Response Generation:** LLMs then use the retrieved information to generate comprehensive and informative \n",
       "responses.\n",
       "* **Retrieval Augmentation:** LlamaIndex can be used to augment LLM responses with relevant information from \n",
       "external data sources, making them more accurate and complete.\n",
       "* **Customizability:** Users can customize LlamaIndex to fit their specific needs and data sources.\n",
       "\n",
       "**Benefits of using LlamaIndex:**\n",
       "\n",
       "* **Enhanced LLM Capabilities:** LLMs can access and utilize external data, improving their knowledge base and \n",
       "ability to provide accurate and relevant information.\n",
       "* **Real-World Applications:** LlamaIndex enables LLMs to be used in a wider range of practical applications, such \n",
       "as:\n",
       "    * **Knowledge Management:** Creating a searchable knowledge base from company documents.\n",
       "    * **Customer Service:** Providing accurate and helpful responses to customer inquiries.\n",
       "    * **Research:** Summarizing and analyzing research papers.\n",
       "    * **Education:** Creating personalized learning experiences.\n",
       "* **Simplified LLM Integration:** LlamaIndex simplifies the process of integrating LLMs with external data sources,\n",
       "making it easier for developers to build LLM-powered applications.\n",
       "\n",
       "**In essence, LlamaIndex acts as a bridge between LLMs and the real world, allowing them to access and utilize \n",
       "external data to provide more comprehensive and helpful responses.**\n",
       "\n",
       "**Here's an analogy:** Think of LlamaIndex as a librarian who helps you find the right books in a library. You ask \n",
       "the librarian a question, and they direct you to the relevant books. Similarly, LlamaIndex helps LLMs find and \n",
       "understand information from various sources, making them more knowledgeable and helpful.\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "LlamaIndex is an open-source framework designed to **make large language models \u001b[1m(\u001b[0mLLMs\u001b[1m)\u001b[0m more useful for real-world \n",
       "applications**. It does this by bridging the gap between LLMs and external data sources, allowing them to access \n",
       "and process information from various sources.\n",
       "\n",
       "Here's a breakdown of what LlamaIndex does:\n",
       "\n",
       "**Key Features:**\n",
       "\n",
       "* **Data Connection:** LlamaIndex connects LLMs to data sources like:\n",
       "    * **Documents:** PDFs, Word documents, web pages\n",
       "    * **Databases:** SQL, NoSQL\n",
       "    * **APIs:** Weather, stock data, etc.\n",
       "* **Data Indexing:** It indexes data into a format LLMs can understand, allowing them to retrieve and process \n",
       "information efficiently.\n",
       "* **Querying:** Users can ask natural language questions, and LlamaIndex translates them into queries that retrieve\n",
       "relevant information from the indexed data.\n",
       "* **Response Generation:** LLMs then use the retrieved information to generate comprehensive and informative \n",
       "responses.\n",
       "* **Retrieval Augmentation:** LlamaIndex can be used to augment LLM responses with relevant information from \n",
       "external data sources, making them more accurate and complete.\n",
       "* **Customizability:** Users can customize LlamaIndex to fit their specific needs and data sources.\n",
       "\n",
       "**Benefits of using LlamaIndex:**\n",
       "\n",
       "* **Enhanced LLM Capabilities:** LLMs can access and utilize external data, improving their knowledge base and \n",
       "ability to provide accurate and relevant information.\n",
       "* **Real-World Applications:** LlamaIndex enables LLMs to be used in a wider range of practical applications, such \n",
       "as:\n",
       "    * **Knowledge Management:** Creating a searchable knowledge base from company documents.\n",
       "    * **Customer Service:** Providing accurate and helpful responses to customer inquiries.\n",
       "    * **Research:** Summarizing and analyzing research papers.\n",
       "    * **Education:** Creating personalized learning experiences.\n",
       "* **Simplified LLM Integration:** LlamaIndex simplifies the process of integrating LLMs with external data sources,\n",
       "making it easier for developers to build LLM-powered applications.\n",
       "\n",
       "**In essence, LlamaIndex acts as a bridge between LLMs and the real world, allowing them to access and utilize \n",
       "external data to provide more comprehensive and helpful responses.**\n",
       "\n",
       "**Here's an analogy:** Think of LlamaIndex as a librarian who helps you find the right books in a library. You ask \n",
       "the librarian a question, and they direct you to the relevant books. Similarly, LlamaIndex helps LLMs find and \n",
       "understand information from various sources, making them more knowledgeable and helpful.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Input Tokens: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>\n",
       " Output Tokens: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">504</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Input Tokens: \u001b[1;36m6\u001b[0m\n",
       " Output Tokens: \u001b[1;36m504\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = llm.invoke(\"What is LlamaIndex?\")\n",
    "\n",
    "print(result.content)\n",
    "print(f\"Input Tokens: {result.usage_metadata['input_tokens']}\\nOutput Tokens: {result.usage_metadata['output_tokens']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatPrompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatPromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">input_variables</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'input'</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">messages</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SystemMessagePromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">prompt</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTemplate</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">input_variables</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">template</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'You are a senior Python developer. You write code snippets based on the query'</span>\n",
       "            <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">HumanMessagePromptTemplate</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">prompt</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTemplate</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">input_variables</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'input'</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">template</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{input}'</span><span style=\"font-weight: bold\">))</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatPromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33minput_variables\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'input'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mmessages\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mSystemMessagePromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mprompt\u001b[0m=\u001b[1;35mPromptTemplate\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33minput_variables\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "                \u001b[33mtemplate\u001b[0m=\u001b[32m'You are a senior Python developer. You write code snippets based on the query'\u001b[0m\n",
       "            \u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mHumanMessagePromptTemplate\u001b[0m\u001b[1m(\u001b[0m\u001b[33mprompt\u001b[0m=\u001b[1;35mPromptTemplate\u001b[0m\u001b[1m(\u001b[0m\u001b[33minput_variables\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'input'\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mtemplate\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32minput\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_core.prompts import  ChatPromptTemplate\n",
    "# writing a prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a senior Python developer. You write code snippets based on the query\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='```python\\ndef merge_dictionaries(dict1, dict2):\\n  \"\"\"Merges two dictionaries, giving precedence to values in dict2 if keys are the same.\\n\\n  Args:\\n    dict1: The first dictionary.\\n    dict2: The second dictionary.\\n\\n  Returns:\\n    A new dictionary containing the merged contents of dict1 and dict2.\\n  \"\"\"\\n\\n  merged_dict = dict1.copy()  # Start with a copy of dict1\\n  merged_dict.update(dict2)  # Update with dict2, overwriting keys if necessary\\n  return merged_dict\\n\\n# Example usage\\ndict1 = {\\'a\\': 1, \\'b\\': 2}\\ndict2 = {\\'b\\': 3, \\'c\\': 4}\\n\\nmerged_dict = merge_dictionaries(dict1, dict2)\\nprint(merged_dict)  # Output: {\\'a\\': 1, \\'b\\': 3, \\'c\\': 4}\\n```\\n\\n**Explanation:**\\n\\n1. **`merge_dictionaries(dict1, dict2)` function:**\\n   - Takes two dictionaries (`dict1` and `dict2`) as input.\\n   - Creates a copy of `dict1` using `dict1.copy()` to avoid modifying the original dictionary.\\n   - Uses the `update()` method on the copy to merge the contents of `dict2`. If a key exists in both dictionaries, the value from `dict2` will overwrite the value from `dict1`.\\n   - Returns the merged dictionary.\\n\\n2. **Example Usage:**\\n   - Defines two sample dictionaries, `dict1` and `dict2`.\\n   - Calls the `merge_dictionaries` function to merge them.\\n   - Prints the resulting `merged_dict`, which shows that values from `dict2` have taken precedence for the shared key \\'b\\'.\\n', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-1e99bfdd-c895-4fa5-a409-dd26f32bf027-0', usage_metadata={'input_tokens': 24, 'output_tokens': 401, 'total_tokens': 425})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a chain to combine prompt template and llm\n",
    "chain = prompt | llm\n",
    "# getting the response\n",
    "response = chain.invoke({\"input\": \"Write a Python script that merges two dictionaries\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">```python\n",
       "def <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">merge_dictionaries</span><span style=\"font-weight: bold\">(</span>dict1, dict2<span style=\"font-weight: bold\">)</span>:\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"Merges two dictionaries, giving precedence to values in dict2 if keys are the same.\n",
       "\n",
       "  Args:\n",
       "    dict1: The first dictionary.\n",
       "    dict2: The second dictionary.\n",
       "\n",
       "  Returns:\n",
       "    A new dictionary containing the merged contents of dict1 and dict2.\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
       "\n",
       "  merged_dict = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">dict1.copy</span><span style=\"font-weight: bold\">()</span>  # Start with a copy of dict1\n",
       "  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">merged_dict.update</span><span style=\"font-weight: bold\">(</span>dict2<span style=\"font-weight: bold\">)</span>  # Update with dict2, overwriting keys if necessary\n",
       "  return merged_dict\n",
       "\n",
       "# Example usage\n",
       "dict1 = <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'a'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'b'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">}</span>\n",
       "dict2 = <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'b'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'c'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "merged_dict = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">merge_dictionaries</span><span style=\"font-weight: bold\">(</span>dict1, dict2<span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">print</span><span style=\"font-weight: bold\">(</span>merged_dict<span style=\"font-weight: bold\">)</span>  # Output: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'a'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'b'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'c'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">}</span>\n",
       "```\n",
       "\n",
       "**Explanation:**\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. **`<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">merge_dictionaries</span><span style=\"font-weight: bold\">(</span>dict1, dict2<span style=\"font-weight: bold\">)</span>` function:**\n",
       "   - Takes two dictionaries <span style=\"font-weight: bold\">(</span>`dict1` and `dict2`<span style=\"font-weight: bold\">)</span> as input.\n",
       "   - Creates a copy of `dict1` using `<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">dict1.copy</span><span style=\"font-weight: bold\">()</span>` to avoid modifying the original dictionary.\n",
       "   - Uses the `<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">update</span><span style=\"font-weight: bold\">()</span>` method on the copy to merge the contents of `dict2`. If a key exists in both dictionaries,\n",
       "the value from `dict2` will overwrite the value from `dict1`.\n",
       "   - Returns the merged dictionary.\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. **Example Usage:**\n",
       "   - Defines two sample dictionaries, `dict1` and `dict2`.\n",
       "   - Calls the `merge_dictionaries` function to merge them.\n",
       "   - Prints the resulting `merged_dict`, which shows that values from `dict2` have taken precedence for the shared \n",
       "key <span style=\"color: #008000; text-decoration-color: #008000\">'b'</span>.\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "```python\n",
       "def \u001b[1;35mmerge_dictionaries\u001b[0m\u001b[1m(\u001b[0mdict1, dict2\u001b[1m)\u001b[0m:\n",
       "  \u001b[32m\"\"\u001b[0m\"Merges two dictionaries, giving precedence to values in dict2 if keys are the same.\n",
       "\n",
       "  Args:\n",
       "    dict1: The first dictionary.\n",
       "    dict2: The second dictionary.\n",
       "\n",
       "  Returns:\n",
       "    A new dictionary containing the merged contents of dict1 and dict2.\n",
       "  \u001b[32m\"\"\u001b[0m\"\n",
       "\n",
       "  merged_dict = \u001b[1;35mdict1.copy\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m  # Start with a copy of dict1\n",
       "  \u001b[1;35mmerged_dict.update\u001b[0m\u001b[1m(\u001b[0mdict2\u001b[1m)\u001b[0m  # Update with dict2, overwriting keys if necessary\n",
       "  return merged_dict\n",
       "\n",
       "# Example usage\n",
       "dict1 = \u001b[1m{\u001b[0m\u001b[32m'a'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'b'\u001b[0m: \u001b[1;36m2\u001b[0m\u001b[1m}\u001b[0m\n",
       "dict2 = \u001b[1m{\u001b[0m\u001b[32m'b'\u001b[0m: \u001b[1;36m3\u001b[0m, \u001b[32m'c'\u001b[0m: \u001b[1;36m4\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "merged_dict = \u001b[1;35mmerge_dictionaries\u001b[0m\u001b[1m(\u001b[0mdict1, dict2\u001b[1m)\u001b[0m\n",
       "\u001b[1;35mprint\u001b[0m\u001b[1m(\u001b[0mmerged_dict\u001b[1m)\u001b[0m  # Output: \u001b[1m{\u001b[0m\u001b[32m'a'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'b'\u001b[0m: \u001b[1;36m3\u001b[0m, \u001b[32m'c'\u001b[0m: \u001b[1;36m4\u001b[0m\u001b[1m}\u001b[0m\n",
       "```\n",
       "\n",
       "**Explanation:**\n",
       "\n",
       "\u001b[1;36m1\u001b[0m. **`\u001b[1;35mmerge_dictionaries\u001b[0m\u001b[1m(\u001b[0mdict1, dict2\u001b[1m)\u001b[0m` function:**\n",
       "   - Takes two dictionaries \u001b[1m(\u001b[0m`dict1` and `dict2`\u001b[1m)\u001b[0m as input.\n",
       "   - Creates a copy of `dict1` using `\u001b[1;35mdict1.copy\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m` to avoid modifying the original dictionary.\n",
       "   - Uses the `\u001b[1;35mupdate\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m` method on the copy to merge the contents of `dict2`. If a key exists in both dictionaries,\n",
       "the value from `dict2` will overwrite the value from `dict1`.\n",
       "   - Returns the merged dictionary.\n",
       "\n",
       "\u001b[1;36m2\u001b[0m. **Example Usage:**\n",
       "   - Defines two sample dictionaries, `dict1` and `dict2`.\n",
       "   - Calls the `merge_dictionaries` function to merge them.\n",
       "   - Prints the resulting `merged_dict`, which shows that values from `dict2` have taken precedence for the shared \n",
       "key \u001b[32m'b'\u001b[0m.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(response.content)\n",
    "type(response) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StrOutput Parser\n",
    "It structures the output as string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "# adding the output parser in chain\n",
    "chain = prompt | llm | output_parser\n",
    "response = chain.invoke({\"input\": \"Write a code snippet that calculates factorial of a number\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">```python\n",
       "def <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">factorial</span><span style=\"font-weight: bold\">(</span>n<span style=\"font-weight: bold\">)</span>:\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"Calculates the factorial of a non-negative integer.\n",
       "\n",
       "  Args:\n",
       "    n: The non-negative integer to calculate the factorial of.\n",
       "\n",
       "  Returns:\n",
       "    The factorial of n, or <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> if n is <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.\n",
       "\n",
       "  Raises:\n",
       "    ValueError: If n is negative.\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
       "  if n &lt; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>:\n",
       "    raise <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ValueError</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Factorial is not defined for negative numbers\"</span><span style=\"font-weight: bold\">)</span>\n",
       "  elif n == <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>:\n",
       "    return <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "  else:\n",
       "    return n * <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">factorial</span><span style=\"font-weight: bold\">(</span>n - <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "# Example usage\n",
       "number = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "result = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">factorial</span><span style=\"font-weight: bold\">(</span>number<span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">print</span><span style=\"font-weight: bold\">(</span>f\"The factorial of <span style=\"font-weight: bold\">{</span>number<span style=\"font-weight: bold\">}</span> is <span style=\"font-weight: bold\">{</span>result<span style=\"font-weight: bold\">}</span>\"<span style=\"font-weight: bold\">)</span>\n",
       "```\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "```python\n",
       "def \u001b[1;35mfactorial\u001b[0m\u001b[1m(\u001b[0mn\u001b[1m)\u001b[0m:\n",
       "  \u001b[32m\"\"\u001b[0m\"Calculates the factorial of a non-negative integer.\n",
       "\n",
       "  Args:\n",
       "    n: The non-negative integer to calculate the factorial of.\n",
       "\n",
       "  Returns:\n",
       "    The factorial of n, or \u001b[1;36m1\u001b[0m if n is \u001b[1;36m0\u001b[0m.\n",
       "\n",
       "  Raises:\n",
       "    ValueError: If n is negative.\n",
       "  \u001b[32m\"\"\u001b[0m\"\n",
       "  if n < \u001b[1;36m0\u001b[0m:\n",
       "    raise \u001b[1;35mValueError\u001b[0m\u001b[1m(\u001b[0m\u001b[32m\"Factorial is not defined for negative numbers\"\u001b[0m\u001b[1m)\u001b[0m\n",
       "  elif n == \u001b[1;36m0\u001b[0m:\n",
       "    return \u001b[1;36m1\u001b[0m\n",
       "  else:\n",
       "    return n * \u001b[1;35mfactorial\u001b[0m\u001b[1m(\u001b[0mn - \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n",
       "\n",
       "# Example usage\n",
       "number = \u001b[1;36m5\u001b[0m\n",
       "result = \u001b[1;35mfactorial\u001b[0m\u001b[1m(\u001b[0mnumber\u001b[1m)\u001b[0m\n",
       "\u001b[1;35mprint\u001b[0m\u001b[1m(\u001b[0mf\"The factorial of \u001b[1m{\u001b[0mnumber\u001b[1m}\u001b[0m is \u001b[1m{\u001b[0mresult\u001b[1m}\u001b[0m\"\u001b[1m)\u001b[0m\n",
       "```\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(response)  # it'll print the content of the response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
